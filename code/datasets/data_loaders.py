#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# datasets/data_loaders.py

"""
ç®€åŒ–çš„MR2æ•°æ®åŠ è½½å™¨
ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½ï¼Œæ˜“äºç†è§£å’Œä½¿ç”¨
"""

import torch
from torch.utils.data import DataLoader
import numpy as np
from typing import Dict, List, Optional, Any
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_file = Path(__file__).resolve()
code_root = current_file.parent.parent
sys.path.append(str(code_root))

# å¯¼å…¥å¿…è¦æ¨¡å— - ä¿®å¤å¯¼å…¥é—®é¢˜
try:
    # æ–¹æ³•1: å°è¯•ç›¸å¯¹å¯¼å…¥
    from .mr2_dataset import MR2Dataset
    USE_CUSTOM_MODULES = True
    print("âœ… æˆåŠŸå¯¼å…¥è‡ªå®šä¹‰æ¨¡å— (ç›¸å¯¹å¯¼å…¥)")
except ImportError:
    try:
        # æ–¹æ³•2: å°è¯•ç›´æ¥å¯¼å…¥
        from mr2_dataset import MR2Dataset
        USE_CUSTOM_MODULES = True
        print("âœ… æˆåŠŸå¯¼å…¥è‡ªå®šä¹‰æ¨¡å— (ç›´æ¥å¯¼å…¥)")
    except ImportError:
        try:
            # æ–¹æ³•3: å°è¯•ç»å¯¹è·¯å¾„å¯¼å…¥
            import sys
            datasets_path = current_file.parent
            sys.path.insert(0, str(datasets_path))
            from mr2_dataset import MR2Dataset
            USE_CUSTOM_MODULES = True
            print("âœ… æˆåŠŸå¯¼å…¥è‡ªå®šä¹‰æ¨¡å— (ç»å¯¹è·¯å¾„å¯¼å…¥)")
        except ImportError as e:
            print(f"âš ï¸  å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—å¤±è´¥: {e}")
            USE_CUSTOM_MODULES = False
            
            # åˆ›å»ºç®€å•çš„æ•°æ®é›†å ä½ç¬¦
            class MR2Dataset:
                def __init__(self, *args, **kwargs):
                    self.items = []
                    print("ä½¿ç”¨ç®€åŒ–ç‰ˆMR2Dataset")
                
                def __len__(self):
                    return len(self.items)
                
                def __getitem__(self, idx):
                    return {'item_id': 'demo', 'label': 0, 'text': 'demo text'}

# å°è¯•å¯¼å…¥é…ç½®ç®¡ç†å™¨
try:
    from utils.config_manager import get_training_config, get_data_config
    USE_CONFIG = True
except ImportError:
    USE_CONFIG = False


class SimpleDataLoaderConfig:
    """ç®€åŒ–çš„æ•°æ®åŠ è½½å™¨é…ç½®"""
    
    def __init__(self):
        """åˆå§‹åŒ–é…ç½®"""
        self.config = self.load_config()
    
    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        if USE_CONFIG:
            try:
                training_config = get_training_config()
                data_config = get_data_config()
                
                # ä»é…ç½®ä¸­æå–å…³é”®å‚æ•°
                general_config = training_config.get('general', {}).get('data', {})
                return {
                    'train_batch_size': general_config.get('train_batch_size', 32),
                    'eval_batch_size': general_config.get('eval_batch_size', 64),
                    'num_workers': general_config.get('data_workers', 4),
                    'pin_memory': general_config.get('pin_memory', True)
                }
            except Exception as e:
                print(f"âš ï¸  åŠ è½½é…ç½®å¤±è´¥: {e}")
        
        # é»˜è®¤é…ç½®
        return {
            'train_batch_size': 32,
            'eval_batch_size': 64,
            'num_workers': 4,
            'pin_memory': True
        }


class SimpleCollateFunction:
    """ç®€åŒ–çš„æ‰¹å¤„ç†å‡½æ•°"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        pass
    
    def __call__(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç®€å•çš„æ‰¹å¤„ç†å‡½æ•°
        
        Args:
            batch: æ‰¹æ¬¡æ•°æ®åˆ—è¡¨
            
        Returns:
            æ‰¹å¤„ç†åçš„æ•°æ®å­—å…¸
        """
        if not batch:
            return {}
        
        batch_data = {}
        
        # å¤„ç†åŸºæœ¬å­—æ®µ - ä¿®å¤ä¸ºæ”¯æŒcaptionå­—æ®µ
        for key in ['item_id', 'label', 'text', 'caption']:
            if key in batch[0]:
                batch_data[key] = [item.get(key) for item in batch]
        
        # å¤„ç†æ ‡ç­¾ï¼ˆè½¬æ¢ä¸ºtensorï¼‰
        if 'label' in batch_data:
            batch_data['labels'] = torch.tensor(batch_data['label'], dtype=torch.long)
        
        # å¤„ç†å›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'image' in batch[0]:
            try:
                images = []
                for item in batch:
                    if 'image' in item and item['image'] is not None:
                        images.append(item['image'])
                    else:
                        # åˆ›å»ºç©ºå›¾åƒtensor
                        images.append(torch.zeros(3, 224, 224))
                
                if images:
                    batch_data['images'] = torch.stack(images)
            except Exception as e:
                print(f"âš ï¸  å¤„ç†å›¾åƒå¤±è´¥: {e}")
                batch_data['images'] = torch.zeros(len(batch), 3, 224, 224)
        
        return batch_data


def create_simple_dataloader(data_dir: str,
                            split: str = 'train',
                            batch_size: Optional[int] = None,
                            shuffle: Optional[bool] = None,
                            num_workers: int = 4) -> Optional[DataLoader]:
    """
    åˆ›å»ºç®€å•çš„MR2æ•°æ®åŠ è½½å™¨
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        split: æ•°æ®åˆ’åˆ† ('train', 'val', 'test')
        batch_size: æ‰¹æ¬¡å¤§å°
        shuffle: æ˜¯å¦æ‰“ä¹±
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        
    Returns:
        DataLoaderå¯¹è±¡æˆ–None
    """
    try:
        # åŠ è½½é…ç½®
        config = SimpleDataLoaderConfig()
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        if batch_size is None:
            batch_size = config.config['train_batch_size'] if split == 'train' else config.config['eval_batch_size']
        
        if shuffle is None:
            shuffle = (split == 'train')
        
        print(f"ğŸ“‚ åˆ›å»º {split} æ•°æ®åŠ è½½å™¨...")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"   æ˜¯å¦æ‰“ä¹±: {shuffle}")
        
        if not USE_CUSTOM_MODULES:
            print("âš ï¸  ä½¿ç”¨å ä½ç¬¦æ•°æ®é›†ï¼Œä»…ç”¨äºæµ‹è¯•")
            dataset = MR2Dataset()
            # åˆ›å»ºä¸€äº›è™šæ‹Ÿæ•°æ®
            dataset.items = [{'item_id': f'demo_{i}', 'label': i % 3, 'text': f'Demo text {i}'} for i in range(10)]
        else:
            # åˆ›å»ºçœŸå®æ•°æ®é›†
            print(f"âœ… ä½¿ç”¨çœŸå®MR2æ•°æ®é›†")
            dataset = MR2Dataset(
                data_dir=data_dir,
                split=split,
                transform_type='train' if split == 'train' else 'val',
                load_images=True  # å°è¯•åŠ è½½å›¾åƒ
            )
        
        # åˆ›å»ºcollateå‡½æ•°
        collate_fn = SimpleCollateFunction()
        
        # åˆ›å»ºDataLoader
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=shuffle,
            num_workers=0 if not USE_CUSTOM_MODULES else min(num_workers, 4),  # ç®€åŒ–ï¼šå‡å°‘è¿›ç¨‹æ•°
            collate_fn=collate_fn,
            pin_memory=config.config['pin_memory'] and torch.cuda.is_available()
        )
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        return dataloader
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ•°æ®åŠ è½½å™¨å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None


def create_all_dataloaders(data_dir: str,
                          batch_sizes: Optional[Dict[str, int]] = None) -> Dict[str, DataLoader]:
    """
    åˆ›å»ºæ‰€æœ‰æ•°æ®åŠ è½½å™¨
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        batch_sizes: å„æ•°æ®é›†çš„æ‰¹æ¬¡å¤§å°
        
    Returns:
        æ•°æ®åŠ è½½å™¨å­—å…¸
    """
    if batch_sizes is None:
        batch_sizes = {'train': 32, 'val': 64, 'test': 64}
    
    dataloaders = {}
    
    for split in ['train', 'val', 'test']:
        print(f"\nğŸ“‚ åˆ›å»º {split} æ•°æ®åŠ è½½å™¨...")
        
        batch_size = batch_sizes.get(split, 32)
        dataloader = create_simple_dataloader(
            data_dir=data_dir,
            split=split,
            batch_size=batch_size,
            num_workers=2  # ç®€åŒ–ï¼šä½¿ç”¨è¾ƒå°‘çš„å·¥ä½œè¿›ç¨‹
        )
        
        if dataloader is not None:
            dataloaders[split] = dataloader
            print(f"âœ… {split} æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        else:
            print(f"âŒ {split} æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥")
    
    return dataloaders


def test_dataloader(dataloader: DataLoader, max_batches: int = 3):
    """
    æµ‹è¯•æ•°æ®åŠ è½½å™¨
    
    Args:
        dataloader: è¦æµ‹è¯•çš„æ•°æ®åŠ è½½å™¨
        max_batches: æœ€å¤§æµ‹è¯•æ‰¹æ¬¡æ•°
    """
    print(f"\nğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½å™¨ (æœ€å¤š {max_batches} ä¸ªæ‰¹æ¬¡)")
    
    try:
        for batch_idx, batch in enumerate(dataloader):
            print(f"  æ‰¹æ¬¡ {batch_idx}:")
            
            if isinstance(batch, dict):
                print(f"    æ•°æ®é”®: {list(batch.keys())}")
                
                if 'item_id' in batch:
                    print(f"    æ‰¹æ¬¡å¤§å°: {len(batch['item_id'])}")
                
                if 'labels' in batch:
                    print(f"    æ ‡ç­¾: {batch['labels']}")
                elif 'label' in batch:
                    print(f"    æ ‡ç­¾: {batch['label']}")
                
                if 'images' in batch:
                    print(f"    å›¾åƒå½¢çŠ¶: {batch['images'].shape}")
                
                # æ˜¾ç¤ºæ–‡æœ¬æ ·ä¾‹
                if 'text' in batch and batch['text']:
                    print(f"    æ–‡æœ¬æ ·ä¾‹: {batch['text'][0][:50]}...")
                elif 'caption' in batch and batch['caption']:
                    print(f"    æ–‡æœ¬æ ·ä¾‹: {batch['caption'][0][:50]}...")
            else:
                print(f"    æ‰¹æ¬¡ç±»å‹: {type(batch)}")
            
            if batch_idx >= max_batches - 1:
                break
        
        print("âœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


def demo_usage():
    """æ¼”ç¤ºç”¨æ³•"""
    print("ğŸ”„ æ¼”ç¤ºæ•°æ®åŠ è½½å™¨ä½¿ç”¨æ–¹æ³•")
    
    # è®¾ç½®æ•°æ®ç›®å½•
    data_dir = "data"  # ç›¸å¯¹äºcodeç›®å½•
    
    # åˆ›å»ºå•ä¸ªæ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“š === åˆ›å»ºå•ä¸ªæ•°æ®åŠ è½½å™¨ ===")
    train_loader = create_simple_dataloader(
        data_dir=data_dir,
        split='train',
        batch_size=8,
        shuffle=True
    )
    
    if train_loader:
        test_dataloader(train_loader, max_batches=2)
    
    # åˆ›å»ºæ‰€æœ‰æ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“š === åˆ›å»ºæ‰€æœ‰æ•°æ®åŠ è½½å™¨ ===")
    all_loaders = create_all_dataloaders(
        data_dir=data_dir,
        batch_sizes={'train': 4, 'val': 8, 'test': 8}
    )
    
    print(f"\nğŸ“Š æ•°æ®åŠ è½½å™¨æ‘˜è¦:")
    for split, loader in all_loaders.items():
        print(f"  {split}: {len(loader.dataset)} æ ·æœ¬, æ‰¹æ¬¡å¤§å° {loader.batch_size}")


# ä¸»æ‰§è¡Œä»£ç 
if __name__ == "__main__":
    print("ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½å™¨é…ç½®")
    
    if not USE_CUSTOM_MODULES:
        print("âš ï¸  è‡ªå®šä¹‰æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬è¿›è¡Œæ¼”ç¤º")
    else:
        print("âœ… è‡ªå®šä¹‰æ¨¡å—å¯ç”¨ï¼Œä½¿ç”¨çœŸå®æ•°æ®é›†")
    
    # è¿è¡Œæ¼”ç¤º
    demo_usage()
    
    print("\nâœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•å®Œæˆ")