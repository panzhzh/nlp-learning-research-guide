#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# datasets/mr2_dataset.py

"""
MR2å¤šæ¨¡æ€è°£è¨€æ£€æµ‹æ•°æ®é›†ç±»
PyTorch Datasetå®ç°ï¼Œæ”¯æŒï¼š
- æ–‡æœ¬å’Œå›¾åƒçš„å¤šæ¨¡æ€æ•°æ®åŠ è½½
- æ£€ç´¢å¢å¼ºä¿¡æ¯çš„æ•´åˆ
- çµæ´»çš„æ•°æ®å¢å¼ºç­–ç•¥
- æ‰¹é‡æ•°æ®å¤„ç†
- ç¼“å­˜æœºåˆ¶ä¼˜åŒ–
"""

import os
import json
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
from typing import Dict, List, Optional, Tuple, Union, Any
from pathlib import Path
import sys
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_file = Path(__file__).resolve()
code_root = current_file.parent.parent
sys.path.append(str(code_root))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from preprocessing.text_processing import TextProcessor
    from preprocessing.image_processing import ImageProcessor
    from utils.config_manager import get_data_config, get_data_dir, get_label_mapping
    USE_CUSTOM_MODULES = True
except ImportError as e:
    print(f"âš ï¸  å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—å¤±è´¥: {e}")
    USE_CUSTOM_MODULES = False

import logging
logger = logging.getLogger(__name__)


class MR2Dataset(Dataset):
    """
    MR2å¤šæ¨¡æ€è°£è¨€æ£€æµ‹æ•°æ®é›†
    
    æ•°æ®æ ¼å¼:
    - æ–‡æœ¬: ä¸­è‹±æ–‡æ··åˆçš„å£°æ˜æ–‡æœ¬
    - å›¾åƒ: ä¸å£°æ˜ç›¸å…³çš„å›¾åƒ
    - æ ‡ç­¾: 0=Non-rumor, 1=Rumor, 2=Unverified
    - æ£€ç´¢ä¿¡æ¯: ç›´æ¥æ£€ç´¢å’Œåå‘æ£€ç´¢çš„éªŒè¯ä¿¡æ¯
    """
    
    def __init__(self, 
                 data_dir: Union[str, Path],
                 split: str = 'train',
                 transform_type: str = 'train',
                 load_retrieval_info: bool = True,
                 use_cache: bool = True,
                 target_size: Tuple[int, int] = (224, 224),
                 max_text_length: int = 512):
        """
        åˆå§‹åŒ–MR2æ•°æ®é›†
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            split: æ•°æ®åˆ’åˆ† ('train', 'val', 'test')
            transform_type: å›¾åƒå˜æ¢ç±»å‹ ('train', 'val')
            load_retrieval_info: æ˜¯å¦åŠ è½½æ£€ç´¢ä¿¡æ¯
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            target_size: ç›®æ ‡å›¾åƒå°ºå¯¸
            max_text_length: æœ€å¤§æ–‡æœ¬é•¿åº¦
        """
        self.data_dir = Path(data_dir)
        self.split = split
        self.transform_type = transform_type
        self.load_retrieval_info = load_retrieval_info
        self.use_cache = use_cache
        self.target_size = target_size
        self.max_text_length = max_text_length
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.setup_processors()
        
        # åŠ è½½é…ç½®
        self.load_config()
        
        # åŠ è½½æ•°æ®
        self.load_dataset()
        
        # åˆå§‹åŒ–ç¼“å­˜
        if self.use_cache:
            self.image_cache = {}
            self.text_cache = {}
        
        print(f"ğŸ“š MR2æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ•°æ®åˆ’åˆ†: {self.split}")
        print(f"   æ ·æœ¬æ•°é‡: {len(self.items)}")
        print(f"   æ ‡ç­¾åˆ†å¸ƒ: {self.get_label_distribution()}")
    
    def setup_processors(self):
        """è®¾ç½®æ–‡æœ¬å’Œå›¾åƒå¤„ç†å™¨"""
        if USE_CUSTOM_MODULES:
            # ä½¿ç”¨è‡ªå®šä¹‰å¤„ç†å™¨
            self.text_processor = TextProcessor(language='mixed')
            self.image_processor = ImageProcessor(target_size=self.target_size)
        else:
            # ä½¿ç”¨åŸºæœ¬å¤„ç†å™¨
            self.text_processor = None
            self.image_processor = None
            
            # è®¾ç½®åŸºæœ¬å›¾åƒå˜æ¢
            if self.transform_type == 'train':
                self.image_transforms = transforms.Compose([
                    transforms.Resize(self.target_size),
                    transforms.RandomHorizontalFlip(p=0.5),
                    transforms.RandomRotation(degrees=10),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                       std=[0.229, 0.224, 0.225])
                ])
            else:
                self.image_transforms = transforms.Compose([
                    transforms.Resize(self.target_size),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                       std=[0.229, 0.224, 0.225])
                ])
    
    def load_config(self):
        """åŠ è½½é…ç½®ä¿¡æ¯"""
        if USE_CUSTOM_MODULES:
            try:
                # ä½¿ç”¨é…ç½®ç®¡ç†å™¨
                self.label_mapping = get_label_mapping()
                data_config = get_data_config()
                self.dataset_config = data_config.get('dataset', {})
            except:
                # é»˜è®¤é…ç½®
                self.label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
                self.dataset_config = {}
        else:
            # é»˜è®¤é…ç½®
            self.label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
            self.dataset_config = {}
    
    def load_dataset(self):
        """åŠ è½½æ•°æ®é›†æ–‡ä»¶"""
        # åŠ è½½ä¸»æ•°æ®æ–‡ä»¶
        dataset_file = self.data_dir / f'dataset_items_{self.split}.json'
        
        if not dataset_file.exists():
            raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset_file}")
        
        with open(dataset_file, 'r', encoding='utf-8') as f:
            self.raw_data = json.load(f)
        
        # æ„å»ºæ•°æ®é¡¹åˆ—è¡¨
        self.items = []
        self.item_ids = []
        
        for item_id, item_data in self.raw_data.items():
            # éªŒè¯å¿…è¦å­—æ®µ
            if 'caption' in item_data and 'label' in item_data:
                self.items.append(item_data)
                self.item_ids.append(item_id)
        
        print(f"ğŸ“‚ åŠ è½½ {self.split} æ•°æ®: {len(self.items)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
        
        # åŠ è½½æ£€ç´¢ä¿¡æ¯
        if self.load_retrieval_info:
            self.load_retrieval_annotations()
    
    def load_retrieval_annotations(self):
        """åŠ è½½æ£€ç´¢æ ‡æ³¨ä¿¡æ¯"""
        self.direct_annotations = {}
        self.inverse_annotations = {}
        
        # åŠ è½½ç›´æ¥æ£€ç´¢æ ‡æ³¨
        direct_file = self.data_dir / self.split / 'img_html_news' / 'direct_annotation.json'
        if direct_file.exists():
            try:
                with open(direct_file, 'r', encoding='utf-8') as f:
                    self.direct_annotations = json.load(f)
                print(f"âœ… åŠ è½½ç›´æ¥æ£€ç´¢æ ‡æ³¨: {len(self.direct_annotations)} æ¡")
            except Exception as e:
                logger.warning(f"åŠ è½½ç›´æ¥æ£€ç´¢æ ‡æ³¨å¤±è´¥: {e}")
        
        # åŠ è½½åå‘æ£€ç´¢æ ‡æ³¨
        inverse_file = self.data_dir / self.split / 'inverse_search' / 'inverse_annotation.json'
        if inverse_file.exists():
            try:
                with open(inverse_file, 'r', encoding='utf-8') as f:
                    self.inverse_annotations = json.load(f)
                print(f"âœ… åŠ è½½åå‘æ£€ç´¢æ ‡æ³¨: {len(self.inverse_annotations)} æ¡")
            except Exception as e:
                logger.warning(f"åŠ è½½åå‘æ£€ç´¢æ ‡æ³¨å¤±è´¥: {e}")
    
    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†å¤§å°"""
        return len(self.items)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """
        è·å–å•ä¸ªæ•°æ®æ ·æœ¬
        
        Args:
            idx: æ ·æœ¬ç´¢å¼•
            
        Returns:
            åŒ…å«æ–‡æœ¬ã€å›¾åƒã€æ ‡ç­¾ç­‰ä¿¡æ¯çš„å­—å…¸
        """
        if idx >= len(self.items):
            raise IndexError(f"ç´¢å¼•è¶…å‡ºèŒƒå›´: {idx} >= {len(self.items)}")
        
        item = self.items[idx]
        item_id = self.item_ids[idx]
        
        # æ„å»ºåŸºæœ¬æ•°æ®é¡¹
        data_item = {
            'item_id': item_id,
            'text': item.get('caption', ''),
            'label': item.get('label', -1),
            'language': item.get('language', 'unknown'),
            'source': item.get('source', 'unknown')
        }
        
        # å¤„ç†æ–‡æœ¬
        processed_text = self.process_text(data_item['text'])
        data_item.update(processed_text)
        
        # å¤„ç†å›¾åƒ
        if 'image_path' in item:
            processed_image = self.process_image(item['image_path'], item_id)
            data_item.update(processed_image)
        else:
            # å¦‚æœæ²¡æœ‰å›¾åƒï¼Œåˆ›å»ºç©ºtensor
            data_item['image'] = torch.zeros(3, *self.target_size)
            data_item['has_image'] = False
        
        # æ·»åŠ æ£€ç´¢ä¿¡æ¯
        if self.load_retrieval_info:
            retrieval_info = self.get_retrieval_info(item_id)
            data_item.update(retrieval_info)
        
        return data_item
    
    def process_text(self, text: str) -> Dict[str, Any]:
        """
        å¤„ç†æ–‡æœ¬æ•°æ®
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            å¤„ç†åçš„æ–‡æœ¬ä¿¡æ¯å­—å…¸
        """
        if USE_CUSTOM_MODULES and self.text_processor:
            # ä½¿ç”¨ç¼“å­˜
            if self.use_cache and text in self.text_cache:
                return self.text_cache[text]
            
            # å¤„ç†æ–‡æœ¬
            cleaned_text = self.text_processor.clean_text(text)
            tokens = self.text_processor.tokenize(text)
            features = self.text_processor.extract_features(text)
            
            processed = {
                'text_cleaned': cleaned_text,
                'text_tokens': tokens,
                'text_length': len(text),
                'token_count': len(tokens),
                'detected_language': features.get('language', 'unknown'),
                'text_features': features
            }
            
            # ç¼“å­˜ç»“æœ
            if self.use_cache:
                self.text_cache[text] = processed
            
            return processed
        else:
            # åŸºæœ¬æ–‡æœ¬å¤„ç†
            return {
                'text_cleaned': text.strip(),
                'text_tokens': text.split(),
                'text_length': len(text),
                'token_count': len(text.split()),
                'detected_language': 'unknown',
                'text_features': {}
            }
    
    def process_image(self, image_path: str, item_id: str) -> Dict[str, Any]:
        """
        å¤„ç†å›¾åƒæ•°æ®
        
        Args:
            image_path: å›¾åƒç›¸å¯¹è·¯å¾„
            item_id: æ•°æ®é¡¹ID
            
        Returns:
            å¤„ç†åçš„å›¾åƒä¿¡æ¯å­—å…¸
        """
        # æ„å»ºå®Œæ•´è·¯å¾„
        full_image_path = self.data_dir / image_path
        
        # ä½¿ç”¨ç¼“å­˜
        if self.use_cache and item_id in self.image_cache:
            return self.image_cache[item_id]
        
        if not full_image_path.exists():
            logger.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {full_image_path}")
            return {
                'image': torch.zeros(3, *self.target_size),
                'has_image': False,
                'image_path': str(full_image_path)
            }
        
        try:
            if USE_CUSTOM_MODULES and self.image_processor:
                # ä½¿ç”¨è‡ªå®šä¹‰å›¾åƒå¤„ç†å™¨
                image_tensor = self.image_processor.process_single_image(
                    full_image_path, 
                    transform_type=self.transform_type
                )
                
                if image_tensor is None:
                    raise Exception("å›¾åƒå¤„ç†å¤±è´¥")
                
                # è·å–å›¾åƒä¿¡æ¯
                image_info = self.image_processor.get_image_info(full_image_path)
                
                processed = {
                    'image': image_tensor,
                    'has_image': True,
                    'image_path': str(full_image_path),
                    'image_info': image_info
                }
            else:
                # åŸºæœ¬å›¾åƒå¤„ç†
                image = Image.open(full_image_path).convert('RGB')
                image_tensor = self.image_transforms(image)
                
                processed = {
                    'image': image_tensor,
                    'has_image': True,
                    'image_path': str(full_image_path),
                    'image_info': {
                        'size': image.size,
                        'mode': image.mode
                    }
                }
            
            # ç¼“å­˜ç»“æœ
            if self.use_cache:
                self.image_cache[item_id] = processed
            
            return processed
            
        except Exception as e:
            logger.error(f"å¤„ç†å›¾åƒå¤±è´¥ {full_image_path}: {e}")
            return {
                'image': torch.zeros(3, *self.target_size),
                'has_image': False,
                'image_path': str(full_image_path)
            }
    
    def get_retrieval_info(self, item_id: str) -> Dict[str, Any]:
        """
        è·å–æ£€ç´¢ä¿¡æ¯
        
        Args:
            item_id: æ•°æ®é¡¹ID
            
        Returns:
            æ£€ç´¢ä¿¡æ¯å­—å…¸
        """
        retrieval_info = {
            'has_direct_retrieval': False,
            'has_inverse_retrieval': False,
            'direct_info': {},
            'inverse_info': {}
        }
        
        # ç›´æ¥æ£€ç´¢ä¿¡æ¯
        if item_id in self.direct_annotations:
            retrieval_info['has_direct_retrieval'] = True
            retrieval_info['direct_info'] = self.direct_annotations[item_id]
        
        # åå‘æ£€ç´¢ä¿¡æ¯
        if item_id in self.inverse_annotations:
            retrieval_info['has_inverse_retrieval'] = True
            retrieval_info['inverse_info'] = self.inverse_annotations[item_id]
        
        return retrieval_info
    
    def get_label_distribution(self) -> Dict[str, int]:
        """è·å–æ ‡ç­¾åˆ†å¸ƒ"""
        label_counts = {}
        for item in self.items:
            label = item.get('label', -1)
            label_name = self.label_mapping.get(label, f'Unknown({label})')
            label_counts[label_name] = label_counts.get(label_name, 0) + 1
        return label_counts
    
    def get_sample_by_id(self, item_id: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®IDè·å–æ ·æœ¬
        
        Args:
            item_id: æ•°æ®é¡¹ID
            
        Returns:
            æ ·æœ¬æ•°æ®æˆ–None
        """
        try:
            idx = self.item_ids.index(item_id)
            return self[idx]
        except ValueError:
            return None
    
    def get_samples_by_label(self, label: int, max_samples: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šæ ‡ç­¾çš„æ ·æœ¬
        
        Args:
            label: æ ‡ç­¾å€¼
            max_samples: æœ€å¤§æ ·æœ¬æ•°
            
        Returns:
            æ ·æœ¬åˆ—è¡¨
        """
        samples = []
        for idx, item in enumerate(self.items):
            if item.get('label') == label and len(samples) < max_samples:
                samples.append(self[idx])
        return samples
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_samples': len(self.items),
            'label_distribution': self.get_label_distribution(),
            'language_distribution': {},
            'has_image_count': 0,
            'has_retrieval_count': 0
        }
        
        # ç»Ÿè®¡è¯­è¨€åˆ†å¸ƒå’Œå…¶ä»–ä¿¡æ¯
        for item in self.items:
            # è¯­è¨€åˆ†å¸ƒ
            language = item.get('language', 'unknown')
            stats['language_distribution'][language] = stats['language_distribution'].get(language, 0) + 1
            
            # å›¾åƒç»Ÿè®¡
            if 'image_path' in item:
                stats['has_image_count'] += 1
        
        # æ£€ç´¢ä¿¡æ¯ç»Ÿè®¡
        if self.load_retrieval_info:
            stats['direct_retrieval_count'] = len(self.direct_annotations)
            stats['inverse_retrieval_count'] = len(self.inverse_annotations)
        
        return stats
    
    def save_processed_data(self, output_dir: Optional[str] = None):
        """
        ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®
        
        Args:
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºdata/processed
        """
        if output_dir is None:
            output_dir = self.data_dir / 'processed'
        else:
            output_dir = Path(output_dir)
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å¤„ç†æ‰€æœ‰æ•°æ®
        processed_data = []
        print(f"ğŸ”„ å¤„ç† {len(self.items)} ä¸ªæ ·æœ¬...")
        
        for idx in range(len(self.items)):
            if idx % 50 == 0:
                print(f"  å·²å¤„ç† {idx}/{len(self.items)}")
            
            data_item = self[idx]
            processed_data.append(data_item)
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        output_file = output_dir / f'{self.split}_processed.json'
        
        # ç”±äºåŒ…å«tensorï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        serializable_data = []
        for item in processed_data:
            # åˆ›å»ºå¯åºåˆ—åŒ–çš„å‰¯æœ¬
            serializable_item = {}
            for key, value in item.items():
                if isinstance(value, torch.Tensor):
                    # ä¿å­˜tensorçš„å½¢çŠ¶ä¿¡æ¯
                    serializable_item[f'{key}_shape'] = list(value.shape)
                elif key == 'text_features' and isinstance(value, dict):
                    # ä¿å­˜æ–‡æœ¬ç‰¹å¾
                    serializable_item[key] = value
                elif not isinstance(value, (torch.Tensor, type(lambda: None))):
                    serializable_item[key] = value
            
            serializable_data.append(serializable_item)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å¤„ç†åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")


def create_mr2_dataloader(data_dir: Union[str, Path],
                         split: str = 'train',
                         batch_size: int = 32,
                         shuffle: bool = True,
                         num_workers: int = 4,
                         **dataset_kwargs) -> DataLoader:
    """
    åˆ›å»ºMR2æ•°æ®åŠ è½½å™¨
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        split: æ•°æ®åˆ’åˆ†
        batch_size: æ‰¹æ¬¡å¤§å°
        shuffle: æ˜¯å¦æ‰“ä¹±
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        **dataset_kwargs: æ•°æ®é›†é¢å¤–å‚æ•°
        
    Returns:
        DataLoaderå¯¹è±¡
    """
    # åˆ›å»ºæ•°æ®é›†
    dataset = MR2Dataset(data_dir=data_dir, split=split, **dataset_kwargs)
    
    # è‡ªå®šä¹‰collate functionå¤„ç†å¯å˜é•¿åº¦æ•°æ®
    def collate_fn(batch):
        """è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°"""
        # æ”¶é›†æ‰€æœ‰å­—æ®µ
        batch_data = {}
        
        # å¤„ç†æ¯ä¸ªå­—æ®µ
        for key in batch[0].keys():
            if key == 'image':
                # å †å å›¾åƒtensor
                batch_data[key] = torch.stack([item[key] for item in batch])
            elif key in ['text_tokens']:
                # ä¿æŒåˆ—è¡¨å½¢å¼
                batch_data[key] = [item[key] for item in batch]
            elif isinstance(batch[0][key], (int, float, str, bool)):
                # ç®€å•ç±»å‹ç›´æ¥æ”¶é›†
                batch_data[key] = [item[key] for item in batch]
            elif isinstance(batch[0][key], dict):
                # å­—å…¸ç±»å‹
                batch_data[key] = [item[key] for item in batch]
            else:
                # å…¶ä»–ç±»å‹
                batch_data[key] = [item[key] for item in batch]
        
        return batch_data
    
    # åˆ›å»ºDataLoader
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=torch.cuda.is_available()
    )
    
    return dataloader


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ“š æµ‹è¯•MR2æ•°æ®é›†ç±»")
    
    # è®¾ç½®æ•°æ®ç›®å½•
    data_dir = "data"  # æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®é›†...")
        train_dataset = MR2Dataset(
            data_dir=data_dir,
            split='train',
            transform_type='train',
            load_retrieval_info=True,
            use_cache=True
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"   æ•°æ®é›†å¤§å°: {len(train_dataset)}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = train_dataset.get_statistics()
        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"   æ ‡ç­¾åˆ†å¸ƒ: {stats['label_distribution']}")
        print(f"   è¯­è¨€åˆ†å¸ƒ: {stats['language_distribution']}")
        print(f"   æœ‰å›¾åƒæ ·æœ¬: {stats['has_image_count']}")
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        print(f"\nğŸ” æµ‹è¯•å•ä¸ªæ ·æœ¬:")
        sample = train_dataset[0]
        print(f"   æ ·æœ¬ID: {sample['item_id']}")
        print(f"   æ–‡æœ¬é•¿åº¦: {sample['text_length']}")
        print(f"   æ ‡ç­¾: {sample['label']}")
        print(f"   æœ‰å›¾åƒ: {sample['has_image']}")
        if sample['has_image']:
            print(f"   å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        
        # æµ‹è¯•æŒ‰æ ‡ç­¾è·å–æ ·æœ¬
        print(f"\nğŸ·ï¸  æµ‹è¯•æŒ‰æ ‡ç­¾è·å–æ ·æœ¬:")
        rumor_samples = train_dataset.get_samples_by_label(label=1, max_samples=3)
        print(f"   è·å–åˆ° {len(rumor_samples)} ä¸ªè°£è¨€æ ·æœ¬")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print(f"\nğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        dataloader = create_mr2_dataloader(
            data_dir=data_dir,
            split='train',
            batch_size=4,
            shuffle=True,
            num_workers=0  # è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
        )
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ‰¹å¤„ç†
        print(f"\nğŸ“¦ æµ‹è¯•æ‰¹å¤„ç†:")
        for batch_idx, batch in enumerate(dataloader):
            print(f"   æ‰¹æ¬¡ {batch_idx}:")
            print(f"     æ‰¹æ¬¡å¤§å°: {len(batch['item_id'])}")
            print(f"     å›¾åƒå½¢çŠ¶: {batch['image'].shape}")
            print(f"     æ ‡ç­¾: {batch['label']}")
            
            if batch_idx >= 2:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
                break
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
        print(f"\nğŸ’¾ ä¿å­˜å¤„ç†åçš„æ•°æ®...")
        train_dataset.save_processed_data()
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print(f"è¯·ç¡®ä¿æ•°æ®ç›®å½• '{data_dir}' å­˜åœ¨ä¸”åŒ…å«å¿…è¦çš„æ–‡ä»¶")
        
        # æä¾›è°ƒè¯•ä¿¡æ¯
        data_path = Path(data_dir)
        if data_path.exists():
            print(f"\nğŸ” æ•°æ®ç›®å½•å†…å®¹:")
            for item in data_path.iterdir():
                print(f"   {item.name}")
        else:
            print(f"\nâŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
    
    print(f"\nâœ… MR2æ•°æ®é›†æµ‹è¯•å®Œæˆ")