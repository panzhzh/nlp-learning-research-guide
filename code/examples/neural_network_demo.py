#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# examples/neural_network_demo.py

"""
ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒæ¼”ç¤º - ä½¿ç”¨çœŸå®MR2æ•°æ®
ä¸traditional_ml_demo.pyä¿æŒä¸€è‡´çš„å‘½åå’Œç»“æ„
ä¿®å¤äº†æ¨¡å—å¯¼å…¥å’Œæ•°æ®åŠ è½½é—®é¢˜ï¼Œç¡®ä¿ä½¿ç”¨çœŸå®æ•°æ®
"""

import sys
import os
import json
import time
from pathlib import Path
import warnings
import numpy as np
import pandas as pd
from collections import Counter
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from tqdm import tqdm
import pickle

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_file = Path(__file__).resolve()
code_root = current_file.parent.parent
sys.path.append(str(code_root))

print("ğŸ§  MR2ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒæ¼”ç¤º")
print("="*50)

class TextDataset(Dataset):
    """æ–‡æœ¬æ•°æ®é›†ç±»"""
    
    def __init__(self, texts, labels, vocab, max_length=128):
        self.texts = texts
        self.labels = labels
        self.vocab = vocab
        self.max_length = max_length
        
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]
        
        # ç®€å•åˆ†è¯
        tokens = text.lower().split()
        
        # è½¬æ¢ä¸ºç´¢å¼•
        indices = [self.vocab.get(token, self.vocab.get('<UNK>', 1)) for token in tokens]
        
        # æˆªæ–­æˆ–å¡«å……
        if len(indices) > self.max_length:
            indices = indices[:self.max_length]
        else:
            indices.extend([self.vocab.get('<PAD>', 0)] * (self.max_length - len(indices)))
        
        return {
            'input_ids': torch.tensor(indices, dtype=torch.long),
            'labels': torch.tensor(label, dtype=torch.long),
            'attention_mask': torch.tensor([1 if i != 0 else 0 for i in indices], dtype=torch.long)
        }

class TextCNN(nn.Module):
    """TextCNNæ¨¡å‹"""
    
    def __init__(self, vocab_size, embedding_dim=128, filter_sizes=[3, 4, 5], 
                 num_filters=64, num_classes=3, dropout=0.5):
        super(TextCNN, self).__init__()
        
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        
        self.convs = nn.ModuleList([
            nn.Conv1d(embedding_dim, num_filters, kernel_size=k)
            for k in filter_sizes
        ])
        
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)
        
    def forward(self, input_ids, attention_mask=None):
        embedded = self.embedding(input_ids)
        embedded = embedded.transpose(1, 2)
        
        conv_outputs = []
        for conv in self.convs:
            conv_out = F.relu(conv(embedded))
            pooled = F.max_pool1d(conv_out, conv_out.size(2)).squeeze(2)
            conv_outputs.append(pooled)
        
        concatenated = torch.cat(conv_outputs, dim=1)
        output = self.dropout(concatenated)
        logits = self.fc(output)
        
        return logits

class BiLSTM(nn.Module):
    """åŒå‘LSTMæ¨¡å‹"""
    
    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=64, 
                 num_layers=2, num_classes=3, dropout=0.5):
        super(BiLSTM, self).__init__()
        
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.lstm = nn.LSTM(
            embedding_dim, hidden_dim, num_layers,
            bidirectional=True, dropout=dropout if num_layers > 1 else 0,
            batch_first=True
        )
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim * 2, num_classes)
        
    def forward(self, input_ids, attention_mask=None):
        embedded = self.embedding(input_ids)
        lstm_out, (hidden, cell) = self.lstm(embedded)
        
        if attention_mask is not None:
            lengths = attention_mask.sum(dim=1) - 1
            lengths = lengths.clamp(min=0)
            batch_size = lstm_out.size(0)
            last_outputs = lstm_out[range(batch_size), lengths]
        else:
            last_outputs = lstm_out[:, -1, :]
        
        output = self.dropout(last_outputs)
        logits = self.fc(output)
        
        return logits

class TextRCNN(nn.Module):
    """Text-RCNNæ¨¡å‹"""
    
    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=64, 
                 num_classes=3, dropout=0.5):
        super(TextRCNN, self).__init__()
        
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)
        self.context_weight = nn.Linear(hidden_dim * 2 + embedding_dim, hidden_dim)
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim, num_classes)
        
    def forward(self, input_ids, attention_mask=None):
        embedded = self.embedding(input_ids)
        lstm_out, _ = self.lstm(embedded)
        combined = torch.cat([embedded, lstm_out], dim=2)
        context = torch.tanh(self.context_weight(combined))
        pooled = F.max_pool1d(context.transpose(1, 2), context.size(1)).squeeze(2)
        output = self.dropout(pooled)
        logits = self.fc(output)
        
        return logits

def check_real_data():
    """æ£€æŸ¥çœŸå®æ•°æ®æ˜¯å¦å­˜åœ¨"""
    print("\nğŸ“ æ£€æŸ¥çœŸå®æ•°æ®æ–‡ä»¶...")
    
    data_dir = code_root / "data"
    required_files = [
        "dataset_items_train.json",
        "dataset_items_val.json", 
        "dataset_items_test.json"
    ]
    
    existing_files = []
    
    for file_name in required_files:
        file_path = data_dir / file_name
        if file_path.exists():
            file_size = file_path.stat().st_size
            existing_files.append((file_name, file_size))
            print(f"   âœ… {file_name} ({file_size/1024:.1f} KB)")
        else:
            print(f"   âŒ {file_name} - æ–‡ä»¶ä¸å­˜åœ¨")
            return False
    
    print(f"\nâœ… æ‰€æœ‰æ•°æ®æ–‡ä»¶å°±ç»ª! å…± {len(existing_files)} ä¸ªæ–‡ä»¶")
    return True

def load_real_mr2_data():
    """ç›´æ¥åŠ è½½çœŸå®MR2æ•°æ®"""
    print("\nğŸ“š åŠ è½½çœŸå®MR2æ•°æ®...")
    
    data_dir = code_root / "data"
    datasets = {}
    total_samples = 0
    
    for split in ['train', 'val', 'test']:
        file_path = data_dir / f'dataset_items_{split}.json'
        
        print(f"ğŸ“‚ è¯»å– {split} æ•°æ®: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        texts = []
        labels = []
        
        for item_id, item_data in raw_data.items():
            if 'caption' in item_data and 'label' in item_data:
                text = item_data['caption']
                if isinstance(text, str) and text.strip():
                    texts.append(text.strip())
                    labels.append(item_data['label'])
        
        datasets[split] = (texts, labels)
        total_samples += len(texts)
        
        # æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒ
        label_dist = Counter(labels)
        print(f"   âœ… {split}: {len(texts)} æ ·æœ¬")
        print(f"   ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ: {dict(label_dist)}")
    
    print(f"\nğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}")
    return datasets

def preprocess_text(text):
    """ç®€å•æ–‡æœ¬é¢„å¤„ç†"""
    import re
    
    if not isinstance(text, str):
        return ""
    
    # åŸºæœ¬æ¸…ç†
    text = re.sub(r'http\S+', '', text)  # ç§»é™¤URL
    text = re.sub(r'@\w+', '', text)     # ç§»é™¤@æåŠ
    text = re.sub(r'#\w+', '', text)     # ç§»é™¤#æ ‡ç­¾
    text = re.sub(r'\s+', ' ', text)     # æ ‡å‡†åŒ–ç©ºç™½
    text = text.strip().lower()
    
    return text

def build_vocabulary(texts, min_freq=2, max_vocab_size=5000):
    """æ„å»ºè¯æ±‡è¡¨"""
    print("ğŸ“– æ„å»ºè¯æ±‡è¡¨...")
    
    word_freq = Counter()
    for text in texts:
        processed_text = preprocess_text(text)
        words = processed_text.split()
        word_freq.update(words)
    
    # æŒ‰é¢‘ç‡æ’åº
    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
    
    vocab = {'<PAD>': 0, '<UNK>': 1}
    for word, freq in sorted_words:
        if freq >= min_freq and len(vocab) < max_vocab_size:
            vocab[word] = len(vocab)
    
    print(f"âœ… è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
    return vocab

def train_single_model(model, train_loader, val_loader, device, epochs=10, learning_rate=0.001):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    train_losses = []
    val_accuracies = []
    best_val_acc = 0
    best_model_state = None
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0
        
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]", leave=False)
        for batch in train_pbar:
            input_ids = batch['input_ids'].to(device)
            labels = batch['labels'].to(device)
            attention_mask = batch.get('attention_mask', None)
            if attention_mask is not None:
                attention_mask = attention_mask.to(device)
            
            optimizer.zero_grad()
            
            logits = model(input_ids, attention_mask)
            loss = criterion(logits, labels)
            
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(logits.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()
            
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{100*train_correct/train_total:.2f}%'
            })
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_correct = 0
        val_total = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(device)
                labels = batch['labels'].to(device)
                attention_mask = batch.get('attention_mask', None)
                if attention_mask is not None:
                    attention_mask = attention_mask.to(device)
                
                logits = model(input_ids, attention_mask)
                _, predicted = torch.max(logits.data, 1)
                
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()
                
                all_preds.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        train_acc = 100 * train_correct / train_total
        val_acc = 100 * val_correct / val_total
        avg_train_loss = train_loss / len(train_loader)
        
        train_losses.append(avg_train_loss)
        val_accuracies.append(val_acc)
        
        print(f"Epoch {epoch+1}/{epochs}: "
              f"Train Loss: {avg_train_loss:.4f}, "
              f"Train Acc: {train_acc:.2f}%, "
              f"Val Acc: {val_acc:.2f}%")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
    
    # æ¢å¤æœ€ä½³æ¨¡å‹
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    # è®¡ç®—æœ€ç»ˆéªŒè¯é›†F1åˆ†æ•°
    val_f1 = f1_score(all_labels, all_preds, average='macro')
    
    return {
        'best_val_accuracy': best_val_acc,
        'val_f1_score': val_f1,
        'train_losses': train_losses,
        'val_accuracies': val_accuracies
    }

def evaluate_model(model, test_loader, device):
    """è¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½"""
    model.eval()
    
    test_correct = 0
    test_total = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Testing"):
            input_ids = batch['input_ids'].to(device)
            labels = batch['labels'].to(device)
            attention_mask = batch.get('attention_mask', None)
            if attention_mask is not None:
                attention_mask = attention_mask.to(device)
            
            logits = model(input_ids, attention_mask)
            _, predicted = torch.max(logits.data, 1)
            
            test_total += labels.size(0)
            test_correct += (predicted == labels).sum().item()
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    test_acc = 100 * test_correct / test_total
    test_f1 = f1_score(all_labels, all_preds, average='macro')
    
    # åˆ†ç±»æŠ¥å‘Š
    label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
    report = classification_report(
        all_labels, all_preds,
        target_names=list(label_mapping.values()),
        output_dict=True
    )
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    
    return {
        'test_accuracy': test_acc,
        'test_f1_score': test_f1,
        'classification_report': report,
        'confusion_matrix': cm.tolist()
    }

def train_neural_networks(datasets):
    """è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹"""
    print("\nğŸ§  å¼€å§‹è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹...")
    
    # æ£€æµ‹è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    if device.type == "cuda":
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"   GPU: {gpu_name}")
        print(f"   æ˜¾å­˜: {gpu_memory:.1f} GB")
    
    # å‡†å¤‡æ•°æ®
    train_texts, train_labels = datasets['train']
    val_texts, val_labels = datasets['val']
    test_texts, test_labels = datasets['test']
    
    # é¢„å¤„ç†æ–‡æœ¬
    print("ğŸ”§ é¢„å¤„ç†æ–‡æœ¬æ•°æ®...")
    train_texts = [preprocess_text(text) for text in train_texts]
    val_texts = [preprocess_text(text) for text in val_texts]
    test_texts = [preprocess_text(text) for text in test_texts]
    
    # æ„å»ºè¯æ±‡è¡¨
    all_texts = train_texts + val_texts + test_texts
    vocab = build_vocabulary(train_texts, min_freq=2, max_vocab_size=3000)
    
    print(f"âœ… é¢„å¤„ç†å®Œæˆ")
    print(f"   è®­ç»ƒé›†: {len(train_texts)} æ ·æœ¬")
    print(f"   éªŒè¯é›†: {len(val_texts)} æ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {len(test_texts)} æ ·æœ¬")
    print(f"   è¯æ±‡è¡¨å¤§å°: {len(vocab)}")
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    max_length = 64  # é€‚ä¸­çš„åºåˆ—é•¿åº¦
    batch_size = 16
    
    train_dataset = TextDataset(train_texts, train_labels, vocab, max_length)
    val_dataset = TextDataset(val_texts, val_labels, vocab, max_length)
    test_dataset = TextDataset(test_texts, test_labels, vocab, max_length)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    # å®šä¹‰æ¨¡å‹
    vocab_size = len(vocab)
    models = {
        'TextCNN': TextCNN(vocab_size=vocab_size, embedding_dim=128, num_filters=64, num_classes=3),
        'BiLSTM': BiLSTM(vocab_size=vocab_size, embedding_dim=128, hidden_dim=64, num_classes=3),
        'TextRCNN': TextRCNN(vocab_size=vocab_size, embedding_dim=128, hidden_dim=64, num_classes=3)
    }
    
    # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡å¹¶æ˜¾ç¤ºå‚æ•°é‡
    for name, model in models.items():
        model.to(device)
        param_count = sum(p.numel() for p in model.parameters())
        print(f"   {name}: {param_count:,} å‚æ•°")
    
    results = {}
    
    # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
    for model_name, model in models.items():
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒæ¨¡å‹: {model_name}")
        print(f"{'='*60}")
        
        start_time = time.time()
        
        # è®­ç»ƒæ¨¡å‹
        train_result = train_single_model(
            model, train_loader, val_loader, device,
            epochs=12, learning_rate=0.001
        )
        
        # æµ‹è¯•è¯„ä¼°
        test_result = evaluate_model(model, test_loader, device)
        
        training_time = time.time() - start_time
        
        # åˆå¹¶ç»“æœ
        results[model_name] = {
            **train_result,
            **test_result,
            'training_time': training_time,
            'model_parameters': sum(p.numel() for p in model.parameters())
        }
        
        print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ (è€—æ—¶: {training_time:.1f}ç§’)")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {train_result['best_val_accuracy']:.2f}%")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {test_result['test_accuracy']:.2f}%")
        print(f"   æµ‹è¯•F1åˆ†æ•°: {test_result['test_f1_score']:.4f}")
    
    return results, vocab, models

def save_results(results, vocab, models):
    """ä¿å­˜è®­ç»ƒç»“æœ"""
    print("\nğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = code_root / 'outputs' / 'neural_network_demo'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜è¯æ±‡è¡¨
    vocab_file = output_dir / 'vocabulary.pkl'
    with open(vocab_file, 'wb') as f:
        pickle.dump(vocab, f)
    print(f"âœ… ä¿å­˜è¯æ±‡è¡¨: {vocab_file}")
    
    # ä¿å­˜æ¨¡å‹
    for model_name, model in models.items():
        model_file = output_dir / f'{model_name.lower()}_model.pth'
        torch.save(model.state_dict(), model_file)
        print(f"âœ… ä¿å­˜æ¨¡å‹: {model_file}")
    
    # ä¿å­˜ç»“æœJSON
    results_file = output_dir / 'training_results.json'
    
    # è½¬æ¢numpyç±»å‹ä¸ºå¯åºåˆ—åŒ–ç±»å‹
    serializable_results = {}
    for model_name, result in results.items():
        serializable_result = {}
        for key, value in result.items():
            if isinstance(value, (list, np.ndarray)):
                serializable_result[key] = list(value) if hasattr(value, 'tolist') else value
            else:
                serializable_result[key] = value
        serializable_results[model_name] = serializable_result
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(serializable_results, f, indent=2, ensure_ascii=False)
    print(f"âœ… ä¿å­˜ç»“æœ: {results_file}")
    
    # ä¿å­˜CSVæ¯”è¾ƒ
    comparison_data = []
    for model_name, result in results.items():
        comparison_data.append({
            'Model': model_name,
            'Val_Accuracy': result['best_val_accuracy'],
            'Test_Accuracy': result['test_accuracy'],
            'Val_F1': result['val_f1_score'],
            'Test_F1': result['test_f1_score'],
            'Parameters': result['model_parameters'],
            'Training_Time': result['training_time']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    comparison_file = output_dir / 'model_comparison.csv'
    comparison_df.to_csv(comparison_file, index=False)
    print(f"âœ… ä¿å­˜æ¯”è¾ƒ: {comparison_file}")
    
    return output_dir

def display_final_results(results):
    """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
    print(f"\nğŸ“Š {'='*80}")
    print("ç¥ç»ç½‘ç»œæ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print(f"{'='*80}")
    
    print(f"{'æ¨¡å‹':<12} {'éªŒè¯å‡†ç¡®ç‡':<10} {'æµ‹è¯•å‡†ç¡®ç‡':<10} {'éªŒè¯F1':<8} {'æµ‹è¯•F1':<8} {'å‚æ•°é‡':<10} {'è®­ç»ƒæ—¶é—´':<10}")
    print("-" * 80)
    
    # æŒ‰æµ‹è¯•F1åˆ†æ•°æ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]['test_f1_score'], reverse=True)
    
    for model_name, result in sorted_results:
        print(f"{model_name:<12} "
              f"{result['best_val_accuracy']:<10.2f} "
              f"{result['test_accuracy']:<10.2f} "
              f"{result['val_f1_score']:<8.4f} "
              f"{result['test_f1_score']:<8.4f} "
              f"{result['model_parameters']:<10,} "
              f"{result['training_time']:<10.1f}")
    
    # æœ€ä½³æ¨¡å‹
    best_model_name, best_result = sorted_results[0]
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}")
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_result['test_accuracy']:.2f}%")
    print(f"   æµ‹è¯•F1åˆ†æ•°: {best_result['test_f1_score']:.4f}")
    print(f"   è®­ç»ƒæ—¶é—´: {best_result['training_time']:.1f}ç§’")
    
    # æ˜¾ç¤ºè¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print(f"\nğŸ“‹ {best_model_name} è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    report = best_result['classification_report']
    
    label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
    
    print(f"{'ç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'æ”¯æŒæ•°':<8}")
    print("-" * 50)
    
    for i, label_name in label_mapping.items():
        if str(i) in report:
            metrics = report[str(i)]
            print(f"{label_name:<12} "
                  f"{metrics['precision']:<8.3f} "
                  f"{metrics['recall']:<8.3f} "
                  f"{metrics['f1-score']:<8.3f} "
                  f"{int(metrics['support']):<8}")
    
    # æ€»ä½“æŒ‡æ ‡
    if 'macro avg' in report:
        macro_avg = report['macro avg']
        print("-" * 50)
        print(f"{'Macro Avg':<12} "
              f"{macro_avg['precision']:<8.3f} "
              f"{macro_avg['recall']:<8.3f} "
              f"{macro_avg['f1-score']:<8.3f} "
              f"{int(macro_avg['support']):<8}")

def analyze_results(results):
    """åˆ†æç»“æœå¹¶æä¾›å»ºè®®"""
    print(f"\nğŸ” ç»“æœåˆ†æ:")
    
    # è·å–æ‰€æœ‰F1åˆ†æ•°
    f1_scores = [result['test_f1_score'] for result in results.values()]
    avg_f1 = np.mean(f1_scores)
    std_f1 = np.std(f1_scores)
    
    print(f"   å¹³å‡æµ‹è¯•F1åˆ†æ•°: {avg_f1:.4f} (Â±{std_f1:.4f})")
    
    if avg_f1 > 0.8:
        print("   ğŸ‰ æ•´ä½“æ€§èƒ½ä¼˜ç§€!")
    elif avg_f1 > 0.7:
        print("   ğŸ‘ æ•´ä½“æ€§èƒ½è‰¯å¥½!")
    elif avg_f1 > 0.6:
        print("   ğŸ’¡ æ€§èƒ½ä¸­ç­‰ï¼Œæœ‰æå‡ç©ºé—´")
    else:
        print("   âš ï¸  æ€§èƒ½è¾ƒä½ï¼Œéœ€è¦ä¼˜åŒ–")
    
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if avg_f1 < 0.8:
        print("   1. å¢åŠ è®­ç»ƒè½®æ•°")
        print("   2. è°ƒæ•´å­¦ä¹ ç‡å’Œæ‰¹æ¬¡å¤§å°") 
        print("   3. ä½¿ç”¨é¢„è®­ç»ƒè¯åµŒå…¥ (Word2Vec, GloVe)")
        print("   4. å°è¯•æ›´æ·±çš„ç½‘ç»œç»“æ„")
        print("   5. æ·»åŠ æ­£åˆ™åŒ–æŠ€æœ¯ (BatchNorm, LayerNorm)")
    
    print("   6. å°è¯•é¢„è®­ç»ƒTransformeræ¨¡å‹ (BERT, RoBERTa)")
    print("   7. å®éªŒå¤šæ¨¡æ€èåˆ (æ–‡æœ¬+å›¾åƒ)")

def main():
    """ä¸»å‡½æ•°"""
    print("æ¬¢è¿ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒæ¼”ç¤º!")
    print("æœ¬æ¼”ç¤ºå°†ä½¿ç”¨çœŸå®MR2æ•°æ®è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹\n")
    
    # 1. æ£€æŸ¥æ•°æ®
    if not check_real_data():
        print("âŒ è¯·ç¡®ä¿çœŸå®æ•°æ®æ–‡ä»¶å­˜åœ¨äº data/ ç›®å½•")
        return
    
    # 2. åŠ è½½çœŸå®æ•°æ®
    datasets = load_real_mr2_data()
    
    # 3. è®­ç»ƒæ¨¡å‹
    start_time = time.time()
    results, vocab, models = train_neural_networks(datasets)
    total_time = time.time() - start_time
    
    # 4. ä¿å­˜ç»“æœ
    output_dir = save_results(results, vocab, models)
    
    # 5. æ˜¾ç¤ºç»“æœ
    display_final_results(results)
    
    # 6. åˆ†æç»“æœ
    analyze_results(results)
    
    # 7. æ€»ç»“
    print(f"\nğŸ‰ === ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒå®Œæˆ ===")
    print(f"âœ… æ€»è®­ç»ƒæ—¶é—´: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
    print(f"âœ… å…±è®­ç»ƒ {len(models)} ä¸ªæ¨¡å‹")
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("   1. æŸ¥çœ‹ç”Ÿæˆçš„CSVæ–‡ä»¶åˆ†æè¯¦ç»†ç»“æœ")
    print("   2. å°è¯•è°ƒæ•´è¶…å‚æ•°æå‡æ€§èƒ½")
    print("   3. ä¸ä¼ ç»ŸMLæ¨¡å‹ç»“æœè¿›è¡Œå¯¹æ¯”")
    print("   4. å®éªŒé¢„è®­ç»ƒæ¨¡å‹å’Œå¤šæ¨¡æ€èåˆ")

if __name__ == "__main__":
    main()