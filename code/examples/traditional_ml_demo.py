#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# examples/traditional_ml_demo.py

"""
ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ¼”ç¤º - ä¿®å¤ç‰ˆæœ¬
ä¸“é—¨é’ˆå¯¹ä¼ ç»ŸMLæ¨¡å‹çš„è®­ç»ƒï¼Œä½¿ç”¨çœŸå®MR2æ•°æ®
ä¿®å¤äº†æ¨¡å—å¯¼å…¥å’Œæ•°æ®åŠ è½½é—®é¢˜
"""

import sys
import os
import json
import time
from pathlib import Path
import warnings
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import pickle

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_file = Path(__file__).resolve()
code_root = current_file.parent.parent
sys.path.append(str(code_root))

print("ğŸ¤– MR2ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ¼”ç¤º")
print("="*50)

def check_real_data():
    """æ£€æŸ¥çœŸå®æ•°æ®æ˜¯å¦å­˜åœ¨"""
    print("\nğŸ“ æ£€æŸ¥çœŸå®æ•°æ®æ–‡ä»¶...")
    
    data_dir = code_root / "data"
    required_files = [
        "dataset_items_train.json",
        "dataset_items_val.json", 
        "dataset_items_test.json"
    ]
    
    existing_files = []
    
    for file_name in required_files:
        file_path = data_dir / file_name
        if file_path.exists():
            file_size = file_path.stat().st_size
            existing_files.append((file_name, file_size))
            print(f"   âœ… {file_name} ({file_size/1024:.1f} KB)")
        else:
            print(f"   âŒ {file_name} - æ–‡ä»¶ä¸å­˜åœ¨")
            return False
    
    print(f"\nâœ… æ‰€æœ‰æ•°æ®æ–‡ä»¶å°±ç»ª! å…± {len(existing_files)} ä¸ªæ–‡ä»¶")
    return True

def load_real_mr2_data():
    """ç›´æ¥åŠ è½½çœŸå®MR2æ•°æ®"""
    print("\nğŸ“š åŠ è½½çœŸå®MR2æ•°æ®...")
    
    data_dir = code_root / "data"
    
    # ç›´æ¥è¯»å–JSONæ–‡ä»¶
    datasets = {}
    total_samples = 0
    
    for split in ['train', 'val', 'test']:
        file_path = data_dir / f'dataset_items_{split}.json'
        
        print(f"ğŸ“‚ è¯»å– {split} æ•°æ®: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        # æå–æ–‡æœ¬å’Œæ ‡ç­¾
        texts = []
        labels = []
        
        for item_id, item_data in raw_data.items():
            if 'caption' in item_data and 'label' in item_data:
                texts.append(item_data['caption'])
                labels.append(item_data['label'])
        
        datasets[split] = (texts, labels)
        total_samples += len(texts)
        
        print(f"   âœ… {split}: {len(texts)} æ ·æœ¬")
        
        # æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒ
        from collections import Counter
        label_dist = Counter(labels)
        print(f"   ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ: {dict(label_dist)}")
    
    print(f"\nğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}")
    return datasets

def preprocess_text_simple(text):
    """ç®€å•æ–‡æœ¬é¢„å¤„ç†"""
    if not isinstance(text, str):
        return ""
    
    # åŸºæœ¬æ¸…ç†
    import re
    text = re.sub(r'http\S+', '', text)  # ç§»é™¤URL
    text = re.sub(r'@\w+', '', text)     # ç§»é™¤@æåŠ
    text = re.sub(r'#\w+', '', text)     # ç§»é™¤#æ ‡ç­¾
    text = re.sub(r'\s+', ' ', text)     # æ ‡å‡†åŒ–ç©ºç™½
    text = text.strip().lower()
    
    return text

def train_traditional_models(datasets):
    """è®­ç»ƒä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹"""
    print("\nğŸ¤– å¼€å§‹è®­ç»ƒä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹...")
    
    # åˆå¹¶æ•°æ®
    train_texts, train_labels = datasets['train']
    val_texts, val_labels = datasets['val']
    test_texts, test_labels = datasets['test']
    
    # é¢„å¤„ç†æ–‡æœ¬
    print("ğŸ”§ é¢„å¤„ç†æ–‡æœ¬æ•°æ®...")
    train_texts = [preprocess_text_simple(text) for text in train_texts]
    val_texts = [preprocess_text_simple(text) for text in val_texts]
    test_texts = [preprocess_text_simple(text) for text in test_texts]
    
    # ç‰¹å¾æå–
    print("ğŸ”§ æå–TF-IDFç‰¹å¾...")
    vectorizer = TfidfVectorizer(
        max_features=5000,
        ngram_range=(1, 2),
        min_df=2,
        max_df=0.95,
        stop_words=None  # ä¿ç•™åœç”¨è¯ï¼Œå› ä¸ºæ˜¯å¤šè¯­è¨€
    )
    
    # è®­ç»ƒç‰¹å¾æå–å™¨
    X_train = vectorizer.fit_transform(train_texts)
    X_val = vectorizer.transform(val_texts)
    X_test = vectorizer.transform(test_texts)
    
    print(f"âœ… ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")
    print(f"âœ… è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"âœ… éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
    print(f"âœ… æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    
    # è½¬æ¢æ ‡ç­¾
    y_train = np.array(train_labels)
    y_val = np.array(val_labels)
    y_test = np.array(test_labels)
    
    # å®šä¹‰æ¨¡å‹
    models = {
        'SVM': SVC(kernel='rbf', C=1.0, probability=True, random_state=42),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'Naive Bayes': MultinomialNB(alpha=1.0),
        'Logistic Regression': LogisticRegression(C=1.0, max_iter=1000, random_state=42)
    }
    
    results = {}
    label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
    
    # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
    for model_name, model in models.items():
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒæ¨¡å‹: {model_name}")
        print(f"{'='*60}")
        
        start_time = time.time()
        
        # è®­ç»ƒ
        print(f"ğŸ‹ï¸ å¼€å§‹è®­ç»ƒ {model_name}...")
        model.fit(X_train, y_train)
        
        training_time = time.time() - start_time
        
        # é¢„æµ‹
        train_pred = model.predict(X_train)
        val_pred = model.predict(X_val)
        test_pred = model.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        train_acc = accuracy_score(y_train, train_pred)
        val_acc = accuracy_score(y_val, val_pred)
        test_acc = accuracy_score(y_test, test_pred)
        
        train_f1 = f1_score(y_train, train_pred, average='macro')
        val_f1 = f1_score(y_val, val_pred, average='macro')
        test_f1 = f1_score(y_test, test_pred, average='macro')
        
        # è¯¦ç»†æŠ¥å‘Š
        test_report = classification_report(
            y_test, test_pred,
            target_names=list(label_mapping.values()),
            output_dict=True
        )
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_test, test_pred)
        
        results[model_name] = {
            'train_accuracy': train_acc,
            'val_accuracy': val_acc,
            'test_accuracy': test_acc,
            'train_f1': train_f1,
            'val_f1': val_f1,
            'test_f1': test_f1,
            'training_time': training_time,
            'classification_report': test_report,
            'confusion_matrix': cm.tolist()
        }
        
        print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ (è€—æ—¶: {training_time:.2f}ç§’)")
        print(f"   è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        print(f"   æµ‹è¯•F1åˆ†æ•°: {test_f1:.4f}")
    
    return results, vectorizer, models

def save_results(results, vectorizer, models):
    """ä¿å­˜è®­ç»ƒç»“æœ"""
    print("\nğŸ’¾ ä¿å­˜è®­ç»ƒç»“æœ...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = code_root / 'outputs' / 'traditional_ml_demo'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ¨¡å‹
    for model_name, model in models.items():
        model_file = output_dir / f'{model_name.lower().replace(" ", "_")}_model.pkl'
        with open(model_file, 'wb') as f:
            pickle.dump(model, f)
        print(f"âœ… ä¿å­˜æ¨¡å‹: {model_file}")
    
    # ä¿å­˜ç‰¹å¾æå–å™¨
    vectorizer_file = output_dir / 'tfidf_vectorizer.pkl'
    with open(vectorizer_file, 'wb') as f:
        pickle.dump(vectorizer, f)
    print(f"âœ… ä¿å­˜ç‰¹å¾æå–å™¨: {vectorizer_file}")
    
    # ä¿å­˜ç»“æœJSON
    results_file = output_dir / 'training_results.json'
    
    # è½¬æ¢numpyç±»å‹ä¸ºå¯åºåˆ—åŒ–ç±»å‹
    serializable_results = {}
    for model_name, result in results.items():
        serializable_result = {}
        for key, value in result.items():
            if isinstance(value, np.ndarray):
                serializable_result[key] = value.tolist()
            else:
                serializable_result[key] = value
        serializable_results[model_name] = serializable_result
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(serializable_results, f, indent=2, ensure_ascii=False)
    print(f"âœ… ä¿å­˜ç»“æœ: {results_file}")
    
    # ä¿å­˜CSVæ¯”è¾ƒ
    comparison_data = []
    for model_name, result in results.items():
        comparison_data.append({
            'Model': model_name,
            'Train_Accuracy': result['train_accuracy'],
            'Val_Accuracy': result['val_accuracy'],
            'Test_Accuracy': result['test_accuracy'],
            'Train_F1': result['train_f1'],
            'Val_F1': result['val_f1'],
            'Test_F1': result['test_f1'],
            'Training_Time': result['training_time']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    comparison_file = output_dir / 'model_comparison.csv'
    comparison_df.to_csv(comparison_file, index=False)
    print(f"âœ… ä¿å­˜æ¯”è¾ƒ: {comparison_file}")
    
    return output_dir

def display_final_results(results):
    """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
    print(f"\nğŸ“Š {'='*80}")
    print("ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print(f"{'='*80}")
    
    print(f"{'æ¨¡å‹':<18} {'è®­ç»ƒå‡†ç¡®ç‡':<10} {'éªŒè¯å‡†ç¡®ç‡':<10} {'æµ‹è¯•å‡†ç¡®ç‡':<10} {'æµ‹è¯•F1':<10} {'è®­ç»ƒæ—¶é—´':<10}")
    print("-" * 80)
    
    # æŒ‰æµ‹è¯•F1åˆ†æ•°æ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]['test_f1'], reverse=True)
    
    for model_name, result in sorted_results:
        print(f"{model_name:<18} "
              f"{result['train_accuracy']:<10.4f} "
              f"{result['val_accuracy']:<10.4f} "
              f"{result['test_accuracy']:<10.4f} "
              f"{result['test_f1']:<10.4f} "
              f"{result['training_time']:<10.2f}")
    
    # æœ€ä½³æ¨¡å‹
    best_model_name, best_result = sorted_results[0]
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}")
    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_result['test_accuracy']:.4f}")
    print(f"   æµ‹è¯•F1åˆ†æ•°: {best_result['test_f1']:.4f}")
    print(f"   è®­ç»ƒæ—¶é—´: {best_result['training_time']:.2f}ç§’")
    
    # æ˜¾ç¤ºè¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print(f"\nğŸ“‹ {best_model_name} è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    report = best_result['classification_report']
    
    label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
    
    print(f"{'ç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'æ”¯æŒæ•°':<8}")
    print("-" * 50)
    
    for i, label_name in label_mapping.items():
        if str(i) in report:
            metrics = report[str(i)]
            print(f"{label_name:<12} "
                  f"{metrics['precision']:<8.3f} "
                  f"{metrics['recall']:<8.3f} "
                  f"{metrics['f1-score']:<8.3f} "
                  f"{int(metrics['support']):<8}")
    
    # æ€»ä½“æŒ‡æ ‡
    if 'macro avg' in report:
        macro_avg = report['macro avg']
        print("-" * 50)
        print(f"{'Macro Avg':<12} "
              f"{macro_avg['precision']:<8.3f} "
              f"{macro_avg['recall']:<8.3f} "
              f"{macro_avg['f1-score']:<8.3f} "
              f"{int(macro_avg['support']):<8}")

def analyze_results(results):
    """åˆ†æç»“æœå¹¶æä¾›å»ºè®®"""
    print(f"\nğŸ” ç»“æœåˆ†æ:")
    
    # è·å–æ‰€æœ‰F1åˆ†æ•°
    f1_scores = [result['test_f1'] for result in results.values()]
    avg_f1 = np.mean(f1_scores)
    std_f1 = np.std(f1_scores)
    
    print(f"   å¹³å‡æµ‹è¯•F1åˆ†æ•°: {avg_f1:.4f} (Â±{std_f1:.4f})")
    
    if avg_f1 > 0.8:
        print("   ğŸ‰ æ•´ä½“æ€§èƒ½ä¼˜ç§€!")
    elif avg_f1 > 0.7:
        print("   ğŸ‘ æ•´ä½“æ€§èƒ½è‰¯å¥½!")
    elif avg_f1 > 0.6:
        print("   ğŸ’¡ æ€§èƒ½ä¸­ç­‰ï¼Œæœ‰æå‡ç©ºé—´")
    else:
        print("   âš ï¸  æ€§èƒ½è¾ƒä½ï¼Œéœ€è¦ä¼˜åŒ–")
    
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if avg_f1 < 0.8:
        print("   1. å°è¯•æ›´å¤æ‚çš„ç‰¹å¾å·¥ç¨‹ (N-gram, Word2Vec)")
        print("   2. ä½¿ç”¨è¶…å‚æ•°è°ƒä¼˜")
        print("   3. å°è¯•é›†æˆæ–¹æ³•")
        print("   4. å¢åŠ æ•°æ®é¢„å¤„ç†æ­¥éª¤")
    
    print("   5. è€ƒè™‘ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹")
    print("   6. æ·»åŠ å¤šæ¨¡æ€ç‰¹å¾ (å›¾åƒ+æ–‡æœ¬)")

def main():
    """ä¸»å‡½æ•°"""
    print("æ¬¢è¿ä½¿ç”¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ¼”ç¤º!")
    print("æœ¬æ¼”ç¤ºå°†ä½¿ç”¨çœŸå®MR2æ•°æ®è®­ç»ƒä¼ ç»ŸMLæ¨¡å‹\n")
    
    # 1. æ£€æŸ¥æ•°æ®
    if not check_real_data():
        print("âŒ è¯·ç¡®ä¿çœŸå®æ•°æ®æ–‡ä»¶å­˜åœ¨äº data/ ç›®å½•")
        return
    
    # 2. åŠ è½½çœŸå®æ•°æ®
    datasets = load_real_mr2_data()
    
    # 3. è®­ç»ƒæ¨¡å‹
    start_time = time.time()
    results, vectorizer, models = train_traditional_models(datasets)
    total_time = time.time() - start_time
    
    # 4. ä¿å­˜ç»“æœ
    output_dir = save_results(results, vectorizer, models)
    
    # 5. æ˜¾ç¤ºç»“æœ
    display_final_results(results)
    
    # 6. åˆ†æç»“æœ
    analyze_results(results)
    
    # 7. æ€»ç»“
    print(f"\nğŸ‰ === ä¼ ç»ŸMLæ¨¡å‹è®­ç»ƒå®Œæˆ ===")
    print(f"âœ… æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f}ç§’")
    print(f"âœ… å…±è®­ç»ƒ {len(models)} ä¸ªæ¨¡å‹")
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("   1. æŸ¥çœ‹ç”Ÿæˆçš„CSVæ–‡ä»¶åˆ†æè¯¦ç»†ç»“æœ")
    print("   2. å°è¯•è°ƒæ•´è¶…å‚æ•°æå‡æ€§èƒ½")
    print("   3. è¿è¡Œç¥ç»ç½‘ç»œæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
    print("   4. å®éªŒå¤šæ¨¡æ€èåˆæ–¹æ³•")

if __name__ == "__main__":
    main()