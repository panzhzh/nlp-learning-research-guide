# æ”¯æŒæ¨¡å‹åˆ—è¡¨ Supported Models

> ğŸ“‹ **é¡¹ç›®æ”¯æŒçš„æ‰€æœ‰æ¨¡å‹åŠå…¶å…¼å®¹æ€§ä¿¡æ¯**

## ğŸ“‹ åŠŸèƒ½è¯´æ˜

`supported_models.yaml` åˆ—å‡ºäº†é¡¹ç›®ä¸­æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬å®ç°è·¯å¾„ã€æ”¯æŒä»»åŠ¡ã€è¾“å…¥ç±»å‹ç­‰è¯¦ç»†ä¿¡æ¯ã€‚

## ğŸ¯ ä¸»è¦é…ç½®å—

### traditional_models - ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹
- **åˆ†ç±»å™¨åˆ—è¡¨**: SVM, RandomForest, NaiveBayes, LogisticRegression, XGBoost
- **å®ç°ä¿¡æ¯**: sklearn/xgboostå®ç°ï¼Œç±»è·¯å¾„
- **æ”¯æŒä»»åŠ¡**: äºŒåˆ†ç±»ã€å¤šåˆ†ç±»
- **ç‰¹å¾è¦æ±‚**: text_features

### neural_network_models - ç¥ç»ç½‘ç»œæ¨¡å‹
- **æ–‡æœ¬æ¨¡å‹**: TextCNN, BiLSTM, TextRCNN, HierarchicalAttention
- **å›¾åƒæ¨¡å‹**: ImageCNN, ResNetç³»åˆ—
- **å®ç°æ¡†æ¶**: PyTorch
- **è¾“å…¥ç±»å‹**: text, image

### pretrained_models - é¢„è®­ç»ƒæ¨¡å‹
- **æ–‡æœ¬ç¼–ç å™¨**:
  - English: BERT, RoBERTa, ALBERT, ELECTRA, DeBERTa
  - Chinese: Chinese-BERT-wwm, Chinese-RoBERTa-wwm, MacBERT, ERNIE
  - Multilingual: mBERT, XLM-RoBERTa
- **ç”Ÿæˆæ¨¡å‹**: GPT-2, T5, BART
- **æ¨¡å‹è§„æ ¼**: max_length, hidden_sizeç­‰

### multimodal_models - å¤šæ¨¡æ€æ¨¡å‹
- **è§†è§‰-è¯­è¨€æ¨¡å‹**: CLIP, Chinese-CLIP, BLIP, ALBEF, FLAVA
- **è¾“å…¥ç±»å‹**: text + image
- **å›¾åƒå°ºå¯¸**: 224x224, 384x384ç­‰
- **æ–‡æœ¬é•¿åº¦**: 77, 512ç­‰é™åˆ¶

### graph_models - å›¾ç¥ç»ç½‘ç»œæ¨¡å‹
- **åŸºç¡€GNN**: GCN, GAT, GraphSAGE, GIN
- **é«˜çº§GNN**: GraphTransformer, GraphBERT
- **å®ç°æ¡†æ¶**: torch_geometric
- **æ”¯æŒä»»åŠ¡**: node_classification, graph_classification

### large_language_models - å¤§è¯­è¨€æ¨¡å‹
- **å¼€æºLLM**: ChatGLM2-6B, Qwen-7B-Chat, Baichuan2-7B-Chat
- **å¤šæ¨¡æ€LLM**: LLaVA, BLIP-2
- **æ¨¡å‹è§„æ ¼**: å‚æ•°é‡, max_length
- **æ”¯æŒä»»åŠ¡**: chat, classification, VQA

### specialized_models - ä¸“ç”¨æ¨¡å‹
- **è°£è¨€æ£€æµ‹**: RumorDetectionTransformer
- **ç¤¾äº¤åª’ä½“**: SocialMediaBERT
- **é¢†åŸŸä¸“ç”¨**: é’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–

### ensemble_models - é›†æˆæ¨¡å‹
- **æŠ•ç¥¨é›†æˆ**: VotingClassifier
- **å †å é›†æˆ**: StackingClassifier  
- **å¤šæ¨¡æ€é›†æˆ**: MultiModalEnsemble
- **æ”¯æŒåŸºæ¨¡å‹**: ä¼ ç»Ÿã€ç¥ç»ç½‘ç»œã€é¢„è®­ç»ƒæ¨¡å‹

## ğŸ” å…¼å®¹æ€§ä¿¡æ¯

### compatibility_matrix - å…¼å®¹æ€§çŸ©é˜µ
- **ä»»åŠ¡å…¼å®¹**: classification, regression, generation, retrieval
- **è¾“å…¥ç±»å‹**: text_only, image_only, multimodal, graph
- **è¯­è¨€æ”¯æŒ**: english, chinese, mixed

### recommended_models - æ¨èæ¨¡å‹
- **åˆå­¦è€…**: LogisticRegression, BERT, CLIP
- **ä¸­çº§ç”¨æˆ·**: RoBERTa, Chinese-BERT-wwm, BLIP, GAT
- **é«˜çº§ç”¨æˆ·**: DeBERTa, ChatGLM2-6B, LLaVA, GraphTransformer

### performance_benchmarks - æ€§èƒ½åŸºå‡†
åœ¨MR2æ•°æ®é›†ä¸Šçš„é¢„æœŸæ€§èƒ½:
- **ä¼ ç»Ÿæ–¹æ³•**: SVM (65%), RandomForest (68%)
- **é¢„è®­ç»ƒæ¨¡å‹**: BERT (78%), RoBERTa (79%), Chinese-BERT-wwm (80%)
- **å¤šæ¨¡æ€**: CLIP (82%), BLIP (84%), Chinese-CLIP (83%)

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

- æŸ¥çœ‹æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
- é€‰æ‹©é€‚åˆä»»åŠ¡çš„æ¨¡å‹
- äº†è§£æ¨¡å‹å…¼å®¹æ€§å’Œé™åˆ¶
- æŸ¥çœ‹æ€§èƒ½åŸºå‡†å‚è€ƒ
- è·å–æ¨¡å‹å®ç°è·¯å¾„

---

**[â¬…ï¸ è®­ç»ƒé…ç½®](training_configs.md) | [RAGé…ç½® â¡ï¸](rag_configs.md)**
