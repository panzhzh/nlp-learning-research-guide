# é¢„å¤„ç†æ¨¡å— Preprocessing Module

> ğŸ”§ **ä¸“ä¸šçš„ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬å’Œå›¾åƒé¢„å¤„ç†å·¥å…·ï¼Œæ”¯æŒMR2å¤šæ¨¡æ€æ•°æ®**

## ğŸ“‹ æ¨¡å—æ¦‚è§ˆ

é¢„å¤„ç†æ¨¡å—æä¾›ä¸“é—¨é’ˆå¯¹MR2æ•°æ®é›†çš„æ–‡æœ¬å’Œå›¾åƒé¢„å¤„ç†åŠŸèƒ½ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆæ–‡æœ¬å¤„ç†ã€æ ‡å‡†åŒ–å›¾åƒé¢„å¤„ç†å’Œå¤šæ¨¡æ€ç‰¹å¾æå–ã€‚

## ğŸ“ æ ¸å¿ƒç»„ä»¶

### ä¸»è¦æ¨¡å—æ–‡ä»¶
| æ–‡ä»¶å | åŠŸèƒ½è¯´æ˜ | ç‰¹ç‚¹ |
|-------|----------|------|
| [**text_processing.py**](text_processing.md) | ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬é¢„å¤„ç†å™¨ | æ™ºèƒ½åˆ†è¯ã€å¤šè¯­è¨€æ£€æµ‹ã€ç‰¹å¾æå– |
| [**image_processing.py**](image_processing.md) | å›¾åƒé¢„å¤„ç†å’Œç‰¹å¾æå–å™¨ | æ ‡å‡†åŒ–å¤„ç†ã€æ•°æ®å¢å¼ºã€æ‰¹é‡å¤„ç† |
| [**demo.py**](demo.md) | é¢„å¤„ç†åŠŸèƒ½æ¼”ç¤ºè„šæœ¬ | å¿«é€Ÿæµ‹è¯•ã€åŠŸèƒ½éªŒè¯ |

### æ¨¡å—åˆå§‹åŒ– (__init__.py)
```python
from .text_processing import TextProcessor
from .image_processing import ImageProcessor

__all__ = [
    'TextProcessor',
    'ImageProcessor'
]
```

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

### å¤šè¯­è¨€æ–‡æœ¬å¤„ç†
- **ä¸­è‹±æ–‡æ··åˆ**: æ™ºèƒ½è¯†åˆ«å’Œå¤„ç†ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬
- **è¯­è¨€æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬è¯­è¨€ç±»å‹
- **æ™ºèƒ½åˆ†è¯**: jieba + NLTKè”åˆåˆ†è¯å¼•æ“
- **æ·±åº¦æ¸…æ´—**: URLã€æåŠã€emojiç­‰å™ªå£°æ¸…ç†
- **ç‰¹å¾æå–**: é•¿åº¦ã€è¯é¢‘ã€è¯­è¨€ç‰¹å¾ç­‰å¤šç»´ç‰¹å¾

### ä¸“ä¸šå›¾åƒå¤„ç†
- **æ ‡å‡†åŒ–å¤„ç†**: ImageNetæ ‡å‡†å½’ä¸€åŒ–å’Œå°ºå¯¸è°ƒæ•´
- **æ•°æ®å¢å¼º**: å¤šçº§åˆ«æ•°æ®å¢å¼ºç­–ç•¥
- **ç‰¹å¾æå–**: é¢œè‰²ã€çº¹ç†ã€å‡ ä½•ç­‰åº•å±‚ç‰¹å¾
- **æ‰¹é‡å¤„ç†**: é«˜æ•ˆçš„MR2æ•°æ®é›†æ‰¹é‡å¤„ç†
- **è´¨é‡æ§åˆ¶**: å®Œå–„çš„å›¾åƒè´¨é‡æ£€æŸ¥å’Œé”™è¯¯æ¢å¤

### é…ç½®é©±åŠ¨è®¾è®¡
- **é…ç½®é›†æˆ**: ä¸é¡¹ç›®é…ç½®ç®¡ç†å™¨æ— ç¼é›†æˆ
- **å‚æ•°åŒ–**: æ‰€æœ‰å¤„ç†å‚æ•°éƒ½å¯é€šè¿‡é…ç½®æ–‡ä»¶è°ƒæ•´
- **é»˜è®¤å…¼å®¹**: å³ä½¿æ²¡æœ‰é…ç½®æ–‡ä»¶ä¹Ÿèƒ½æ­£å¸¸å·¥ä½œ

## ğŸ¯ å¿«é€Ÿä½¿ç”¨

### æ–‡æœ¬å¤„ç†
```python
from preprocessing import TextProcessor

# åˆ›å»ºä¸­è‹±æ–‡æ··åˆæ–‡æœ¬å¤„ç†å™¨
processor = TextProcessor(language='mixed')

# æ–‡æœ¬æ¸…æ´—
text = "è¿™æ˜¯æµ‹è¯•æ–‡æœ¬ This is test! @user https://example.com ğŸ˜Š"
cleaned = processor.clean_text(text)
print(f"æ¸…æ´—å: {cleaned}")
# è¾“å‡º: "è¿™æ˜¯æµ‹è¯•æ–‡æœ¬ This is test"

# è¯­è¨€æ£€æµ‹
language = processor.detect_language(text)
print(f"è¯­è¨€ç±»å‹: {language}")  # è¾“å‡º: "mixed"

# æ™ºèƒ½åˆ†è¯
tokens = processor.tokenize(text)
print(f"åˆ†è¯ç»“æœ: {tokens}")
# è¾“å‡º: ['è¿™æ˜¯', 'æµ‹è¯•', 'æ–‡æœ¬', 'this', 'test']

# ç‰¹å¾æå–
features = processor.extract_features(text)
print(f"æ–‡æœ¬é•¿åº¦: {features['text_length']}")
print(f"è¯æ•°: {features['token_count']}")
print(f"è¯­è¨€: {features['language']}")
```

### å›¾åƒå¤„ç†
```python
from preprocessing import ImageProcessor

# åˆ›å»ºå›¾åƒå¤„ç†å™¨
processor = ImageProcessor(target_size=(224, 224))

# å¤„ç†å•å¼ å›¾åƒ
tensor = processor.process_single_image(
    image_path='data/train/img/example.jpg',
    transform_type='train'  # åŒ…å«æ•°æ®å¢å¼º
)
print(f"å›¾åƒå¼ é‡å½¢çŠ¶: {tensor.shape}")  # torch.Size([3, 224, 224])

# è·å–å›¾åƒä¿¡æ¯
info = processor.get_image_info('data/train/img/example.jpg')
print(f"å›¾åƒå°ºå¯¸: {info['width']} x {info['height']}")
print(f"æ–‡ä»¶å¤§å°: {info['file_size_mb']:.2f} MB")

# æå–å›¾åƒç‰¹å¾
image = processor.load_image('data/train/img/example.jpg')
features = processor.extract_image_features(image)
print(f"äº®åº¦: {features['brightness']:.2f}")
print(f"å¯¹æ¯”åº¦: {features['contrast']:.2f}")

# æ‰¹é‡å¤„ç†MR2æ•°æ®é›†
results = processor.process_mr2_dataset(
    splits=['train'],
    save_features=True
)
print(f"å¤„ç†å®Œæˆ: {results['train']['processed_images']} å¼ å›¾åƒ")
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### æ–‡æœ¬å¤„ç†é«˜çº§ç‰¹æ€§

#### é…ç½®é©±åŠ¨çš„å‚æ•°
```python
# ä»é…ç½®æ–‡ä»¶è‡ªåŠ¨åŠ è½½å‚æ•°
processor = TextProcessor(language='mixed')
# è‡ªåŠ¨è·å–ï¼š
# - max_length: 512
# - remove_urls: True
# - remove_mentions: True
# - normalize_whitespace: True
```

#### æ‰¹é‡æ–‡æœ¬å¤„ç†
```python
texts = [
    "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬",
    "This is the second test text",
    "æ··åˆè¯­è¨€æ–‡æœ¬ mixed language"
]

# æ‰¹é‡é¢„å¤„ç†
results = processor.preprocess_batch(texts)
for i, result in enumerate(results):
    print(f"æ–‡æœ¬{i+1}: {len(result['tokens'])} tokens")
    print(f"ç‰¹å¾: {result['features']['language']}")
```

#### è‡ªå®šä¹‰å¤„ç†é…ç½®
```python
# è‡ªå®šä¹‰æ¸…æ´—å‚æ•°
processor = TextProcessor()
processor.remove_hashtags = True  # ç§»é™¤è¯é¢˜æ ‡ç­¾
processor.remove_urls = False     # ä¿ç•™URL

cleaned = processor.clean_text(text)
```

### å›¾åƒå¤„ç†é«˜çº§ç‰¹æ€§

#### å¤šçº§æ•°æ®å¢å¼º
```python
# è½»åº¦å¢å¼ºï¼ˆ50%ç¿»è½¬ + 5åº¦æ—‹è½¬ï¼‰
light_augmented = processor.apply_augmentation(image, 'light')

# ä¸­åº¦å¢å¼ºï¼ˆç¿»è½¬ + æ—‹è½¬ + äº®åº¦è°ƒæ•´ï¼‰
medium_augmented = processor.apply_augmentation(image, 'medium')

# é‡åº¦å¢å¼ºï¼ˆå…¨å¥—å¢å¼º + é«˜æ–¯æ¨¡ç³Šï¼‰
heavy_augmented = processor.apply_augmentation(image, 'heavy')
```

#### è‡ªå®šä¹‰å˜æ¢é…ç½®
```python
import torchvision.transforms as transforms

# è‡ªå®šä¹‰è®­ç»ƒå˜æ¢
processor.train_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop((224, 224)),
    transforms.RandomHorizontalFlip(p=0.7),
    transforms.ColorJitter(brightness=0.3, contrast=0.3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])
```

#### MR2æ•°æ®é›†ä¸“ç”¨å¤„ç†
```python
# å¤„ç†å®Œæ•´çš„MR2æ•°æ®é›†
results = processor.process_mr2_dataset(
    splits=['train', 'val', 'test'],
    save_features=True
)

# åˆ›å»ºç»Ÿè®¡ä¿¡æ¯
statistics = processor.create_image_statistics(results)
print(f"æ€»å›¾åƒæ•°: {statistics['total_images']}")
print(f"å¹³å‡å°ºå¯¸: {statistics['avg_width']:.1f} x {statistics['avg_height']:.1f}")
print(f"æ ¼å¼åˆ†å¸ƒ: {statistics['format_distribution']}")
```

## ğŸ¨ ç‰¹å¾æå–

### æ–‡æœ¬ç‰¹å¾
```python
features = processor.extract_features(text)
"""
è¿”å›å®Œæ•´ç‰¹å¾å­—å…¸:
{
    'text_length': int,           # æ–‡æœ¬é•¿åº¦
    'word_count': int,            # è¯æ•°
    'char_count': int,            # å­—ç¬¦æ•°
    'language': str,              # è¯­è¨€ç±»å‹
    'tokens': List[str],          # åˆ†è¯ç»“æœ
    'token_count': int,           # tokenæ•°é‡
    'exclamation_count': int,     # æ„Ÿå¹å·æ•°é‡
    'question_count': int,        # é—®å·æ•°é‡
    'uppercase_ratio': float,     # å¤§å†™å­—æ¯æ¯”ä¾‹
    'digit_count': int,           # æ•°å­—å­—ç¬¦æ•°
    'url_count': int,             # URLæ•°é‡
    'mention_count': int,         # æåŠæ•°é‡
    'hashtag_count': int,         # è¯é¢˜æ ‡ç­¾æ•°é‡
    'emoji_count': int            # emojiæ•°é‡
}
"""
```

### å›¾åƒç‰¹å¾
```python
features = processor.extract_image_features(image)
"""
è¿”å›å›¾åƒç‰¹å¾å­—å…¸:
{
    'width': float,               # å›¾åƒå®½åº¦
    'height': float,              # å›¾åƒé«˜åº¦
    'aspect_ratio': float,        # å®½é«˜æ¯”
    'total_pixels': float,        # æ€»åƒç´ æ•°
    'mean_r': float,              # çº¢è‰²é€šé“å‡å€¼
    'mean_g': float,              # ç»¿è‰²é€šé“å‡å€¼
    'mean_b': float,              # è“è‰²é€šé“å‡å€¼
    'std_r': float,               # çº¢è‰²é€šé“æ ‡å‡†å·®
    'std_g': float,               # ç»¿è‰²é€šé“æ ‡å‡†å·®
    'std_b': float,               # è“è‰²é€šé“æ ‡å‡†å·®
    'brightness': float,          # æ•´ä½“äº®åº¦
    'contrast': float,            # å¯¹æ¯”åº¦
    'edge_density': float         # è¾¹ç¼˜å¯†åº¦
}
"""
```

## âš™ï¸ é…ç½®é›†æˆ

### é…ç½®æ–‡ä»¶æ”¯æŒ
```python
# è‡ªåŠ¨ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°
try:
    from utils.config_manager import get_data_config
    config = get_data_config()
    processing_config = config.get('processing', {})
    
    # æ–‡æœ¬å¤„ç†é…ç½®
    text_config = processing_config.get('text', {})
    self.max_length = text_config.get('max_length', 512)
    self.remove_urls = text_config.get('remove_urls', True)
    
    # å›¾åƒå¤„ç†é…ç½®
    image_config = processing_config.get('image', {})
    self.target_size = image_config.get('target_size', [224, 224])
    self.normalize_mean = image_config.get('normalize_mean', [0.485, 0.456, 0.406])
    
except ImportError:
    # æ²¡æœ‰é…ç½®ç®¡ç†å™¨æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
    pass
```

### é…ç½®å‚æ•°å¯¹åº”å…³ç³»
| é…ç½®æ–‡ä»¶å‚æ•° | åŠŸèƒ½è¯´æ˜ | é»˜è®¤å€¼ |
|-------------|----------|--------|
| `processing.text.max_length` | æœ€å¤§æ–‡æœ¬é•¿åº¦ | 512 |
| `processing.text.remove_urls` | æ˜¯å¦ç§»é™¤URL | True |
| `processing.text.tokenization` | åˆ†è¯ç±»å‹ | "mixed" |
| `processing.image.target_size` | ç›®æ ‡å›¾åƒå°ºå¯¸ | [224, 224] |
| `processing.image.normalize_mean` | å½’ä¸€åŒ–å‡å€¼ | ImageNetæ ‡å‡† |
| `processing.image.quality_threshold` | è´¨é‡é˜ˆå€¼ | 0.3 |

## ğŸ” ä¾èµ–åº“ç®¡ç†

### æ–‡æœ¬å¤„ç†ä¾èµ–
```python
# å¿…éœ€åº“
import re, string, emoji
from typing import List, Dict, Optional

# å¯é€‰åº“ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
try:
    import jieba              # ä¸­æ–‡åˆ†è¯
    HAS_JIEBA = True
except ImportError:
    HAS_JIEBA = False
    print("âš ï¸ jiebaæœªå®‰è£…ï¼Œä¸­æ–‡åˆ†è¯åŠŸèƒ½ä¸å¯ç”¨")

try:
    import nltk               # è‹±æ–‡å¤„ç†
    from nltk.corpus import stopwords
    HAS_NLTK = True
except ImportError:
    HAS_NLTK = False
    print("âš ï¸ nltkæœªå®‰è£…ï¼Œè‹±æ–‡é«˜çº§å¤„ç†åŠŸèƒ½ä¸å¯ç”¨")
```

### å›¾åƒå¤„ç†ä¾èµ–
```python
# å¿…éœ€åº“
import cv2, numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import torch, torchvision.transforms as transforms

# è‡ªåŠ¨é™çº§å¤„ç†
try:
    import torchvision.transforms.functional as F
except ImportError:
    print("âš ï¸ torchvisionç‰ˆæœ¬è¾ƒè€ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
```

## ğŸš¨ é”™è¯¯å¤„ç†å’Œè´¨é‡æ§åˆ¶

### æ–‡æœ¬å¤„ç†é”™è¯¯å¤„ç†
```python
# å®‰å…¨çš„æ–‡æœ¬å¤„ç†
def clean_text(self, text: str) -> str:
    if not text or not isinstance(text, str):
        return ""
    
    try:
        # å„ç§æ¸…æ´—æ­¥éª¤
        cleaned = self._apply_cleaning_rules(text)
        return cleaned
    except Exception as e:
        logger.warning(f"æ–‡æœ¬æ¸…æ´—å¤±è´¥: {e}")
        return text  # è¿”å›åŸæ–‡æœ¬
```

### å›¾åƒå¤„ç†è´¨é‡æ§åˆ¶
```python
# å®‰å…¨çš„å›¾åƒåŠ è½½
def load_image_safe(self, image_path: str) -> Dict[str, Any]:
    try:
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        if not full_image_path.exists():
            return self.create_empty_image_result(str(full_image_path))
        
        # å°è¯•åŠ è½½å›¾åƒ
        with Image.open(full_image_path) as image:
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            image_tensor = self.image_transforms(image)
            return {
                'image': image_tensor,
                'has_image': True,
                'image_path': str(full_image_path),
                'image_size': image.size
            }
            
    except Exception as e:
        logger.error(f"å¤„ç†å›¾åƒå¤±è´¥ {full_image_path}: {e}")
        return self.create_empty_image_result(str(full_image_path))
```

## ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### æ–‡æœ¬å¤„ç†ä¼˜åŒ–
- **æ‰¹é‡å¤„ç†**: ä½¿ç”¨`preprocess_batch`æ–¹æ³•æé«˜æ•ˆç‡
- **ç¼“å­˜åˆ†è¯**: å¯¹äºé‡å¤æ–‡æœ¬ï¼Œç¼“å­˜åˆ†è¯ç»“æœ
- **å¹¶è¡Œå¤„ç†**: å¤§æ•°æ®é‡æ—¶ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†

### å›¾åƒå¤„ç†ä¼˜åŒ–
- **å†…å­˜ç®¡ç†**: åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å›¾åƒå¯¹è±¡
- **æ‰¹æ¬¡æ§åˆ¶**: æ ¹æ®å†…å­˜è°ƒæ•´æ‰¹å¤„ç†å¤§å°
- **æ ¼å¼ä¼˜åŒ–**: é€‰æ‹©åˆé€‚çš„å›¾åƒæ ¼å¼å’Œè´¨é‡è®¾ç½®

### é…ç½®ä¼˜åŒ–
```python
# æ€§èƒ½ä¼˜åŒ–é…ç½®ç¤ºä¾‹
optimized_config = {
    'text': {
        'batch_size': 1000,      # æ‰¹å¤„ç†å¤§å°
        'use_cache': True,       # å¯ç”¨ç¼“å­˜
        'max_length': 256        # é€‚å½“å‡å°‘æœ€å¤§é•¿åº¦
    },
    'image': {
        'target_size': [224, 224],  # æ ‡å‡†å°ºå¯¸
        'quality_threshold': 0.5,   # æé«˜è´¨é‡é˜ˆå€¼
        'batch_process': True       # å¯ç”¨æ‰¹å¤„ç†
    }
}
```

---

**[â¬…ï¸ æ¼”ç¤ºè„šæœ¬](../data_utils/demo.md) | [æ–‡æœ¬å¤„ç† â¡ï¸](text_processing.md)**