# é¢„å¤„ç†æ¼”ç¤ºè„šæœ¬ Demo Script

> ğŸ“ **é¢„å¤„ç†æ¨¡å—çš„å¿«é€Ÿæ¼”ç¤ºå’ŒåŠŸèƒ½éªŒè¯è„šæœ¬**

## ğŸ“‹ è„šæœ¬æ¦‚è§ˆ

`demo.py`æä¾›äº†é¢„å¤„ç†æ¨¡å—çš„ç®€åŒ–æ¼”ç¤ºè„šæœ¬ï¼Œå±•ç¤ºæ–‡æœ¬å’Œå›¾åƒå¤„ç†åŠŸèƒ½çš„å®Œæ•´ä½¿ç”¨æµç¨‹ã€‚

## ğŸš€ è„šæœ¬åŠŸèƒ½

### ä¸»è¦ç‰¹æ€§
- **åŠŸèƒ½æ¼”ç¤º**: å±•ç¤ºæ–‡æœ¬å’Œå›¾åƒé¢„å¤„ç†çš„æ ¸å¿ƒåŠŸèƒ½
- **å¿«é€ŸéªŒè¯**: éªŒè¯ä¾èµ–åº“å’Œæ¨¡å—æ˜¯å¦æ­£å¸¸å·¥ä½œ
- **é”™è¯¯è¯Šæ–­**: å¸®åŠ©è¯†åˆ«é…ç½®å’Œç¯å¢ƒé—®é¢˜
- **ç®€åŒ–æ¥å£**: æä¾›æœ€ç›´è§‚çš„ä½¿ç”¨æ–¹å¼

### è„šæœ¬ç»“æ„
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# preprocessing/demo.py

"""
é¢„å¤„ç†æ¨¡å—æ¼”ç¤º - ç®€åŒ–ç‰ˆ
ç›´æ¥è¿è¡Œå³å¯ä½“éªŒæ–‡æœ¬å’Œå›¾åƒé¢„å¤„ç†
"""

from text_processing import TextProcessor
from image_processing import ImageProcessor

def main():
    """ç®€å•æ¼”ç¤ºé¢„å¤„ç†åŠŸèƒ½"""
    print("ğŸ”§ é¢„å¤„ç†æ¨¡å—æ¼”ç¤º")
    print("="*50)
    
    # æ–‡æœ¬å¤„ç†æ¼”ç¤º
    print("\nğŸ“ æ–‡æœ¬å¤„ç†æ¼”ç¤º:")
    processor = TextProcessor(language='mixed')
    
    test_texts = [
        "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ This is a test!",
        "åŒ…å«URLçš„æ–‡æœ¬ https://example.com å’Œ@username",
        "æ··åˆè¯­è¨€æ–‡æœ¬ with English words ä¸­æ–‡å­—ç¬¦"
    ]
    
    for text in test_texts:
        print(f"\nåŸæ–‡: {text}")
        cleaned = processor.clean_text(text)
        tokens = processor.tokenize(text)
        print(f"æ¸…æ´—: {cleaned}")
        print(f"åˆ†è¯: {tokens[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
    
    # å›¾åƒå¤„ç†æ¼”ç¤º
    print("\nğŸ–¼ï¸  å›¾åƒå¤„ç†æ¼”ç¤º:")
    img_processor = ImageProcessor(target_size=(224, 224))
    
    # å¤„ç†æ•°æ®é›†ï¼ˆåªå¤„ç†trainï¼Œæ¼”ç¤ºç”¨ï¼‰
    try:
        results = img_processor.process_mr2_dataset(splits=['train'])
        if results:
            print("å›¾åƒå¤„ç†å®Œæˆ!")
    except Exception as e:
        print(f"å›¾åƒå¤„ç†æ¼”ç¤ºè·³è¿‡: {e}")
    
    print("\nâœ… é¢„å¤„ç†æ¼”ç¤ºå®Œæˆ!")

if __name__ == "__main__":
    main()
```

## ğŸ¯ æ¼”ç¤ºå†…å®¹

### æ–‡æœ¬å¤„ç†æ¼”ç¤º
æ¼”ç¤ºè„šæœ¬ä¼šå±•ç¤ºä»¥ä¸‹æ–‡æœ¬å¤„ç†åŠŸèƒ½ï¼š

#### 1. å¤šè¯­è¨€æ–‡æœ¬å¤„ç†
```python
test_texts = [
    "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ This is a test!",        # ä¸­è‹±æ··åˆ
    "åŒ…å«URLçš„æ–‡æœ¬ https://example.com å’Œ@username",  # åŒ…å«å™ªå£°
    "æ··åˆè¯­è¨€æ–‡æœ¬ with English words ä¸­æ–‡å­—ç¬¦"   # å¤æ‚æ··åˆ
]
```

#### 2. å¤„ç†æ­¥éª¤å±•ç¤º
```python
for text in test_texts:
    print(f"\nåŸæ–‡: {text}")
    
    # æ–‡æœ¬æ¸…æ´—
    cleaned = processor.clean_text(text)
    print(f"æ¸…æ´—: {cleaned}")
    
    # æ™ºèƒ½åˆ†è¯
    tokens = processor.tokenize(text)
    print(f"åˆ†è¯: {tokens[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ªtoken
```

#### æœŸæœ›çš„æ–‡æœ¬å¤„ç†è¾“å‡º
```
ğŸ“ æ–‡æœ¬å¤„ç†æ¼”ç¤º:

åŸæ–‡: è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ This is a test!
æ¸…æ´—: è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ This is a test
åˆ†è¯: ['è¿™æ˜¯', 'ä¸€ä¸ª', 'æµ‹è¯•', 'æ–‡æœ¬', 'this']...

åŸæ–‡: åŒ…å«URLçš„æ–‡æœ¬ https://example.com å’Œ@username
æ¸…æ´—: åŒ…å«URLçš„æ–‡æœ¬ å’Œ
åˆ†è¯: ['åŒ…å«', 'url', 'æ–‡æœ¬']...

åŸæ–‡: æ··åˆè¯­è¨€æ–‡æœ¬ with English words ä¸­æ–‡å­—ç¬¦
æ¸…æ´—: æ··åˆè¯­è¨€æ–‡æœ¬ with English words ä¸­æ–‡å­—ç¬¦
åˆ†è¯: ['æ··åˆ', 'è¯­è¨€', 'æ–‡æœ¬', 'with', 'english']...
```

### å›¾åƒå¤„ç†æ¼”ç¤º
æ¼”ç¤ºè„šæœ¬ä¼šå°è¯•å¤„ç†MR2æ•°æ®é›†çš„å›¾åƒï¼š

#### 1. å›¾åƒå¤„ç†å™¨åˆ›å»º
```python
img_processor = ImageProcessor(target_size=(224, 224))
```

#### 2. æ‰¹é‡å¤„ç†æ¼”ç¤º
```python
try:
    # åªå¤„ç†train splitè¿›è¡Œæ¼”ç¤º
    results = img_processor.process_mr2_dataset(splits=['train'])
    if results:
        print("å›¾åƒå¤„ç†å®Œæˆ!")
        
        # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
        stats = results['train']
        print(f"å¤„ç†ç»Ÿè®¡: æˆåŠŸ{stats['processed_images']}, å¤±è´¥{stats['failed_images']}")
        
except Exception as e:
    print(f"å›¾åƒå¤„ç†æ¼”ç¤ºè·³è¿‡: {e}")
    print("è¿™æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœæ²¡æœ‰å›¾åƒæ•°æ®çš„è¯")
```

#### æœŸæœ›çš„å›¾åƒå¤„ç†è¾“å‡º
```
ğŸ–¼ï¸ å›¾åƒå¤„ç†æ¼”ç¤º:

ğŸ“‚ å¤„ç† train æ•°æ®é›†
  å·²å¤„ç† 50 å¼ å›¾åƒ
  å·²å¤„ç† 100 å¼ å›¾åƒ
  ...

âœ… train æ•°æ®é›†å¤„ç†å®Œæˆ:
  æ€»æ•°: 500
  æˆåŠŸ: 450
  å¤±è´¥: 50

ğŸ’¾ å›¾åƒç‰¹å¾å·²ä¿å­˜åˆ°: data/processed

å›¾åƒå¤„ç†å®Œæˆ!
```

## ğŸš€ å¿«é€Ÿè¿è¡Œ

### ç›´æ¥è¿è¡Œ
```bash
# è¿›å…¥preprocessingç›®å½•
cd preprocessing

# è¿è¡Œæ¼”ç¤ºè„šæœ¬
python demo.py
```

### ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python -m preprocessing.demo
```

## ğŸ”§ è‡ªå®šä¹‰æ¼”ç¤º

### æ‰©å±•æ–‡æœ¬å¤„ç†æ¼”ç¤º
```python
def detailed_text_demo():
    """è¯¦ç»†çš„æ–‡æœ¬å¤„ç†æ¼”ç¤º"""
    print("ğŸ“ è¯¦ç»†æ–‡æœ¬å¤„ç†æ¼”ç¤º")
    processor = TextProcessor(language='mixed')
    
    test_texts = [
        "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬",
        "This is the second test text!",
        "æ··åˆè¯­è¨€æ–‡æœ¬ mixed language text ğŸ˜Š",
        "åŒ…å«@ç”¨æˆ·æåŠ #è¯é¢˜æ ‡ç­¾ https://example.com",
        "ç‰¹æ®Šæ ‡ç‚¹!!! é—®å·??? çœç•¥å·..."
    ]
    
    for i, text in enumerate(test_texts, 1):
        print(f"\n=== æµ‹è¯• {i} ===")
        print(f"åŸæ–‡: {text}")
        
        # è¯­è¨€æ£€æµ‹
        language = processor.detect_language(text)
        print(f"è¯­è¨€: {language}")
        
        # æ–‡æœ¬æ¸…æ´—
        cleaned = processor.clean_text(text)
        print(f"æ¸…æ´—: {cleaned}")
        
        # åˆ†è¯å¤„ç†
        tokens = processor.tokenize(text)
        print(f"åˆ†è¯: {tokens}")
        
        # ç‰¹å¾æå–
        features = processor.extract_features(text)
        print(f"ç‰¹å¾:")
        print(f"  é•¿åº¦: {features['text_length']}")
        print(f"  è¯æ•°: {features['token_count']}")
        print(f"  æ„Ÿå¹å·: {features['exclamation_count']}")
        print(f"  é—®å·: {features['question_count']}")
        print(f"  URLæ•°: {features['url_count']}")
        print(f"  æåŠæ•°: {features['mention_count']}")
```

### æ‰©å±•å›¾åƒå¤„ç†æ¼”ç¤º
```python
def detailed_image_demo():
    """è¯¦ç»†çš„å›¾åƒå¤„ç†æ¼”ç¤º"""
    print("ğŸ–¼ï¸ è¯¦ç»†å›¾åƒå¤„ç†æ¼”ç¤º")
    processor = ImageProcessor(target_size=(224, 224))
    
    # æŸ¥æ‰¾æµ‹è¯•å›¾åƒ
    test_image_dir = Path("../data/train/img")
    if test_image_dir.exists():
        image_files = list(test_image_dir.glob("*.jpg"))[:3]  # åªå–3å¼ 
        
        for i, image_path in enumerate(image_files, 1):
            print(f"\n=== å›¾åƒ {i} ===")
            print(f"è·¯å¾„: {image_path}")
            
            # è·å–å›¾åƒä¿¡æ¯
            info = processor.get_image_info(image_path)
            if info:
                print(f"ä¿¡æ¯:")
                print(f"  å°ºå¯¸: {info['width']} x {info['height']}")
                print(f"  æ ¼å¼: {info['format']}")
                print(f"  å¤§å°: {info['file_size_mb']} MB")
            
            # å¤„ç†å›¾åƒ
            tensor = processor.process_single_image(image_path, 'val')
            if tensor is not None:
                print(f"å¼ é‡å½¢çŠ¶: {tensor.shape}")
            
            # æå–ç‰¹å¾
            image = processor.load_image(image_path)
            if image is not None:
                features = processor.extract_image_features(image)
                print(f"ç‰¹å¾:")
                print(f"  äº®åº¦: {features.get('brightness', 0):.2f}")
                print(f"  å¯¹æ¯”åº¦: {features.get('contrast', 0):.2f}")
                print(f"  è¾¹ç¼˜å¯†åº¦: {features.get('edge_density', 0):.3f}")
    else:
        print("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾åƒç›®å½•")
```

### æ•°æ®å¢å¼ºæ¼”ç¤º
```python
def augmentation_demo():
    """æ•°æ®å¢å¼ºæ¼”ç¤º"""
    print("ğŸ¨ æ•°æ®å¢å¼ºæ¼”ç¤º")
    processor = ImageProcessor(target_size=(224, 224))
    
    # æŸ¥æ‰¾ä¸€å¼ æµ‹è¯•å›¾åƒ
    test_image_dir = Path("../data/train/img")
    if test_image_dir.exists():
        image_files = list(test_image_dir.glob("*.jpg"))
        if image_files:
            test_image_path = image_files[0]
            print(f"æµ‹è¯•å›¾åƒ: {test_image_path}")
            
            # åŠ è½½åŸå§‹å›¾åƒ
            original_image = processor.load_image(test_image_path)
            if original_image is not None:
                print("åŸå§‹å›¾åƒåŠ è½½æˆåŠŸ")
                
                # æµ‹è¯•ä¸åŒçº§åˆ«çš„å¢å¼º
                augment_levels = ['light', 'medium', 'heavy']
                
                for level in augment_levels:
                    print(f"\n{level.upper()} å¢å¼º:")
                    
                    # åº”ç”¨å¢å¼º
                    augmented = processor.apply_augmentation(original_image, level)
                    
                    # è½¬æ¢ä¸ºå¼ é‡
                    tensor = processor.val_transforms(augmented)
                    print(f"  å¢å¼ºåå¼ é‡å½¢çŠ¶: {tensor.shape}")
                    
                    # å¯é€‰ï¼šä¿å­˜å¢å¼ºåçš„å›¾åƒ
                    output_dir = Path("../outputs/augmented")
                    output_dir.mkdir(parents=True, exist_ok=True)
                    
                    output_path = output_dir / f"{level}_augmented.jpg"
                    augmented.save(output_path)
                    print(f"  ä¿å­˜åˆ°: {output_path}")
```

## ğŸ§ª åŠŸèƒ½éªŒè¯

### ä¾èµ–åº“æ£€æŸ¥
```python
def check_dependencies():
    """æ£€æŸ¥é¢„å¤„ç†æ¨¡å—çš„ä¾èµ–åº“"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–åº“...")
    
    dependencies = {
        'jieba': 'ä¸­æ–‡åˆ†è¯',
        'nltk': 'è‹±æ–‡å¤„ç†',
        'PIL': 'å›¾åƒå¤„ç†',
        'cv2': 'è®¡ç®—æœºè§†è§‰',
        'torch': 'PyTorchå¼ é‡',
        'torchvision': 'å›¾åƒå˜æ¢',
        'numpy': 'æ•°å€¼è®¡ç®—'
    }
    
    missing_deps = []
    
    for module, description in dependencies.items():
        try:
            __import__(module)
            print(f"âœ… {module}: {description}")
        except ImportError:
            print(f"âŒ {module}: {description} - æœªå®‰è£…")
            missing_deps.append(module)
    
    if missing_deps:
        print(f"\nç¼ºå¤±çš„ä¾èµ–åº“: {', '.join(missing_deps)}")
        print("è¯·å®‰è£…ç¼ºå¤±çš„åº“ä»¥è·å¾—å®Œæ•´åŠŸèƒ½")
    else:
        print("\nâœ… æ‰€æœ‰ä¾èµ–åº“æ£€æŸ¥é€šè¿‡")
    
    return len(missing_deps) == 0
```

### é…ç½®æ£€æŸ¥
```python
def check_configuration():
    """æ£€æŸ¥é…ç½®ç³»ç»Ÿ"""
    print("âš™ï¸ æ£€æŸ¥é…ç½®ç³»ç»Ÿ...")
    
    try:
        from utils.config_manager import get_data_config
        config = get_data_config()
        print("âœ… é…ç½®ç®¡ç†å™¨å·¥ä½œæ­£å¸¸")
        
        # æ£€æŸ¥å…³é”®é…ç½®
        processing = config.get('processing', {})
        if processing:
            print("âœ… é¢„å¤„ç†é…ç½®å·²åŠ è½½")
        else:
            print("âš ï¸ é¢„å¤„ç†é…ç½®ä¸ºç©º")
            
    except ImportError:
        print("âš ï¸ é…ç½®ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    except Exception as e:
        print(f"âŒ é…ç½®ç³»ç»Ÿé”™è¯¯: {e}")
```

## ğŸš¨ é”™è¯¯å¤„ç†å’Œæ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è¯Šæ–­
```python
def diagnose_issues():