#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NLPé¡¹ç›®æ–‡æ¡£ç»Ÿè®¡è„šæœ¬
ç”¨äºç»Ÿè®¡é¡¹ç›®ä¸­çš„æ–‡æ¡£æ•°é‡ã€å­—æ•°ç­‰ä¿¡æ¯ï¼Œå¹¶ç”ŸæˆJSONæ•°æ®æ–‡ä»¶
"""

import os
import json
import re
import fnmatch
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Set

class DocumentStats:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        
        # è¦ç»Ÿè®¡çš„æ–‡ä»¶æ‰©å±•å
        self.include_extensions = {
            '.md', '.txt', '.py', '.js', '.html', '.css', 
            '.rst', '.tex', '.ipynb', '.json', '.yaml', '.yml'
        }
        
        # ä» .gitignore æ–‡ä»¶è¯»å–æ’é™¤è§„åˆ™
        self.gitignore_patterns = self.load_gitignore_patterns()
        
        # ç»Ÿè®¡ç»“æœ
        self.stats = {
            'total_files': 0,
            'total_words': 0,
            'total_chars': 0,
            'total_lines': 0,
            'file_types': {},
            'largest_files': [],
            'update_time': '',
            'project_structure': {}
        }
    
    def load_gitignore_patterns(self) -> List[str]:
        """è¯»å– .gitignore æ–‡ä»¶å¹¶è§£ææ’é™¤æ¨¡å¼"""
        gitignore_path = self.project_root / '.gitignore'
        patterns = []
        
        if not gitignore_path.exists():
            print(f"è­¦å‘Š: æœªæ‰¾åˆ° .gitignore æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤æ’é™¤è§„åˆ™")
            # å¦‚æœæ²¡æœ‰ .gitignore æ–‡ä»¶ï¼Œä½¿ç”¨ä¸€äº›åŸºæœ¬çš„é»˜è®¤è§„åˆ™
            default_patterns = [
                '__pycache__/',
                '*.pyc',
                '.git/',
                '.vscode/',
                '.idea/',
                'node_modules/',
                '*.log'
            ]
            return default_patterns
        
        try:
            with open(gitignore_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                    if not line or line.startswith('#'):
                        continue
                    patterns.append(line)
            
            print(f"å·²åŠ è½½ {len(patterns)} æ¡ .gitignore è§„åˆ™")
            return patterns
            
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å– .gitignore æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def should_exclude_path(self, file_path: Path) -> bool:
        """æ ¹æ® .gitignore è§„åˆ™åˆ¤æ–­æ˜¯å¦åº”è¯¥æ’é™¤æŸä¸ªè·¯å¾„"""
        # è·å–ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        try:
            relative_path = file_path.relative_to(self.project_root)
        except ValueError:
            # å¦‚æœè·¯å¾„ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ’é™¤å®ƒ
            return True
        
        path_str = str(relative_path)
        path_parts = relative_path.parts
        
        # æ£€æŸ¥æ¯ä¸ª gitignore æ¨¡å¼
        for pattern in self.gitignore_patterns:
            if self.matches_gitignore_pattern(path_str, path_parts, pattern):
                return True
        
        return False
    
    def matches_gitignore_pattern(self, path_str: str, path_parts: tuple, pattern: str) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ¹é… gitignore æ¨¡å¼"""
        # å¤„ç†å¦å®šæ¨¡å¼ (ä»¥ ! å¼€å¤´)
        if pattern.startswith('!'):
            # å¦å®šæ¨¡å¼æš‚ä¸å¤„ç†ï¼Œæ¯”è¾ƒå¤æ‚
            return False
        
        # å¤„ç†ä»¥ / ç»“å°¾çš„ç›®å½•æ¨¡å¼
        if pattern.endswith('/'):
            pattern = pattern[:-1]
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•è·¯å¾„éƒ¨åˆ†åŒ¹é…è¿™ä¸ªç›®å½•å
            for part in path_parts[:-1]:  # æ’é™¤æ–‡ä»¶åæœ¬èº«
                if fnmatch.fnmatch(part, pattern):
                    return True
            return False
        
        # å¤„ç†ä»¥ / å¼€å¤´çš„æ ¹ç›®å½•æ¨¡å¼
        if pattern.startswith('/'):
            pattern = pattern[1:]
            return fnmatch.fnmatch(path_str, pattern)
        
        # å¤„ç†åŒ…å« / çš„è·¯å¾„æ¨¡å¼
        if '/' in pattern:
            return fnmatch.fnmatch(path_str, pattern)
        
        # å¤„ç†æ–‡ä»¶åæ¨¡å¼ - æ£€æŸ¥è·¯å¾„çš„ä»»ä½•éƒ¨åˆ†
        # 1. æ£€æŸ¥å®Œæ•´è·¯å¾„
        if fnmatch.fnmatch(path_str, pattern):
            return True
        
        # 2. æ£€æŸ¥æ–‡ä»¶å
        if fnmatch.fnmatch(path_parts[-1], pattern):
            return True
        
        # 3. æ£€æŸ¥ä»»ä½•ç›®å½•å
        for part in path_parts[:-1]:
            if fnmatch.fnmatch(part, pattern):
                return True
        
        # 4. æ£€æŸ¥æ˜¯å¦åŒ¹é…è·¯å¾„ä¸­çš„ä»»ä½•æ®µ
        if '*' in pattern or '?' in pattern:
            for part in path_parts:
                if fnmatch.fnmatch(part, pattern):
                    return True
        
        return False
    
    def count_words(self, text: str) -> int:
        """ç»Ÿè®¡å­—æ•°ï¼ˆä¸­è‹±æ–‡æ··åˆï¼‰"""
        # ä¸­æ–‡å­—ç¬¦
        chinese_chars = len(re.findall(r'[\u4e00-\u9fa5]', text))
        # è‹±æ–‡å•è¯
        english_words = len(re.findall(r'[a-zA-Z]+', text))
        # æ•°å­—
        numbers = len(re.findall(r'\d+', text))
        
        return chinese_chars + english_words + numbers
    
    def analyze_file(self, file_path: Path) -> Dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼
            encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
            content = None
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                print(f"è­¦å‘Š: æ— æ³•è§£ç æ–‡ä»¶ {file_path}")
                return None
            
            words = self.count_words(content)
            chars = len(content)
            lines = len(content.splitlines())
            
            file_info = {
                'path': str(file_path.relative_to(self.project_root)),
                'words': words,
                'chars': chars,
                'lines': lines,
                'size': file_path.stat().st_size,
                'extension': file_path.suffix.lower()
            }
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å‰å‡ ä¸ªæ–‡ä»¶çš„ç»Ÿè®¡
            if len(getattr(self, '_debug_count', [])) < 5:
                if not hasattr(self, '_debug_count'):
                    self._debug_count = []
                self._debug_count.append(file_info)
                print(f"è°ƒè¯•: {file_info['path']} - {words}å­—, {chars}å­—ç¬¦, {lines}è¡Œ")
            
            return file_info
            
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return None
    
    def scan_project(self) -> None:
        """æ‰«ææ•´ä¸ªé¡¹ç›®"""
        print(f"æ­£åœ¨æ‰«æé¡¹ç›®: {self.project_root.absolute()}")
        print(f"ä½¿ç”¨ {len(self.gitignore_patterns)} æ¡ .gitignore è§„åˆ™")
        
        file_details = []
        total_scanned = 0
        excluded_count = 0
        
        for file_path in self.project_root.rglob('*'):
            if not file_path.is_file():
                continue
            
            total_scanned += 1
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
            if self.should_exclude_path(file_path):
                excluded_count += 1
                if total_scanned % 100 == 0:  # æ¯100ä¸ªæ–‡ä»¶æ‰“å°ä¸€æ¬¡è¿›åº¦
                    print(f"å·²æ‰«æ {total_scanned} ä¸ªæ–‡ä»¶ï¼Œæ’é™¤äº† {excluded_count} ä¸ª")
                continue
                
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if file_path.suffix.lower() not in self.include_extensions:
                continue
            
            # åˆ†ææ–‡ä»¶
            file_info = self.analyze_file(file_path)
            if file_info:
                file_details.append(file_info)
        
        print(f"æ‰«æå®Œæˆï¼æ€»å…±æ‰«æ {total_scanned} ä¸ªæ–‡ä»¶ï¼Œæ’é™¤ {excluded_count} ä¸ª")
        print(f"ç»Ÿè®¡ {len(file_details)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ–‡æ¡£æ–‡ä»¶")
        
        # ç»Ÿè®¡æ±‡æ€»
        self.stats['total_files'] = len(file_details)
        self.stats['total_words'] = sum(f['words'] for f in file_details)
        self.stats['total_chars'] = sum(f['chars'] for f in file_details)
        self.stats['total_lines'] = sum(f['lines'] for f in file_details)
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"\n=== è°ƒè¯•ä¿¡æ¯ ===")
        print(f"æ–‡ä»¶è¯¦æƒ…åˆ—è¡¨é•¿åº¦: {len(file_details)}")
        if file_details:
            print(f"ç¬¬ä¸€ä¸ªæ–‡ä»¶ç¤ºä¾‹: {file_details[0]}")
            sample_words = [f['words'] for f in file_details[:5]]
            print(f"å‰5ä¸ªæ–‡ä»¶å­—æ•°: {sample_words}")
        
        # æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        for file_info in file_details:
            ext = file_info['extension']
            if ext not in self.stats['file_types']:
                self.stats['file_types'][ext] = {
                    'count': 0,
                    'words': 0,
                    'chars': 0,
                    'lines': 0
                }
            
            self.stats['file_types'][ext]['count'] += 1
            self.stats['file_types'][ext]['words'] += file_info['words']
            self.stats['file_types'][ext]['chars'] += file_info['chars']
            self.stats['file_types'][ext]['lines'] += file_info['lines']
        
        # æœ€å¤§çš„æ–‡ä»¶ï¼ˆæŒ‰å­—æ•°æ’åºï¼‰
        self.stats['largest_files'] = sorted(
            file_details, 
            key=lambda x: x['words'], 
            reverse=True
        )[:10]
        
        # æ›´æ–°æ—¶é—´
        self.stats['update_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        print(f"\n=== æœ€ç»ˆç»Ÿè®¡ç»“æœ ===")
        print(f"æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"æ€»å­—æ•°: {self.stats['total_words']:,}")
        print(f"æ€»å­—ç¬¦æ•°: {self.stats['total_chars']:,}")
        print(f"æ€»è¡Œæ•°: {self.stats['total_lines']:,}")
        
        # æ˜¾ç¤ºæ–‡ä»¶ç±»å‹åˆ†å¸ƒ
        if self.stats['file_types']:
            print(f"\næ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
            for ext, info in self.stats['file_types'].items():
                print(f"  {ext}: {info['count']}ä¸ªæ–‡ä»¶, {info['words']:,}å­—")
        
        # æ˜¾ç¤ºæœ€å¤§çš„å‡ ä¸ªæ–‡ä»¶
        if self.stats['largest_files']:
            print(f"\nå­—æ•°æœ€å¤šçš„5ä¸ªæ–‡ä»¶:")
            for i, file_info in enumerate(self.stats['largest_files'][:5], 1):
                print(f"  {i}. {file_info['path']}: {file_info['words']:,}å­—")
    
    def save_stats(self, output_file: str = "docs/stats.json") -> None:
        """ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°JSONæ–‡ä»¶"""
        output_path = self.project_root / output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è°ƒè¯•ï¼šæ£€æŸ¥ä¿å­˜å‰çš„æ•°æ®
        print(f"\n=== ä¿å­˜è°ƒè¯•ä¿¡æ¯ ===")
        print(f"å‡†å¤‡ä¿å­˜çš„ç»Ÿè®¡æ•°æ®:")
        print(f"  total_files: {self.stats['total_files']}")
        print(f"  total_words: {self.stats['total_words']}")
        print(f"  total_chars: {self.stats['total_chars']}")
        print(f"  file_typesæ•°é‡: {len(self.stats['file_types'])}")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, ensure_ascii=False, indent=2)
        
        # éªŒè¯ä¿å­˜çš„æ–‡ä»¶
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            print(f"éªŒè¯ä¿å­˜çš„æ•°æ®:")
            print(f"  total_files: {saved_data.get('total_files', 'Missing')}")
            print(f"  total_words: {saved_data.get('total_words', 'Missing')}")
        except Exception as e:
            print(f"éªŒè¯ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}")
        
        print(f"ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    def generate_markdown_report(self, output_file: str = "docs/stats.md") -> None:
        """ç”ŸæˆMarkdownæ ¼å¼çš„ç»Ÿè®¡æŠ¥å‘Š"""
        output_path = self.project_root / output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        md_content = f"""# ğŸ“Š é¡¹ç›®æ–‡æ¡£ç»Ÿè®¡æŠ¥å‘Š

> æœ€åæ›´æ–°æ—¶é—´: {self.stats['update_time']}

## ğŸ“ˆ æ€»ä½“ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| ğŸ“ æ–‡æ¡£æ–‡ä»¶æ€»æ•° | {self.stats['total_files']:,} |
| ğŸ“ æ€»å­—æ•° | {self.stats['total_words']:,} |
| ğŸ“„ æ€»å­—ç¬¦æ•° | {self.stats['total_chars']:,} |
| ğŸ“‹ æ€»è¡Œæ•° | {self.stats['total_lines']:,} |
| ğŸ“Š å¹³å‡å­—æ•°/æ–‡ä»¶ | {self.stats['total_words'] // max(self.stats['total_files'], 1):,} |

## ğŸ“‚ æ–‡ä»¶ç±»å‹åˆ†å¸ƒ

| æ–‡ä»¶ç±»å‹ | æ–‡ä»¶æ•° | å­—æ•° | å­—ç¬¦æ•° | è¡Œæ•° |
|----------|--------|------|--------|------|
"""
        
        for ext, info in sorted(self.stats['file_types'].items()):
            md_content += f"| {ext} | {info['count']} | {info['words']:,} | {info['chars']:,} | {info['lines']:,} |\n"
        
        md_content += f"""
## ğŸ“‹ ä¸»è¦æ–‡æ¡£æ–‡ä»¶ (æŒ‰å­—æ•°æ’åº)

| æ–‡ä»¶è·¯å¾„ | å­—æ•° | å­—ç¬¦æ•° | è¡Œæ•° |
|----------|------|--------|------|
"""
        
        for file_info in self.stats['largest_files'][:15]:
            md_content += f"| {file_info['path']} | {file_info['words']:,} | {file_info['chars']:,} | {file_info['lines']:,} |\n"
        
        md_content += f"""
---
*æ­¤æŠ¥å‘Šç”±é¡¹ç›®æ–‡æ¡£ç»Ÿè®¡è„šæœ¬è‡ªåŠ¨ç”Ÿæˆ*
"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='NLPé¡¹ç›®æ–‡æ¡£ç»Ÿè®¡å·¥å…·')
    parser.add_argument('--root', '-r', default='.', help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--output', '-o', default='docs/stats.json', help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--markdown', '-m', help='ç”ŸæˆMarkdownæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç»Ÿè®¡å™¨
    stats = DocumentStats(args.root)
    
    # æ‰«æé¡¹ç›®
    stats.scan_project()
    
    # ä¿å­˜JSONæ•°æ®
    stats.save_stats(args.output)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    if args.markdown:
        stats.generate_markdown_report(args.markdown)
    else:
        stats.generate_markdown_report()  # ä½¿ç”¨é»˜è®¤è·¯å¾„
    
    # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    if args.verbose:
        print("\n=== è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ ===")
        print(json.dumps(stats.stats, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    main()