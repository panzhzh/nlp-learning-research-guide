#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# models/explainable_ai/demo.py

"""
æ¼”ç¤ºå¯è§£é‡Šæ€§AIæ¨¡å— (LIME, SHAP) çš„ä½¿ç”¨ï¼Œå¹¶åŒ…å«å¯è§†åŒ–è¾“å‡ºã€‚
SHAP Force Plot ä¸­çš„ç‰¹å¾å€¼å°†æ ¼å¼åŒ–ä¸ºä¸¤ä½å°æ•°ã€‚
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score
from pathlib import Path
import sys
import warnings
warnings.filterwarnings('ignore')

# å¿«é€Ÿè·¯å¾„è®¾ç½® (æ ¹æ®å®é™…é¡¹ç›®ç»“æ„è°ƒæ•´)
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

print(f"Project root (from demo.py): {project_root}")
sys.path.insert(0, str(current_file.parent))

try:
    from explainers import LimeExplainer, ShapExplainer
    print("âœ… æˆåŠŸå¯¼å…¥é¡¹ç›®æ¨¡å— (explainers from demo.py)")
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥é¡¹ç›®æ¨¡å—å¤±è´¥ (demo.py): {e}")
    try:
        from models.explainable_ai.explainers import LimeExplainer, ShapExplainer
        print("âœ… æˆåŠŸé€šè¿‡ç»å¯¹è·¯å¾„å¯¼å…¥é¡¹ç›®æ¨¡å— (explainers from demo.py)")
    except ImportError as e_abs:
        print(f"âš ï¸ é€šè¿‡ç»å¯¹è·¯å¾„å¯¼å…¥é¡¹ç›®æ¨¡å—ä¹Ÿå¤±è´¥ (demo.py): {e_abs}")
        sys.exit(1)

import logging
logger = logging.getLogger(__name__)

# <<< --- å‰é¢çš„ generate_data å’Œ train_model å‡½æ•°ä¿æŒä¸å˜ --- >>>
def generate_data(n_samples: int = 250, n_features: int = 15, n_classes: int = 2, random_state: int = 42) \
        -> tuple[np.ndarray, np.ndarray, list[str], list[str]]:
    """
    ç”Ÿæˆç”¨äºåˆ†ç±»ä»»åŠ¡çš„æ ·æœ¬æ•°æ®ã€‚
    """
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=max(2, n_features // 2),
        n_redundant=max(1, n_features // 4),
        n_clusters_per_class=1,
        n_classes=n_classes,
        random_state=random_state
    )
    feature_names = [f"feature_{i+1}" for i in range(n_features)]
    class_names = [f"class_{j}" for j in range(n_classes)]
    print(f"æ•°æ®å·²ç”Ÿæˆ: X shape: {X.shape}, y shape: {y.shape}")
    return X, y, feature_names, class_names

def train_model(X_train: np.ndarray, y_train: np.ndarray, random_state: int = 42) -> RandomForestClassifier:
    """
    è®­ç»ƒä¸€ä¸ªç®€å•çš„éšæœºæ£®æ—åˆ†ç±»å™¨ã€‚
    """
    model = RandomForestClassifier(n_estimators=100, random_state=random_state, min_samples_leaf=5)
    model.fit(X_train, y_train)
    print("æ¨¡å‹è®­ç»ƒå®Œæˆ: RandomForestClassifier")
    return model

def run_explanation_demo():
    """
    æ‰§è¡ŒLIMEå’ŒSHAPè§£é‡Šçš„å®Œæ•´æ¼”ç¤ºï¼ŒåŒ…å«å¯è§†åŒ–è¾“å‡ºã€‚
    """
    print("\nğŸš€ å¼€å§‹å¯è§£é‡Šæ€§AIæ¼”ç¤º (demo.py) ğŸš€")
    print("=" * 60)

    # åˆ›å»ºç”¨äºä¿å­˜å¯è§†åŒ–ç»“æœçš„ç›®å½•
    output_visualization_dir = project_root / "outputs" / "explainable_ai_visuals"
    output_visualization_dir.mkdir(parents=True, exist_ok=True)
    print(f"å¯è§†åŒ–ç»“æœå°†ä¿å­˜åˆ°: {output_visualization_dir}")

    # 1. æ•°æ®å‡†å¤‡
    print("\n[é˜¶æ®µ1: ç”Ÿæˆæ•°æ®]")
    X, y, feature_names, class_names = generate_data(n_samples=300, n_features=10)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

    X_train_df = pd.DataFrame(X_train, columns=feature_names)
    X_test_df = pd.DataFrame(X_test, columns=feature_names)
    print(f"è®­ç»ƒé›†: {X_train_df.shape}, æµ‹è¯•é›†: {X_test_df.shape}")

    # 2. æ¨¡å‹è®­ç»ƒ
    print("\n[é˜¶æ®µ2: è®­ç»ƒæ¨¡å‹]")
    model = train_model(X_train_df, y_train)
    y_pred_test = model.predict(X_test_df)
    test_accuracy = accuracy_score(y_test, y_pred_test)
    print(f"æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡: {test_accuracy:.4f}")

    sample_idx = 0
    instance_to_explain_np = X_test[sample_idx]
    instance_to_explain_df_row = X_test_df.iloc[[sample_idx]]

    true_label = class_names[y_test[sample_idx]]
    predicted_proba = model.predict_proba(instance_to_explain_df_row)[0]
    predicted_class_idx = np.argmax(predicted_proba)
    predicted_label = class_names[predicted_class_idx]

    print(f"\né€‰æ‹©æµ‹è¯•é›†æ ·æœ¬ #{sample_idx} è¿›è¡Œè§£é‡Š:")
    print(f"  ç‰¹å¾å€¼ (åŸå§‹): {instance_to_explain_np}") # æ‰“å°åŸå§‹å€¼ä»¥å¯¹æ¯”
    print(f"  ç‰¹å¾å€¼ (æ˜¾ç¤ºç”¨, å››èˆäº”å…¥åˆ°ä¸¤ä½å°æ•°): {instance_to_explain_np.round(2)}")
    print(f"  çœŸå®æ ‡ç­¾: {true_label}")
    print(f"  æ¨¡å‹é¢„æµ‹æ ‡ç­¾: {predicted_label} (æ¦‚ç‡: {predicted_proba[predicted_class_idx]:.4f})")
    print(f"  æ¨¡å‹é¢„æµ‹æ¦‚ç‡: {dict(zip(class_names, predicted_proba.round(4)))}")

    # 3. ä½¿ç”¨LIMEè¿›è¡Œè§£é‡Š
    print("\n[é˜¶æ®µ3: LIMEè§£é‡Š]")
    try:
        lime_explainer = LimeExplainer(
            model=model,
            training_data=X_train,
            feature_names=feature_names,
            class_names=class_names,
            mode="classification"
        )

        lime_explanation = lime_explainer.explain_instance(
            instance_to_explain_np,
            num_features=5,
            top_labels=1
        )

        print(f"\nLIME å¯¹æ ·æœ¬ #{sample_idx} (é¢„æµ‹: {predicted_label}) çš„è§£é‡Š:")
        print("  ç‰¹å¾è´¡çŒ® (LIME):")
        for feature, weight in lime_explanation.as_list():
            print(f"    - {feature}: {weight:.4f}")

        # --- LIME å¯è§†åŒ–: ä¿å­˜ä¸º HTML ---
        lime_html_path = output_visualization_dir / f"lime_report_sample_{sample_idx}.html"
        lime_explanation.save_to_file(lime_html_path)
        print(f"  âœ… LIMEè§£é‡ŠæŠ¥å‘Šå·²ä¿å­˜åˆ°: {lime_html_path}")
        print(f"     æ‚¨å¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ­¤HTMLæ–‡ä»¶æŸ¥çœ‹å¯è§†åŒ–LIMEè§£é‡Šã€‚")

    except Exception as e:
        print(f"âŒ LIMEè§£é‡Šè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    # 4. ä½¿ç”¨SHAPè¿›è¡Œè§£é‡Š
    print("\n[é˜¶æ®µ4: SHAPè§£é‡Šä¸å¯è§†åŒ–]")
    try:
        shap_explainer_instance = ShapExplainer(
            model=model,
            data=X_train_df
        )

        shap_values_one_instance = shap_explainer_instance.explain_instance(instance_to_explain_df_row)

        print(f"\nSHAP å¯¹æ ·æœ¬ #{sample_idx} (é¢„æµ‹: {predicted_label}) çš„æ–‡æœ¬è§£é‡Š:")
        if hasattr(shap_values_one_instance, 'base_values') and shap_values_one_instance.base_values is not None:
            base_val_text = ""
            if shap_values_one_instance.base_values.ndim > 0 and len(shap_values_one_instance.base_values) > predicted_class_idx:
                 base_val_text = f"{shap_values_one_instance.base_values[predicted_class_idx]:.4f} (ç±»åˆ« {predicted_label})"
            elif shap_values_one_instance.base_values.ndim == 0 :
                 base_val_text = f"{shap_values_one_instance.base_values:.4f}"
            else:
                 base_val_text = f"{shap_values_one_instance.base_values} (æ‰€æœ‰ç±»åˆ«)"
            print(f"  SHAPåŸºç¡€å€¼: {base_val_text}")

        print("  ç‰¹å¾è´¡çŒ® (SHAP values):")
        current_shap_values = shap_values_one_instance.values
        shap_values_for_predicted_class_plot = None # ç”¨äºç»˜å›¾

        if current_shap_values.ndim == 3 and current_shap_values.shape[0] == 1:
            shap_vals_for_predicted_class = current_shap_values[0, :, predicted_class_idx]
            shap_values_for_predicted_class_plot = shap_vals_for_predicted_class
            for i, feature_name in enumerate(feature_names):
                print(f"    - {feature_name}: {shap_vals_for_predicted_class[i]:.4f} (å¯¹ç±»åˆ« {predicted_label})")
        elif current_shap_values.ndim == 2 and current_shap_values.shape[0] == 1:
            shap_vals_for_instance = current_shap_values[0, :]
            shap_values_for_predicted_class_plot = shap_vals_for_instance
            for i, feature_name in enumerate(feature_names):
                print(f"    - {feature_name}: {shap_vals_for_instance[i]:.4f}")
        else:
            print(f"    SHAPå€¼æ ¼å¼æœªçŸ¥æˆ–ä¸åŒ¹é…å•ä¸ªå®ä¾‹è§£é‡Š: shape={current_shap_values.shape}")

        # --- SHAP å¯è§†åŒ– ---
        print("\n  ç”ŸæˆSHAPå¯è§†åŒ–å›¾:")
        try:
            import matplotlib.pyplot as plt
            import shap
            # shap.initjs() # åœ¨è„šæœ¬ä¸­è¿è¡Œæ—¶ï¼Œæ­¤è¡Œä¸»è¦ç”¨äºJupyterç¯å¢ƒä½†å¯èƒ½å¯¼è‡´IPythonä¾èµ–é—®é¢˜ï¼Œå·²æ³¨é‡Š

            # 1. å•ä¸ªå®ä¾‹çš„åŠ›å›¾ (Force Plot)
            if shap_values_for_predicted_class_plot is not None:
                explainer_base_value = shap_explainer_instance.explainer.expected_value
                if isinstance(explainer_base_value, (list, np.ndarray)) and len(explainer_base_value) > predicted_class_idx:
                    base_value_for_plot = explainer_base_value[predicted_class_idx]
                else:
                    base_value_for_plot = explainer_base_value

                # ---- ä¿®æ”¹å¼€å§‹: æ ¼å¼åŒ–ç”¨äºæ˜¾ç¤ºçš„ç‰¹å¾å€¼ ----
                instance_for_plot_display = instance_to_explain_df_row.copy()
                for col in instance_for_plot_display.columns:
                    if pd.api.types.is_numeric_dtype(instance_for_plot_display[col]):
                        instance_for_plot_display[col] = instance_for_plot_display[col].round(2)
                # ---- ä¿®æ”¹ç»“æŸ ----

                plt.figure()
                shap.force_plot(
                    base_value_for_plot,
                    shap_values_for_predicted_class_plot,
                    instance_for_plot_display, # <--- ä½¿ç”¨æ ¼å¼åŒ–åçš„DataFrameè¿›è¡Œæ˜¾ç¤º
                    matplotlib=True,
                    show=False
                )
                force_plot_path = output_visualization_dir / f"shap_force_plot_sample_{sample_idx}_class_{predicted_label}.png"
                plt.savefig(force_plot_path, bbox_inches='tight')
                plt.close()
                print(f"  âœ… SHAPåŠ›å›¾å·²ä¿å­˜åˆ°: {force_plot_path}")
            else:
                print("  âš ï¸ æ— æ³•ç”ŸæˆSHAPåŠ›å›¾ï¼Œå› SHAPå€¼æ ¼å¼ä¸é€‚ç”¨äºå•å®ä¾‹ç»˜å›¾ã€‚")

            # 2. æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„SHAPå€¼ (ç”¨äºæ‘˜è¦å›¾)
            print("  è®¡ç®—æ•´ä¸ªæµ‹è¯•é›†çš„SHAPå€¼ (å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´)...")
            shap_values_test_set = shap_explainer_instance.explain_model(X_test_df)

            shap_values_for_summary = None
            if shap_values_test_set.values.ndim == 3:
                class_to_summarize_idx = 1
                if shap_values_test_set.values.shape[2] > class_to_summarize_idx:
                    shap_values_for_summary = shap_values_test_set.values[:, :, class_to_summarize_idx]
                    summary_plot_title = f"SHAP Summary Plot (Class {class_names[class_to_summarize_idx]})"
                else:
                    print(f"  âš ï¸ æ— æ³•ä¸ºç±»åˆ«ç´¢å¼• {class_to_summarize_idx} ç”Ÿæˆæ‘˜è¦å›¾ï¼ŒSHAPå€¼ç±»åˆ«ç»´åº¦ä¸è¶³ã€‚")
            elif shap_values_test_set.values.ndim == 2:
                shap_values_for_summary = shap_values_test_set.values
                summary_plot_title = "SHAP Summary Plot"

            if shap_values_for_summary is not None:
                # ---- ä¿®æ”¹å¼€å§‹: å‡†å¤‡ç”¨äºæ‘˜è¦å›¾æ˜¾ç¤ºçš„ç‰¹å¾å€¼ (å¦‚æœéœ€è¦ï¼Œä½†æ‘˜è¦å›¾é€šå¸¸ç”¨é¢œè‰²è¡¨ç¤ºåŸå§‹å€¼èŒƒå›´) ----
                # å¯¹äºæ‘˜è¦å›¾ï¼Œç‰¹å¾å€¼é€šå¸¸é€šè¿‡é¢œè‰²ç¼–ç æ˜¾ç¤ºå…¶åŸå§‹èŒƒå›´ï¼Œè€Œä¸æ˜¯ç›´æ¥æ˜¾ç¤ºæ•°å€¼ã€‚
                # ä½†å¦‚æœç¡®å®éœ€è¦åœ¨Xè½´æ ‡ç­¾ä¸Šæ˜¾ç¤ºæˆªæ–­çš„å€¼ï¼Œéœ€è¦ä¼ é€’æ ¼å¼åŒ–åçš„X_test_dfã€‚
                # è¿™é‡Œæˆ‘ä»¬ä¿æŒX_test_dfä¸å˜ï¼Œå› ä¸ºæ‘˜è¦å›¾çš„ç›®çš„æ˜¯å±•ç¤ºåˆ†å¸ƒã€‚
                # X_test_df_display_for_summary = X_test_df.copy()
                # for col in X_test_df_display_for_summary.columns:
                #    if pd.api.types.is_numeric_dtype(X_test_df_display_for_summary[col]):
                #        X_test_df_display_for_summary[col] = X_test_df_display_for_summary[col].round(2)
                # ---- ä¿®æ”¹ç»“æŸ ----

                plt.figure()
                shap.summary_plot(
                    shap_values_for_summary,
                    X_test_df, # ä¼ é€’åŸå§‹çš„ X_test_dfï¼Œé¢œè‰²ä¼šåŸºäºåŸå§‹å€¼
                    show=False,
                    plot_size=(10, 8)
                )
                plt.title(summary_plot_title, fontsize=14)
                summary_plot_path = output_visualization_dir / "shap_summary_plot.png"
                plt.savefig(summary_plot_path, bbox_inches='tight')
                plt.close()
                print(f"  âœ… SHAPæ‘˜è¦å›¾å·²ä¿å­˜åˆ°: {summary_plot_path}")
                print(f"     æ‘˜è¦å›¾æ˜¾ç¤ºäº†æ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹è¾“å‡ºçš„æ•´ä½“å½±å“ã€‚ç‚¹è¶Šåˆ†æ•£ï¼Œè¯´æ˜è¯¥ç‰¹å¾å¯¹ä¸åŒæ ·æœ¬çš„å½±å“å·®å¼‚è¶Šå¤§ã€‚é¢œè‰²ä»£è¡¨ç‰¹å¾å€¼çš„é«˜ä½ã€‚")

        except ImportError:
            print("  âš ï¸ matplotlibæˆ–shapæœªå®Œå…¨å®‰è£…æˆ–é…ç½®æ­£ç¡®ï¼Œæ— æ³•ç”ŸæˆSHAPå›¾ã€‚è¯·è¿è¡Œ: pip install matplotlib shap")
        except Exception as plot_e:
            print(f"  âŒ ç”ŸæˆSHAPå›¾æ—¶å‘ç”Ÿé”™è¯¯: {plot_e}")
            import traceback
            traceback.print_exc()

    except Exception as e:
        print(f"âŒ SHAPè§£é‡Šè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    print("\n" + "=" * 60)
    print("ğŸ‰ å¯è§£é‡Šæ€§AIæ¼”ç¤ºå®Œæˆ! ğŸ‰")

if __name__ == "__main__":
    run_explanation_demo()