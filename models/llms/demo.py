#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# models/llms/demo.py

"""
LLMæ¨¡å—å®Œæ•´æ¼”ç¤º
è°ƒç”¨å„ä¸ªå­æ¨¡å—çš„æ¼”ç¤ºåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ–°å¢çš„RAGåŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¤– å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨¡å—å®Œæ•´æ¼”ç¤º")
    print("=" * 60)
    print("æœ¬æ¼”ç¤ºå°†ä¾æ¬¡å±•ç¤ºå„ä¸ªå­æ¨¡å—çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ–°å¢çš„RAGé›†æˆ")
    print("=" * 60)
    
    # 1. æ¼”ç¤ºå¼€æºLLMæ¨¡å—
    print("\n" + "ğŸ”¥" * 20)
    print("1. å¼€æºLLMæ¨¡å—æ¼”ç¤º (Qwen3-0.6B)")
    print("ğŸ”¥" * 20)
    
    try:
        from models.llms.open_source_llms import demo_qwen_classification
        demo_qwen_classification()
        print("âœ… å¼€æºLLMæ¨¡å—æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ å¼€æºLLMæ¨¡å—æ¼”ç¤ºå¤±è´¥: {e}")
    
    # 2. æ¼”ç¤ºæç¤ºå·¥ç¨‹æ¨¡å—
    print("\n" + "ğŸ“" * 20)
    print("2. æç¤ºå·¥ç¨‹æ¨¡å—æ¼”ç¤º")
    print("ğŸ“" * 20)
    
    try:
        from models.llms.prompt_engineering import demo_prompt_engineering
        demo_prompt_engineering()
        print("âœ… æç¤ºå·¥ç¨‹æ¨¡å—æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ æç¤ºå·¥ç¨‹æ¨¡å—æ¼”ç¤ºå¤±è´¥: {e}")
    
    # 3. æ¼”ç¤ºå°‘æ ·æœ¬å­¦ä¹ æ¨¡å—
    print("\n" + "ğŸ¯" * 20)
    print("3. å°‘æ ·æœ¬å­¦ä¹ æ¨¡å—æ¼”ç¤º")
    print("ğŸ¯" * 20)
    
    try:
        from models.llms.few_shot_learning import demo_few_shot_learning
        demo_few_shot_learning()
        print("âœ… å°‘æ ·æœ¬å­¦ä¹ æ¨¡å—æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ å°‘æ ·æœ¬å­¦ä¹ æ¨¡å—æ¼”ç¤ºå¤±è´¥: {e}")
    
    # 4. æ¼”ç¤ºRAGé›†æˆæ¨¡å— (æ–°å¢)
    print("\n" + "ğŸ”" * 20)
    print("4. RAGé›†æˆæ¨¡å—æ¼”ç¤º")
    print("ğŸ”" * 20)
    
    try:
        from models.llms.rag_integration import demo_rag_integration
        demo_rag_integration()
        print("âœ… RAGé›†æˆæ¨¡å—æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ RAGé›†æˆæ¨¡å—æ¼”ç¤ºå¤±è´¥: {e}")
    
    # 5. æ¼”ç¤ºé«˜çº§RAGåŠŸèƒ½ (æ–°å¢)
    print("\n" + "ğŸ”¬" * 20)
    print("5. é«˜çº§RAGåŠŸèƒ½æ¼”ç¤º")
    print("ğŸ”¬" * 20)
    
    try:
        from models.llms.rag_integration import demo_advanced_rag_features
        demo_advanced_rag_features()
        print("âœ… é«˜çº§RAGåŠŸèƒ½æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ é«˜çº§RAGåŠŸèƒ½æ¼”ç¤ºå¤±è´¥: {e}")
    
    # æ¼”ç¤ºæ€»ç»“
    print("\n" + "ğŸ‰" * 20)
    print("LLMsæ¨¡å—æ¼”ç¤ºæ€»ç»“")
    print("ğŸ‰" * 20)
    print("âœ… å®Œæˆäº†ä»¥ä¸‹æ¨¡å—çš„æ¼”ç¤º:")
    print("   1. open_source_llms.py - Qwen3-0.6Bè°£è¨€æ£€æµ‹")
    print("   2. prompt_engineering.py - å¤šç§æç¤ºå·¥ç¨‹æŠ€æœ¯")
    print("   3. few_shot_learning.py - å°‘æ ·æœ¬å­¦ä¹ ç­–ç•¥")
    print("   4. rag_integration.py - RAGæ£€ç´¢å¢å¼ºç”Ÿæˆ (æ–°å¢)")
    print("   5. advanced_rag_features.py - é«˜çº§RAGåŠŸèƒ½ (æ–°å¢)")
    
    print("\nğŸ“š å­¦ä¹ è¦ç‚¹:")
    print("   - å¦‚ä½•ä½¿ç”¨å¼€æºå¤§è¯­è¨€æ¨¡å‹")
    print("   - å¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„æç¤ºæ¨¡æ¿")
    print("   - å¦‚ä½•å®ç°å°‘æ ·æœ¬å­¦ä¹ ")
    print("   - å¦‚ä½•æ„å»ºRAGç³»ç»Ÿæå‡æ£€æµ‹å‡†ç¡®æ€§")
    print("   - å¦‚ä½•ä½¿ç”¨é«˜çº§RAGæŠ€æœ¯(å¤šæŸ¥è¯¢ã€è¿­ä»£ç­‰)")
    print("   - å¦‚ä½•è¿›è¡Œè°£è¨€æ£€æµ‹ä»»åŠ¡")
    
    print(f"\nğŸ¯ å¦‚éœ€å•ç‹¬è¿è¡ŒæŸä¸ªæ¨¡å—:")
    print(f"   python models/llms/open_source_llms.py")
    print(f"   python models/llms/prompt_engineering.py")
    print(f"   python models/llms/few_shot_learning.py")
    print(f"   python models/llms/rag_integration.py")
    print(f"   python models/llms/test_rag.py  # RAGåŠŸèƒ½æµ‹è¯•")
    
    # ç»¼åˆæ¼”ç¤ºï¼šRAG vs æ ‡å‡†æ–¹æ³•å¯¹æ¯”
    print("\n" + "âš–ï¸" * 20)
    print("6. RAG vs æ ‡å‡†æ–¹æ³•å¯¹æ¯”æ¼”ç¤º")
    print("âš–ï¸" * 20)
    
    try:
        demo_rag_vs_standard_comparison()
        print("âœ… å¯¹æ¯”æ¼”ç¤ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æ¼”ç¤ºå¤±è´¥: {e}")


def demo_rag_vs_standard_comparison():
    """æ¼”ç¤ºRAGæ–¹æ³•ä¸æ ‡å‡†æ–¹æ³•çš„å¯¹æ¯”"""
    print("ğŸ”„ æ‰§è¡ŒRAG vs æ ‡å‡†æ–¹æ³•å¯¹æ¯”...")
    
    try:
        from models.llms.rag_integration import create_rag_detector
        
        # åˆ›å»ºRAGæ£€æµ‹å™¨
        rag_detector = create_rag_detector(use_existing_llm=False)
        
        # æµ‹è¯•æ¡ˆä¾‹
        test_cases = [
            {
                'text': 'ä¸­å›½ç§‘å­¦é™¢å‘å¸ƒæœ€æ–°ç ”ç©¶æˆæœï¼Œåœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå–å¾—é‡å¤§çªç ´',
                'expected': 'Non-rumor',
                'description': 'æƒå¨æœºæ„å‘å¸ƒ'
            },
            {
                'text': 'ç½‘ä¼ æŸå¸‚æ˜å¤©å°†å‘ç”Ÿå¤§åœ°éœ‡ï¼Œè¯·å¤§å®¶åšå¥½æ’¤ç¦»å‡†å¤‡',
                'expected': 'Rumor', 
                'description': 'åœ°éœ‡è°£è¨€'
            },
            {
                'text': 'æ®ä¸å®Œå…¨ç»Ÿè®¡ï¼Œæ–°äº§å“åœ¨å¸‚åœºä¸Šåå“è‰¯å¥½',
                'expected': 'Unverified',
                'description': 'æ¨¡ç³Šä¿¡æ¯æº'
            }
        ]
        
        print(f"\nğŸ“Š å¯¹æ¯”ç»“æœ:")
        print(f"{'æ¡ˆä¾‹':<30} {'æ ‡å‡†æ–¹æ³•':<15} {'RAGæ–¹æ³•':<15} {'æœŸæœ›ç»“æœ':<15}")
        print("-" * 80)
        
        for i, case in enumerate(test_cases, 1):
            text = case['text']
            expected = case['expected']
            
            # æ ‡å‡†æ–¹æ³•
            standard_result = rag_detector.retrieve_and_generate(text, use_context=False)
            standard_pred = standard_result['predicted_class']
            
            # RAGæ–¹æ³•
            rag_result = rag_detector.retrieve_and_generate(text, use_context=True)
            rag_pred = rag_result['predicted_class']
            
            # æ˜¾ç¤ºç»“æœ
            description = case['description']
            print(f"{description:<30} {standard_pred:<15} {rag_pred:<15} {expected:<15}")
            
            # è¯¦ç»†ä¿¡æ¯
            print(f"  æ ‡å‡†ç½®ä¿¡åº¦: {standard_result['confidence']:.3f}")
            print(f"  RAGç½®ä¿¡åº¦: {rag_result['confidence']:.3f}")
            print(f"  æ£€ç´¢æ–‡æ¡£æ•°: {rag_result['retrieved_count']}")
            print()
        
        # æ€§èƒ½è¯„ä¼°
        print("ğŸ”¬ æ€§èƒ½è¯„ä¼°:")
        evaluation = rag_detector.evaluate_rag_performance()
        
        print(f"  æ ‡å‡†æ–¹æ³•å‡†ç¡®ç‡: {evaluation['standard_mode']['accuracy']:.4f}")
        print(f"  RAGæ–¹æ³•å‡†ç¡®ç‡: {evaluation['rag_mode']['accuracy']:.4f}")
        print(f"  æ€§èƒ½æå‡: {evaluation['improvement']['accuracy_gain']:+.4f}")
        print(f"  å¹³å‡æ£€ç´¢æ–‡æ¡£æ•°: {evaluation['rag_mode']['avg_retrieved_docs']:.1f}")
        
    except Exception as e:
        print(f"å¯¹æ¯”æ¼”ç¤ºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def demo_rag_workflow():
    """æ¼”ç¤ºå®Œæ•´çš„RAGå·¥ä½œæµç¨‹"""
    print("\nğŸ”„ RAGå·¥ä½œæµç¨‹æ¼”ç¤º")
    print("-" * 40)
    
    try:
        from models.llms.rag_integration import RAGRumorDetector, KnowledgeBase
        
        # Step 1: æ„å»ºçŸ¥è¯†åº“
        print("æ­¥éª¤1: æ„å»ºçŸ¥è¯†åº“")
        kb = KnowledgeBase()
        print(f"  çŸ¥è¯†åº“åŒ…å« {len(kb.documents)} ä¸ªæ–‡æ¡£")
        
        # Step 2: åˆ›å»ºRAGæ£€æµ‹å™¨
        print("æ­¥éª¤2: åˆ›å»ºRAGæ£€æµ‹å™¨")
        rag_detector = RAGRumorDetector(knowledge_base=kb)
        print("  RAGæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # Step 3: æ–‡æ¡£æ£€ç´¢æ¼”ç¤º
        print("æ­¥éª¤3: æ–‡æ¡£æ£€ç´¢æ¼”ç¤º")
        query = "æƒå¨æœºæ„å‘å¸ƒä¿¡æ¯"
        retrieved_docs = kb.retrieve(query, top_k=3)
        print(f"  æ£€ç´¢æŸ¥è¯¢: {query}")
        print(f"  æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³æ–‡æ¡£:")
        for i, doc in enumerate(retrieved_docs, 1):
            print(f"    {i}. {doc['content'][:60]}... (ç›¸å…³åº¦: {doc.get('score', 0):.3f})")
        
        # Step 4: æç¤ºç”Ÿæˆæ¼”ç¤º
        print("æ­¥éª¤4: æç¤ºç”Ÿæˆæ¼”ç¤º")
        test_text = "å®˜æ–¹åª’ä½“æŠ¥é“é‡è¦æ–°é—»"
        prompt = rag_detector.create_rag_prompt(test_text, retrieved_docs)
        print(f"  æµ‹è¯•æ–‡æœ¬: {test_text}")
        print(f"  ç”Ÿæˆçš„RAGæç¤ºé•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"  æç¤ºé¢„è§ˆ: {prompt[:150]}...")
        
        # Step 5: å®Œæ•´åˆ†ææ¼”ç¤º
        print("æ­¥éª¤5: å®Œæ•´åˆ†ææ¼”ç¤º")
        result = rag_detector.retrieve_and_generate(test_text)
        print(f"  åˆ†æç»“æœ: {result['predicted_class']}")
        print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"  ä½¿ç”¨ä¸Šä¸‹æ–‡: {result['context_used']}")
        
        print("âœ… RAGå·¥ä½œæµç¨‹æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ RAGå·¥ä½œæµç¨‹æ¼”ç¤ºå¤±è´¥: {e}")


if __name__ == "__main__":
    main()