#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# models/llms/few_shot_learning.py

"""
å°‘æ ·æœ¬å­¦ä¹ ç­–ç•¥æ¨¡å—
å®ç°å¤šç§å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•ç”¨äºè°£è¨€æ£€æµ‹
åŒ…æ‹¬ç¤ºä¾‹é€‰æ‹©ã€ç¤ºä¾‹æ’åºã€åŠ¨æ€ç¤ºä¾‹ç”Ÿæˆç­‰åŠŸèƒ½
"""

import random
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union
from pathlib import Path
import json
import sys
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict, Counter
import logging

logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from data_utils.data_loaders import create_all_dataloaders
    from utils.config_manager import get_config_manager, get_output_path
    from models.llms.prompt_engineering import PromptManager
    USE_PROJECT_MODULES = True
    print("âœ… æˆåŠŸå¯¼å…¥é¡¹ç›®æ¨¡å—")
except ImportError as e:
    print(f"âš ï¸  å¯¼å…¥é¡¹ç›®æ¨¡å—å¤±è´¥: {e}")
    USE_PROJECT_MODULES = False


class ExampleSelector:
    """ç¤ºä¾‹é€‰æ‹©å™¨åŸºç±»"""
    
    def __init__(self, selection_strategy: str = "random"):
        """
        åˆå§‹åŒ–ç¤ºä¾‹é€‰æ‹©å™¨
        
        Args:
            selection_strategy: é€‰æ‹©ç­–ç•¥ ("random", "similarity", "diversity", "balanced")
        """
        self.selection_strategy = selection_strategy
        self.vectorizer = None
        
    def select_examples(self, 
                       candidate_examples: List[Dict],
                       query_text: str,
                       num_examples: int = 3,
                       **kwargs) -> List[Dict]:
        """
        é€‰æ‹©ç¤ºä¾‹
        
        Args:
            candidate_examples: å€™é€‰ç¤ºä¾‹åˆ—è¡¨
            query_text: æŸ¥è¯¢æ–‡æœ¬
            num_examples: é€‰æ‹©çš„ç¤ºä¾‹æ•°é‡
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            é€‰æ‹©çš„ç¤ºä¾‹åˆ—è¡¨
        """
        if self.selection_strategy == "random":
            return self._random_selection(candidate_examples, num_examples)
        elif self.selection_strategy == "similarity":
            return self._similarity_selection(candidate_examples, query_text, num_examples)
        elif self.selection_strategy == "diversity":
            return self._diversity_selection(candidate_examples, num_examples)
        elif self.selection_strategy == "balanced":
            return self._balanced_selection(candidate_examples, num_examples)
        else:
            return self._random_selection(candidate_examples, num_examples)
    
    def _random_selection(self, examples: List[Dict], num_examples: int) -> List[Dict]:
        """éšæœºé€‰æ‹©ç¤ºä¾‹"""
        if len(examples) <= num_examples:
            return examples
        return random.sample(examples, num_examples)
    
    def _similarity_selection(self, examples: List[Dict], query_text: str, num_examples: int) -> List[Dict]:
        """åŸºäºç›¸ä¼¼åº¦é€‰æ‹©ç¤ºä¾‹"""
        if len(examples) <= num_examples:
            return examples
        
        try:
            # æå–æ–‡æœ¬
            texts = [example.get('text', '') for example in examples]
            all_texts = texts + [query_text]
            
            # è®¡ç®—TF-IDFå‘é‡
            if self.vectorizer is None:
                self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
            
            tfidf_matrix = self.vectorizer.fit_transform(all_texts)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            query_vector = tfidf_matrix[-1]
            example_vectors = tfidf_matrix[:-1]
            similarities = cosine_similarity(query_vector, example_vectors).flatten()
            
            # é€‰æ‹©æœ€ç›¸ä¼¼çš„ç¤ºä¾‹
            top_indices = np.argsort(similarities)[-num_examples:]
            return [examples[i] for i in top_indices]
            
        except Exception as e:
            logger.warning(f"ç›¸ä¼¼åº¦é€‰æ‹©å¤±è´¥ï¼Œå›é€€åˆ°éšæœºé€‰æ‹©: {e}")
            return self._random_selection(examples, num_examples)
    
    def _diversity_selection(self, examples: List[Dict], num_examples: int) -> List[Dict]:
        """åŸºäºå¤šæ ·æ€§é€‰æ‹©ç¤ºä¾‹"""
        if len(examples) <= num_examples:
            return examples
        
        try:
            # æå–æ–‡æœ¬
            texts = [example.get('text', '') for example in examples]
            
            # è®¡ç®—TF-IDFå‘é‡
            if self.vectorizer is None:
                self.vectorizer = TfidfVectorizer(max_features=500, stop_words='english')
            
            tfidf_matrix = self.vectorizer.fit_transform(texts)
            
            # è´ªå¿ƒé€‰æ‹©å¤šæ ·æ€§ç¤ºä¾‹
            selected_indices = []
            remaining_indices = list(range(len(examples)))
            
            # éšæœºé€‰æ‹©ç¬¬ä¸€ä¸ª
            first_idx = random.choice(remaining_indices)
            selected_indices.append(first_idx)
            remaining_indices.remove(first_idx)
            
            # ä¾æ¬¡é€‰æ‹©ä¸å·²é€‰ç¤ºä¾‹æœ€ä¸ç›¸ä¼¼çš„
            for _ in range(num_examples - 1):
                if not remaining_indices:
                    break
                
                max_min_distance = -1
                best_idx = None
                
                for idx in remaining_indices:
                    # è®¡ç®—ä¸å·²é€‰ç¤ºä¾‹çš„æœ€å°è·ç¦»
                    min_distance = float('inf')
                    for selected_idx in selected_indices:
                        distance = 1 - cosine_similarity(
                            tfidf_matrix[idx], tfidf_matrix[selected_idx]
                        )[0][0]
                        min_distance = min(min_distance, distance)
                    
                    if min_distance > max_min_distance:
                        max_min_distance = min_distance
                        best_idx = idx
                
                if best_idx is not None:
                    selected_indices.append(best_idx)
                    remaining_indices.remove(best_idx)
            
            return [examples[i] for i in selected_indices]
            
        except Exception as e:
            logger.warning(f"å¤šæ ·æ€§é€‰æ‹©å¤±è´¥ï¼Œå›é€€åˆ°éšæœºé€‰æ‹©: {e}")
            return self._random_selection(examples, num_examples)
    
    def _balanced_selection(self, examples: List[Dict], num_examples: int) -> List[Dict]:
        """å¹³è¡¡é€‰æ‹©ç¤ºä¾‹ï¼ˆç¡®ä¿å„ç±»åˆ«å‡è¡¡ï¼‰"""
        if len(examples) <= num_examples:
            return examples
        
        # æŒ‰æ ‡ç­¾åˆ†ç»„
        label_groups = defaultdict(list)
        for example in examples:
            label = example.get('label', 'unknown')
            label_groups[label].append(example)
        
        # è®¡ç®—æ¯ä¸ªæ ‡ç­¾åº”é€‰æ‹©çš„æ•°é‡
        num_labels = len(label_groups)
        examples_per_label = max(1, num_examples // num_labels)
        remaining = num_examples % num_labels
        
        selected_examples = []
        labels = list(label_groups.keys())
        
        for i, label in enumerate(labels):
            current_examples = examples_per_label + (1 if i < remaining else 0)
            current_examples = min(current_examples, len(label_groups[label]))
            
            selected = random.sample(label_groups[label], current_examples)
            selected_examples.extend(selected)
        
        # å¦‚æœé€‰æ‹©çš„ç¤ºä¾‹ä¸å¤Ÿï¼Œéšæœºè¡¥å……
        if len(selected_examples) < num_examples:
            remaining_examples = [ex for ex in examples if ex not in selected_examples]
            additional = random.sample(
                remaining_examples, 
                min(num_examples - len(selected_examples), len(remaining_examples))
            )
            selected_examples.extend(additional)
        
        return selected_examples[:num_examples]


class FewShotLearner:
    """å°‘æ ·æœ¬å­¦ä¹ å™¨"""
    
    def __init__(self, 
                 selection_strategy: str = "balanced",
                 prompt_manager: Optional[PromptManager] = None):
        """
        åˆå§‹åŒ–å°‘æ ·æœ¬å­¦ä¹ å™¨
        
        Args:
            selection_strategy: ç¤ºä¾‹é€‰æ‹©ç­–ç•¥
            prompt_manager: æç¤ºç®¡ç†å™¨
        """
        self.selection_strategy = selection_strategy
        self.example_selector = ExampleSelector(selection_strategy)
        
        # åˆå§‹åŒ–æç¤ºç®¡ç†å™¨
        if prompt_manager is None and USE_PROJECT_MODULES:
            self.prompt_manager = PromptManager()
        else:
            self.prompt_manager = prompt_manager
        
        # ç¤ºä¾‹åº“
        self.example_pool = []
        self.label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if USE_PROJECT_MODULES:
            config_manager = get_config_manager()
            self.output_dir = get_output_path('models', 'llms')
        else:
            self.output_dir = Path('outputs/models/llms')
            self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½æˆ–åˆ›å»ºç¤ºä¾‹æ± 
        self._initialize_example_pool()
        
        print(f"ğŸ¯ å°‘æ ·æœ¬å­¦ä¹ å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   é€‰æ‹©ç­–ç•¥: {selection_strategy}")
        print(f"   ç¤ºä¾‹æ± å¤§å°: {len(self.example_pool)}")
    
    def _initialize_example_pool(self):
        """åˆå§‹åŒ–ç¤ºä¾‹æ± """
        try:
            if USE_PROJECT_MODULES:
                # ä»çœŸå®æ•°æ®é›†åŠ è½½ç¤ºä¾‹
                self._load_examples_from_dataset()
            else:
                # ä½¿ç”¨é¢„å®šä¹‰ç¤ºä¾‹
                self._load_predefined_examples()
            
            print(f"âœ… ç¤ºä¾‹æ± åŠ è½½å®Œæˆ: {len(self.example_pool)} ä¸ªç¤ºä¾‹")
            
        except Exception as e:
            logger.warning(f"ç¤ºä¾‹æ± åˆå§‹åŒ–å¤±è´¥: {e}")
            self._load_predefined_examples()
    
    def _load_examples_from_dataset(self):
        """ä»æ•°æ®é›†åŠ è½½ç¤ºä¾‹"""
        try:
            dataloaders = create_all_dataloaders(
                batch_sizes={'train': 32, 'val': 32, 'test': 32}
            )
            
            # ä»è®­ç»ƒé›†æå–ç¤ºä¾‹
            for batch in dataloaders['train']:
                texts = batch.get('text', batch.get('caption', []))
                labels = batch.get('labels', batch.get('label', []))
                
                if hasattr(labels, 'tolist'):
                    labels = labels.tolist()
                
                for text, label in zip(texts, labels):
                    if text and len(text.strip()) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                        self.example_pool.append({
                            'text': text.strip(),
                            'label': self.label_mapping.get(label, 'unknown'),
                            'label_id': label
                        })
            
            # é™åˆ¶ç¤ºä¾‹æ± å¤§å°
            if len(self.example_pool) > 1000:
                self.example_pool = random.sample(self.example_pool, 1000)
            
        except Exception as e:
            logger.error(f"ä»æ•°æ®é›†åŠ è½½ç¤ºä¾‹å¤±è´¥: {e}")
            raise
    
    def _load_predefined_examples(self):
        """åŠ è½½é¢„å®šä¹‰ç¤ºä¾‹"""
        predefined_examples = [
            {
                'text': 'ä¸­å›½ç§‘å­¦é™¢å‘å¸ƒæœ€æ–°ç ”ç©¶æˆæœï¼Œåœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå–å¾—é‡å¤§çªç ´',
                'label': 'Non-rumor',
                'label_id': 0
            },
            {
                'text': 'æ•™è‚²éƒ¨æ­£å¼å‘å¸ƒæ–°çš„é«˜è€ƒæ”¹é©æ–¹æ¡ˆï¼Œå°†äºæ˜å¹´å¼€å§‹å®æ–½',
                'label': 'Non-rumor', 
                'label_id': 0
            },
            {
                'text': 'ä¸–ç•Œå«ç”Ÿç»„ç»‡ç¡®è®¤æ–°å† ç–«è‹—å¯¹å˜å¼‚æ ªä»ç„¶æœ‰æ•ˆ',
                'label': 'Non-rumor',
                'label_id': 0
            },
            {
                'text': 'ç½‘ä¼ æŸåœ°æ˜å¤©å°†å‘ç”Ÿå¤§åœ°éœ‡ï¼Œè¯·å¤§å®¶åšå¥½é˜²æŠ¤å‡†å¤‡',
                'label': 'Rumor',
                'label_id': 1
            },
            {
                'text': 'è°£ä¼ æ–°å† ç–«è‹—å«æœ‰æ§åˆ¶èŠ¯ç‰‡ï¼Œå·²è¢«å¤šé¡¹ç ”ç©¶è¯å®ä¸ºè™šå‡ä¿¡æ¯',
                'label': 'Rumor',
                'label_id': 1
            },
            {
                'text': 'ç½‘ä¸Šæµä¼ æŸæ˜æ˜Ÿæ¶‰å«Œè¿æ³•çŠ¯ç½ªï¼Œä½†å½“äº‹äººå·²å‘å£°æ˜è¾Ÿè°£',
                'label': 'Rumor',
                'label_id': 1
            },
            {
                'text': 'æ®ä¸å®Œå…¨ç»Ÿè®¡ï¼ŒæŸæ–°äº§å“åœ¨å¸‚åœºä¸Šåå“è‰¯å¥½',
                'label': 'Unverified',
                'label_id': 2
            },
            {
                'text': 'æœ‰æ¶ˆæ¯ç§°æŸå…¬å¸å°†è¿›è¡Œå¤§è§„æ¨¡è£å‘˜ï¼Œä½†å…¬å¸å°šæœªå®˜æ–¹å›åº”',
                'label': 'Unverified',
                'label_id': 2
            },
            {
                'text': 'ä¸šå†…äººå£«é€éœ²ï¼ŒæŸè¡Œä¸šå¯èƒ½é¢ä¸´é‡å¤§æ”¿ç­–è°ƒæ•´',
                'label': 'Unverified',
                'label_id': 2
            },
            # è‹±æ–‡ç¤ºä¾‹
            {
                'text': 'NASA announces successful launch of new Mars exploration mission',
                'label': 'Non-rumor',
                'label_id': 0
            },
            {
                'text': 'Breaking: Celebrity found dead in apparent overdose, police investigating',
                'label': 'Rumor',
                'label_id': 1
            },
            {
                'text': 'Sources suggest major tech company planning significant layoffs',
                'label': 'Unverified',
                'label_id': 2
            }
        ]
        
        self.example_pool = predefined_examples
    
    def select_examples_for_query(self, 
                                 query_text: str,
                                 num_examples: int = 3,
                                 strategy: Optional[str] = None) -> List[Dict]:
        """
        ä¸ºæŸ¥è¯¢æ–‡æœ¬é€‰æ‹©ç¤ºä¾‹
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            num_examples: ç¤ºä¾‹æ•°é‡
            strategy: é€‰æ‹©ç­–ç•¥ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤ç­–ç•¥ï¼‰
            
        Returns:
            é€‰æ‹©çš„ç¤ºä¾‹åˆ—è¡¨
        """
        if strategy:
            selector = ExampleSelector(strategy)
        else:
            selector = self.example_selector
        
        selected = selector.select_examples(
            self.example_pool,
            query_text,
            num_examples
        )
        
        return selected
    
    def create_few_shot_prompt(self, 
                              query_text: str,
                              num_examples: int = 3,
                              selection_strategy: Optional[str] = None,
                              prompt_style: str = "formal") -> str:
        """
        åˆ›å»ºå°‘æ ·æœ¬æç¤º
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            num_examples: ç¤ºä¾‹æ•°é‡
            selection_strategy: é€‰æ‹©ç­–ç•¥
            prompt_style: æç¤ºé£æ ¼
            
        Returns:
            å°‘æ ·æœ¬æç¤ºå­—ç¬¦ä¸²
        """
        # é€‰æ‹©ç¤ºä¾‹
        examples = self.select_examples_for_query(
            query_text, 
            num_examples, 
            selection_strategy
        )
        
        # ç”Ÿæˆæç¤º
        if self.prompt_manager:
            prompt = self.prompt_manager.create_few_shot_prompt(
                query_text, 
                examples,
                style=prompt_style
            )
        else:
            prompt = self._create_simple_few_shot_prompt(query_text, examples)
        
        return prompt
    
    def _create_simple_few_shot_prompt(self, query_text: str, examples: List[Dict]) -> str:
        """åˆ›å»ºç®€å•çš„å°‘æ ·æœ¬æç¤º"""
        prompt = "ä»¥ä¸‹æ˜¯ä¸€äº›è°£è¨€æ£€æµ‹çš„ä¾‹å­ï¼š\n\n"
        
        for i, example in enumerate(examples, 1):
            prompt += f"ä¾‹å­{i}:\n"
            prompt += f"æ–‡æœ¬: {example['text']}\n"
            prompt += f"æ ‡ç­¾: {example['label']}\n\n"
        
        prompt += f"ç°åœ¨è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬:\næ–‡æœ¬: {query_text}\næ ‡ç­¾: "
        
        return prompt
    
    def analyze_example_distribution(self) -> Dict[str, Any]:
        """åˆ†æç¤ºä¾‹æ± çš„åˆ†å¸ƒæƒ…å†µ"""
        label_counts = Counter([ex['label'] for ex in self.example_pool])
        text_lengths = [len(ex['text']) for ex in self.example_pool]
        
        analysis = {
            'total_examples': len(self.example_pool),
            'label_distribution': dict(label_counts),
            'text_length_stats': {
                'mean': np.mean(text_lengths),
                'median': np.median(text_lengths),
                'min': min(text_lengths),
                'max': max(text_lengths),
                'std': np.std(text_lengths)
            },
            'balance_ratio': min(label_counts.values()) / max(label_counts.values()) if label_counts else 0
        }
        
        return analysis
    
    def evaluate_selection_strategies(self, 
                                    test_queries: List[str],
                                    num_examples: int = 3) -> Dict[str, Any]:
        """
        è¯„ä¼°ä¸åŒé€‰æ‹©ç­–ç•¥çš„æ•ˆæœ
        
        Args:
            test_queries: æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
            num_examples: ç¤ºä¾‹æ•°é‡
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        strategies = ["random", "similarity", "diversity", "balanced"]
        results = {}
        
        for strategy in strategies:
            print(f"ğŸ” è¯„ä¼°ç­–ç•¥: {strategy}")
            
            strategy_results = {
                'strategy': strategy,
                'examples_selected': [],
                'label_distributions': [],
                'diversity_scores': []
            }
            
            for query in test_queries:
                # é€‰æ‹©ç¤ºä¾‹
                examples = self.select_examples_for_query(
                    query, num_examples, strategy
                )
                
                # åˆ†æé€‰æ‹©çš„ç¤ºä¾‹
                labels = [ex['label'] for ex in examples]
                label_dist = Counter(labels)
                
                # è®¡ç®—å¤šæ ·æ€§åˆ†æ•°ï¼ˆç®€å•çš„æ ‡ç­¾å¤šæ ·æ€§ï¼‰
                diversity_score = len(set(labels)) / len(labels) if labels else 0
                
                strategy_results['examples_selected'].append(examples)
                strategy_results['label_distributions'].append(label_dist)
                strategy_results['diversity_scores'].append(diversity_score)
            
            # è®¡ç®—å¹³å‡å¤šæ ·æ€§
            strategy_results['avg_diversity'] = np.mean(strategy_results['diversity_scores'])
            
            results[strategy] = strategy_results
        
        return results
    
    def optimize_example_selection(self, 
                                  validation_queries: List[Tuple[str, str]],
                                  num_examples: int = 3) -> str:
        """
        åŸºäºéªŒè¯é›†ä¼˜åŒ–ç¤ºä¾‹é€‰æ‹©ç­–ç•¥
        
        Args:
            validation_queries: éªŒè¯æŸ¥è¯¢åˆ—è¡¨ [(text, true_label), ...]
            num_examples: ç¤ºä¾‹æ•°é‡
            
        Returns:
            æœ€ä¼˜ç­–ç•¥åç§°
        """
        strategies = ["random", "similarity", "diversity", "balanced"]
        strategy_scores = {}
        
        print("ğŸ” ä¼˜åŒ–ç¤ºä¾‹é€‰æ‹©ç­–ç•¥...")
        
        for strategy in strategies:
            print(f"   æµ‹è¯•ç­–ç•¥: {strategy}")
            
            # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„è¯„ä¼°é€»è¾‘
            # ç›®å‰ä½¿ç”¨ç®€å•çš„å¤šæ ·æ€§åˆ†æ•°ä½œä¸ºè¯„ä¼°æŒ‡æ ‡
            diversity_scores = []
            
            for query_text, true_label in validation_queries:
                examples = self.select_examples_for_query(
                    query_text, num_examples, strategy
                )
                
                labels = [ex['label'] for ex in examples]
                diversity_score = len(set(labels)) / len(labels) if labels else 0
                diversity_scores.append(diversity_score)
            
            avg_score = np.mean(diversity_scores)
            strategy_scores[strategy] = avg_score
            
            print(f"   {strategy}: {avg_score:.4f}")
        
        # é€‰æ‹©æœ€ä¼˜ç­–ç•¥
        best_strategy = max(strategy_scores, key=strategy_scores.get)
        
        print(f"âœ… æœ€ä¼˜ç­–ç•¥: {best_strategy} (åˆ†æ•°: {strategy_scores[best_strategy]:.4f})")
        
        # æ›´æ–°é€‰æ‹©ç­–ç•¥
        self.selection_strategy = best_strategy
        self.example_selector = ExampleSelector(best_strategy)
        
        return best_strategy
    
    def add_examples(self, new_examples: List[Dict]):
        """æ·»åŠ æ–°ç¤ºä¾‹åˆ°ç¤ºä¾‹æ± """
        for example in new_examples:
            if 'text' in example and 'label' in example:
                self.example_pool.append(example)
        
        print(f"âœ… æ·»åŠ  {len(new_examples)} ä¸ªæ–°ç¤ºä¾‹ï¼Œç¤ºä¾‹æ± å¤§å°: {len(self.example_pool)}")
    
    def save_example_pool(self, save_path: Optional[str] = None):
        """ä¿å­˜ç¤ºä¾‹æ± """
        if save_path is None:
            save_path = self.output_dir / "example_pool.json"
        
        data = {
            'examples': self.example_pool,
            'selection_strategy': self.selection_strategy,
            'label_mapping': self.label_mapping,
            'total_examples': len(self.example_pool)
        }
        
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ç¤ºä¾‹æ± å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_example_pool(self, load_path: str):
        """åŠ è½½ç¤ºä¾‹æ± """
        with open(load_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.example_pool = data.get('examples', [])
        self.selection_strategy = data.get('selection_strategy', 'balanced')
        self.label_mapping = data.get('label_mapping', self.label_mapping)
        
        # æ›´æ–°é€‰æ‹©å™¨
        self.example_selector = ExampleSelector(self.selection_strategy)
        
        print(f"âœ… ç¤ºä¾‹æ± å·²ä» {load_path} åŠ è½½: {len(self.example_pool)} ä¸ªç¤ºä¾‹")


class AdaptiveFewShotLearner(FewShotLearner):
    """è‡ªé€‚åº”å°‘æ ·æœ¬å­¦ä¹ å™¨"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.performance_history = []
        self.strategy_performance = defaultdict(list)
    
    def adaptive_select_examples(self, 
                                query_text: str,
                                num_examples: int = 3,
                                performance_threshold: float = 0.7) -> List[Dict]:
        """
        è‡ªé€‚åº”é€‰æ‹©ç¤ºä¾‹
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            num_examples: ç¤ºä¾‹æ•°é‡
            performance_threshold: æ€§èƒ½é˜ˆå€¼
            
        Returns:
            é€‰æ‹©çš„ç¤ºä¾‹
        """
        # å¦‚æœå†å²æ€§èƒ½ä¸ä½³ï¼Œå°è¯•ä¸åŒç­–ç•¥
        if self._should_explore_strategy(performance_threshold):
            strategy = self._choose_exploration_strategy()
            print(f"ğŸ”„ æ¢ç´¢æ–°ç­–ç•¥: {strategy}")
        else:
            strategy = self.selection_strategy
        
        return self.select_examples_for_query(query_text, num_examples, strategy)
    
    def _should_explore_strategy(self, threshold: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ¢ç´¢æ–°ç­–ç•¥"""
        if len(self.performance_history) < 5:
            return False
        
        recent_performance = np.mean(self.performance_history[-5:])
        return recent_performance < threshold
    
    def _choose_exploration_strategy(self) -> str:
        """é€‰æ‹©æ¢ç´¢ç­–ç•¥"""
        strategies = ["random", "similarity", "diversity", "balanced"]
        
        # åŸºäºå†å²æ€§èƒ½é€‰æ‹©
        if self.strategy_performance:
            strategy_scores = {
                strategy: np.mean(scores) 
                for strategy, scores in self.strategy_performance.items()
                if scores
            }
            if strategy_scores:
                return max(strategy_scores, key=strategy_scores.get)
        
        # éšæœºé€‰æ‹©
        return random.choice(strategies)
    
    def update_performance(self, strategy: str, performance: float):
        """æ›´æ–°æ€§èƒ½è®°å½•"""
        self.performance_history.append(performance)
        self.strategy_performance[strategy].append(performance)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]
        
        for strategy_name in self.strategy_performance:
            if len(self.strategy_performance[strategy_name]) > 50:
                self.strategy_performance[strategy_name] = self.strategy_performance[strategy_name][-50:]


def demo_few_shot_learning():
    """æ¼”ç¤ºå°‘æ ·æœ¬å­¦ä¹ åŠŸèƒ½"""
    print("ğŸ¯ å°‘æ ·æœ¬å­¦ä¹ æ¼”ç¤º")
    print("=" * 50)
    
    try:
        # åˆ›å»ºå°‘æ ·æœ¬å­¦ä¹ å™¨
        learner = FewShotLearner(selection_strategy="balanced")
        
        # åˆ†æç¤ºä¾‹æ± 
        print("ğŸ“Š ç¤ºä¾‹æ± åˆ†æ:")
        analysis = learner.analyze_example_distribution()
        print(f"   æ€»ç¤ºä¾‹æ•°: {analysis['total_examples']}")
        print(f"   æ ‡ç­¾åˆ†å¸ƒ: {analysis['label_distribution']}")
        print(f"   å¹³å‡æ–‡æœ¬é•¿åº¦: {analysis['text_length_stats']['mean']:.1f}")
        print(f"   å¹³è¡¡æ¯”ä¾‹: {analysis['balance_ratio']:.2f}")
        
        # æµ‹è¯•ä¸åŒé€‰æ‹©ç­–ç•¥
        test_query = "ä¸“å®¶å­¦è€…åœ¨å›½é™…æœŸåˆŠå‘è¡¨é‡è¦ç ”ç©¶æˆæœ"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        strategies = ["random", "similarity", "diversity", "balanced"]
        for strategy in strategies:
            print(f"\nç­–ç•¥: {strategy.upper()}")
            examples = learner.select_examples_for_query(test_query, 3, strategy)
            
            for i, example in enumerate(examples, 1):
                print(f"   ä¾‹å­{i}: {example['text'][:50]}... ({example['label']})")
        
        # åˆ›å»ºå°‘æ ·æœ¬æç¤º
        print(f"\nğŸ“ ç”Ÿæˆå°‘æ ·æœ¬æç¤º:")
        prompt = learner.create_few_shot_prompt(test_query, 3, "balanced")
        print(prompt[:300] + "...")
        
        # è¯„ä¼°é€‰æ‹©ç­–ç•¥
        print(f"\nğŸ“ˆ è¯„ä¼°é€‰æ‹©ç­–ç•¥:")
        test_queries = [
            "ç§‘å­¦å®¶å‘ç°æ–°çš„æ²»ç–—æ–¹æ³•",
            "ç½‘ä¼ æŸåœ°å°†å‘ç”Ÿè‡ªç„¶ç¾å®³",
            "æ®æ¶ˆæ¯äººå£«é€éœ²çš„æœªç¡®è®¤ä¿¡æ¯"
        ]
        
        evaluation = learner.evaluate_selection_strategies(test_queries, 2)
        for strategy, result in evaluation.items():
            print(f"   {strategy}: å¹³å‡å¤šæ ·æ€§ {result['avg_diversity']:.3f}")
        
        # ä¿å­˜ç¤ºä¾‹æ± 
        learner.save_example_pool()
        
        print(f"\nâœ… å°‘æ ·æœ¬å­¦ä¹ æ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    demo_few_shot_learning()