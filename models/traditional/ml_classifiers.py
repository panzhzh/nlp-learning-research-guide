#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# models/traditional/ml_classifiers.py

"""
ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»å™¨æ¨¡å— - ä¿®å¤ç‰ˆæœ¬
ä¿®å¤æ•°æ®åŠ è½½å™¨è°ƒç”¨é—®é¢˜
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.pipeline import Pipeline
import pickle
import json
from typing import Dict, List, Tuple, Any, Optional, Union
from pathlib import Path
import sys
import warnings
warnings.filterwarnings('ignore')

# å¿«é€Ÿè·¯å¾„è®¾ç½®
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from datasets.data_loaders import create_all_dataloaders
    from utils.config_manager import get_config_manager, get_output_path
    from preprocessing.text_processing import TextProcessor
    USE_PROJECT_MODULES = True
    print("âœ… æˆåŠŸå¯¼å…¥é¡¹ç›®æ¨¡å—")
except ImportError as e:
    print(f"âš ï¸  å¯¼å…¥é¡¹ç›®æ¨¡å—å¤±è´¥: {e}")
    USE_PROJECT_MODULES = False

import logging
logger = logging.getLogger(__name__)


class MLClassifierTrainer:
    """
    ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»å™¨è®­ç»ƒå™¨
    æ”¯æŒå¤šç§ç®—æ³•å’Œè‡ªåŠ¨ç‰¹å¾æå–
    """
    
    def __init__(self, data_dir: str = "data"):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
        """
        self.data_dir = data_dir
        self.models = {}
        self.results = {}
        self.vectorizers = {}
        
        # åˆå§‹åŒ–æ–‡æœ¬å¤„ç†å™¨
        if USE_PROJECT_MODULES:
            self.text_processor = TextProcessor(language='mixed')
        else:
            self.text_processor = None
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if USE_PROJECT_MODULES:
            config_manager = get_config_manager()
            self.output_dir = get_output_path('models', 'traditional')
        else:
            self.output_dir = Path('outputs/models/traditional')
            self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ ‡ç­¾æ˜ å°„
        self.label_mapping = {0: 'Non-rumor', 1: 'Rumor', 2: 'Unverified'}
        
        print(f"ğŸ¤– ä¼ ç»ŸMLåˆ†ç±»å™¨è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ•°æ®ç›®å½•: {self.data_dir}")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def load_data(self) -> Dict[str, Tuple[List[str], List[int]]]:
        """
        åŠ è½½MR2æ•°æ®é›† - ä¿®å¤ç‰ˆæœ¬
        
        Returns:
            æ•°æ®å­—å…¸ {split: (texts, labels)}
        """
        print("ğŸ“š åŠ è½½MR2æ•°æ®é›†...")
        
        if USE_PROJECT_MODULES:
            try:
                # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å‡½æ•°è°ƒç”¨æ–¹å¼
                dataloaders = create_all_dataloaders(
                    batch_sizes={'train': 32, 'val': 32, 'test': 32}
                )
                
                data = {}
                for split, dataloader in dataloaders.items():
                    texts = []
                    labels = []
                    
                    for batch in dataloader:
                        # æå–æ–‡æœ¬å’Œæ ‡ç­¾
                        if 'text' in batch:
                            texts.extend(batch['text'])
                        elif 'caption' in batch:  # MR2æ•°æ®é›†ä½¿ç”¨captionå­—æ®µ
                            texts.extend(batch['caption'])
                        
                        if 'labels' in batch:
                            labels.extend(batch['labels'].tolist())
                        elif 'label' in batch:
                            labels.extend(batch['label'])
                    
                    data[split] = (texts, labels)
                    print(f"âœ… åŠ è½½ {split}: {len(texts)} æ ·æœ¬")
                
                return data
                
            except Exception as e:
                print(f"âŒ ä½¿ç”¨é¡¹ç›®æ•°æ®åŠ è½½å™¨å¤±è´¥: {e}")
                return self._create_demo_data()
        else:
            return self._create_demo_data()
    
    def _create_demo_data(self) -> Dict[str, Tuple[List[str], List[int]]]:
        """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
        print("ğŸ”§ åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
        
        demo_texts = [
            "è¿™æ˜¯ä¸€ä¸ªå…³äºç§‘æŠ€è¿›æ­¥çš„çœŸå®æ–°é—»æŠ¥é“",
            "This is a fake news about celebrity scandal",
            "æœªç»è¯å®çš„ä¼ è¨€éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥éªŒè¯",
            "Breaking: Major breakthrough in AI technology announced",
            "ç½‘ä¼ æŸåœ°å‘ç”Ÿé‡å¤§äº‹æ•…ï¼Œå®˜æ–¹å°šæœªç¡®è®¤",
            "Scientists discover new species in deep ocean",
            "è°£ä¼ æŸå…¬å¸å€’é—­ï¼Œå®é™…æƒ…å†µæœ‰å¾…æ ¸å®",
            "Weather alert: Severe storm approaching coastal areas",
            "ç¤¾äº¤åª’ä½“æµä¼ çš„æœªè¯å®æ¶ˆæ¯å¼•å‘å…³æ³¨",
            "Economic indicators show positive growth trends"
        ]
        
        demo_labels = [0, 1, 2, 0, 2, 0, 1, 0, 2, 0]  # å¯¹åº” Non-rumor, Rumor, Unverified
        
        # åˆ›å»ºæ›´å¤šæ ·æœ¬ä»¥ä¾¿è®­ç»ƒ
        extended_texts = demo_texts * 5  # é‡å¤ä»¥åˆ›å»ºæ›´å¤šæ ·æœ¬
        extended_labels = demo_labels * 5
        
        # æŒ‰æ¯”ä¾‹åˆ†å‰²æ•°æ®
        total_size = len(extended_texts)
        train_size = int(0.7 * total_size)
        val_size = int(0.15 * total_size)
        
        return {
            'train': (extended_texts[:train_size], extended_labels[:train_size]),
            'val': (extended_texts[train_size:train_size+val_size], 
                   extended_labels[train_size:train_size+val_size]),
            'test': (extended_texts[train_size+val_size:], 
                    extended_labels[train_size+val_size:])
        }
    
    def create_feature_extractors(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        print("ğŸ”§ è®¾ç½®ç‰¹å¾æå–å™¨...")
        
        # TF-IDFå‘é‡åŒ–å™¨
        self.vectorizers['tfidf'] = TfidfVectorizer(
            max_features=5000,
            ngram_range=(1, 2),
            stop_words=None,  # ä¿ç•™åœç”¨è¯ï¼Œå› ä¸ºæ˜¯å¤šè¯­è¨€
            lowercase=True,
            min_df=2,
            max_df=0.95,
            sublinear_tf=True
        )
        
        # è¯è¢‹æ¨¡å‹å‘é‡åŒ–å™¨
        self.vectorizers['count'] = CountVectorizer(
            max_features=3000,
            ngram_range=(1, 2),
            stop_words=None,
            lowercase=True,
            min_df=2,
            max_df=0.95
        )
        
        print("âœ… ç‰¹å¾æå–å™¨è®¾ç½®å®Œæˆ")
    
    def preprocess_texts(self, texts: List[str]) -> List[str]:
        """
        é¢„å¤„ç†æ–‡æœ¬
        
        Args:
            texts: åŸå§‹æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å¤„ç†åçš„æ–‡æœ¬åˆ—è¡¨
        """
        if self.text_processor:
            # ä½¿ç”¨é¡¹ç›®çš„æ–‡æœ¬å¤„ç†å™¨
            processed_texts = []
            for text in texts:
                # æ¸…æ´—æ–‡æœ¬
                cleaned_text = self.text_processor.clean_text(text)
                # åˆ†è¯å¹¶é‡æ–°ç»„åˆ
                tokens = self.text_processor.tokenize(cleaned_text)
                processed_text = ' '.join(tokens) if tokens else cleaned_text
                processed_texts.append(processed_text)
            return processed_texts
        else:
            # ç®€å•çš„æ–‡æœ¬æ¸…ç†
            import re
            processed_texts = []
            for text in texts:
                # åŸºæœ¬æ¸…ç†
                text = re.sub(r'http\S+', '', text)  # ç§»é™¤URL
                text = re.sub(r'@\w+', '', text)    # ç§»é™¤@æåŠ
                text = re.sub(r'#\w+', '', text)    # ç§»é™¤#æ ‡ç­¾
                text = re.sub(r'\s+', ' ', text)    # æ ‡å‡†åŒ–ç©ºç™½
                text = text.strip()
                processed_texts.append(text)
            return processed_texts
    
    def create_models(self):
        """åˆ›å»ºæœºå™¨å­¦ä¹ æ¨¡å‹"""
        print("ğŸ¤– åˆ›å»ºæœºå™¨å­¦ä¹ æ¨¡å‹...")
        
        # SVMåˆ†ç±»å™¨
        self.models['svm'] = SVC(
            kernel='rbf',
            C=1.0,
            gamma='scale',
            probability=True,
            random_state=42
        )
        
        # éšæœºæ£®æ—åˆ†ç±»å™¨
        self.models['random_forest'] = RandomForestClassifier(
            n_estimators=100,
            max_depth=None,
            min_samples_split=2,
            min_samples_leaf=1,
            random_state=42
        )
        
        # æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
        self.models['naive_bayes'] = MultinomialNB(
            alpha=1.0,
            fit_prior=True
        )
        
        # é€»è¾‘å›å½’åˆ†ç±»å™¨
        self.models['logistic_regression'] = LogisticRegression(
            C=1.0,
            max_iter=1000,
            random_state=42,
            multi_class='ovr'
        )
        
        print(f"âœ… åˆ›å»ºäº† {len(self.models)} ä¸ªæ¨¡å‹")
    
    def train_single_model(self, model_name: str, X_train: np.ndarray, 
                          y_train: np.ndarray, X_val: np.ndarray, 
                          y_val: np.ndarray) -> Dict[str, Any]:
        """
        è®­ç»ƒå•ä¸ªæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾
            X_val: éªŒè¯ç‰¹å¾
            y_val: éªŒè¯æ ‡ç­¾
            
        Returns:
            è®­ç»ƒç»“æœå­—å…¸
        """
        print(f"ğŸ‹ï¸ è®­ç»ƒ {model_name} æ¨¡å‹...")
        
        model = self.models[model_name]
        
        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_train_pred = model.predict(X_train)
        y_val_pred = model.predict(X_val)
        
        # è®¡ç®—æŒ‡æ ‡
        train_accuracy = accuracy_score(y_train, y_train_pred)
        val_accuracy = accuracy_score(y_val, y_val_pred)
        train_f1 = f1_score(y_train, y_train_pred, average='macro')
        val_f1 = f1_score(y_val, y_val_pred, average='macro')
        
        # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        val_report = classification_report(y_val, y_val_pred, 
                                         target_names=list(self.label_mapping.values()),
                                         output_dict=True)
        
        result = {
            'model_name': model_name,
            'train_accuracy': train_accuracy,
            'val_accuracy': val_accuracy,
            'train_f1': train_f1,
            'val_f1': val_f1,
            'classification_report': val_report,
            'confusion_matrix': confusion_matrix(y_val, y_val_pred).tolist()
        }
        
        print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ:")
        print(f"   è®­ç»ƒå‡†ç¡®ç‡: {train_accuracy:.4f}")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}")
        print(f"   éªŒè¯F1åˆ†æ•°: {val_f1:.4f}")
        
        return result
    
    def hyperparameter_tuning(self, model_name: str, X_train: np.ndarray, 
                             y_train: np.ndarray) -> Dict[str, Any]:
        """
        è¶…å‚æ•°è°ƒä¼˜
        
        Args:
            model_name: æ¨¡å‹åç§°
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾
            
        Returns:
            æœ€ä½³å‚æ•°å­—å…¸
        """
        print(f"ğŸ” è¿›è¡Œ {model_name} è¶…å‚æ•°è°ƒä¼˜...")
        
        # å®šä¹‰å‚æ•°ç½‘æ ¼
        param_grids = {
            'svm': {
                'C': [0.1, 1, 10],
                'gamma': ['scale', 'auto', 0.001, 0.01],
                'kernel': ['rbf', 'linear']
            },
            'random_forest': {
                'n_estimators': [50, 100, 200],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5]
            },
            'logistic_regression': {
                'C': [0.1, 1, 10, 100],
                'penalty': ['l2'],
                'solver': ['lbfgs', 'liblinear']
            }
        }
        
        if model_name not in param_grids:
            print(f"âš ï¸  {model_name} ä¸æ”¯æŒè¶…å‚æ•°è°ƒä¼˜")
            return {}
        
        # æ‰§è¡Œç½‘æ ¼æœç´¢
        grid_search = GridSearchCV(
            self.models[model_name],
            param_grids[model_name],
            cv=3,
            scoring='f1_macro',
            n_jobs=-1,
            verbose=0
        )
        
        grid_search.fit(X_train, y_train)
        
        print(f"âœ… {model_name} æœ€ä½³å‚æ•°: {grid_search.best_params_}")
        print(f"   æœ€ä½³åˆ†æ•°: {grid_search.best_score_:.4f}")
        
        # æ›´æ–°æ¨¡å‹ä¸ºæœ€ä½³å‚æ•°
        self.models[model_name] = grid_search.best_estimator_
        
        return {
            'best_params': grid_search.best_params_,
            'best_score': grid_search.best_score_,
            'cv_results': grid_search.cv_results_
        }
    
    def train_all_models(self, use_hyperparameter_tuning: bool = False):
        """
        è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        
        Args:
            use_hyperparameter_tuning: æ˜¯å¦ä½¿ç”¨è¶…å‚æ•°è°ƒä¼˜
        """
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
        
        # åŠ è½½æ•°æ®
        data = self.load_data()
        
        # åˆ›å»ºç‰¹å¾æå–å™¨å’Œæ¨¡å‹
        self.create_feature_extractors()
        self.create_models()
        
        # é¢„å¤„ç†æ–‡æœ¬
        train_texts = self.preprocess_texts(data['train'][0])
        val_texts = self.preprocess_texts(data['val'][0])
        test_texts = self.preprocess_texts(data['test'][0])
        
        train_labels = np.array(data['train'][1])
        val_labels = np.array(data['val'][1])
        test_labels = np.array(data['test'][1])
        
        # ä½¿ç”¨TF-IDFç‰¹å¾æå–
        print("ğŸ”§ æå–TF-IDFç‰¹å¾...")
        X_train_tfidf = self.vectorizers['tfidf'].fit_transform(train_texts)
        X_val_tfidf = self.vectorizers['tfidf'].transform(val_texts)
        X_test_tfidf = self.vectorizers['tfidf'].transform(test_texts)
        
        print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼Œç‰¹å¾ç»´åº¦: {X_train_tfidf.shape[1]}")
        
        # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
        for model_name in self.models.keys():
            print(f"\n{'='*50}")
            print(f"è®­ç»ƒæ¨¡å‹: {model_name.upper()}")
            print(f"{'='*50}")
            
            # è¶…å‚æ•°è°ƒä¼˜ï¼ˆå¯é€‰ï¼‰
            if use_hyperparameter_tuning:
                tuning_results = self.hyperparameter_tuning(
                    model_name, X_train_tfidf, train_labels
                )
            else:
                tuning_results = {}
            
            # è®­ç»ƒæ¨¡å‹
            train_result = self.train_single_model(
                model_name, X_train_tfidf, train_labels,
                X_val_tfidf, val_labels
            )
            
            # æµ‹è¯•é›†è¯„ä¼°
            model = self.models[model_name]
            test_pred = model.predict(X_test_tfidf)
            test_accuracy = accuracy_score(test_labels, test_pred)
            test_f1 = f1_score(test_labels, test_pred, average='macro')
            
            # ä¿å­˜ç»“æœ
            self.results[model_name] = {
                **train_result,
                'test_accuracy': test_accuracy,
                'test_f1': test_f1,
                'hyperparameter_tuning': tuning_results,
                'feature_dim': X_train_tfidf.shape[1]
            }
            
            print(f"ğŸ¯ {model_name} æœ€ç»ˆç»“æœ:")
            print(f"   æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy:.4f}")
            print(f"   æµ‹è¯•F1åˆ†æ•°: {test_f1:.4f}")
        
        # ä¿å­˜æ¨¡å‹å’Œç»“æœ
        self.save_models_and_results()
        
        # æ˜¾ç¤ºæœ€ç»ˆå¯¹æ¯”
        self.print_model_comparison()
    
    def save_models_and_results(self):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹å’Œç»“æœ"""
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹å’Œç»“æœ...")
        
        # ä¿å­˜æ¯ä¸ªæ¨¡å‹
        for model_name, model in self.models.items():
            model_file = self.output_dir / f'{model_name}_model.pkl'
            with open(model_file, 'wb') as f:
                pickle.dump(model, f)
            print(f"âœ… ä¿å­˜æ¨¡å‹: {model_file}")
        
        # ä¿å­˜ç‰¹å¾æå–å™¨
        for vec_name, vectorizer in self.vectorizers.items():
            vec_file = self.output_dir / f'{vec_name}_vectorizer.pkl'
            with open(vec_file, 'wb') as f:
                pickle.dump(vectorizer, f)
            print(f"âœ… ä¿å­˜ç‰¹å¾æå–å™¨: {vec_file}")
        
        # ä¿å­˜ç»“æœ
        results_file = self.output_dir / 'training_results.json'
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"âœ… ä¿å­˜è®­ç»ƒç»“æœ: {results_file}")
        
        # ä¿å­˜æ¨¡å‹æ¯”è¾ƒ
        comparison_data = []
        for model_name, result in self.results.items():
            comparison_data.append({
                'Model': model_name,
                'Train_Accuracy': result['train_accuracy'],
                'Val_Accuracy': result['val_accuracy'],
                'Test_Accuracy': result['test_accuracy'],
                'Train_F1': result['train_f1'],
                'Val_F1': result['val_f1'],
                'Test_F1': result['test_f1']
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        comparison_file = self.output_dir / 'model_comparison.csv'
        comparison_df.to_csv(comparison_file, index=False)
        print(f"âœ… ä¿å­˜æ¨¡å‹æ¯”è¾ƒ: {comparison_file}")
    
    def print_model_comparison(self):
        """æ‰“å°æ¨¡å‹æ¯”è¾ƒç»“æœ"""
        print(f"\nğŸ“Š {'='*60}")
        print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        print(f"{'='*60}")
        
        # åˆ›å»ºæ¯”è¾ƒè¡¨æ ¼
        headers = ['æ¨¡å‹', 'è®­ç»ƒå‡†ç¡®ç‡', 'éªŒè¯å‡†ç¡®ç‡', 'æµ‹è¯•å‡†ç¡®ç‡', 'æµ‹è¯•F1']
        
        print(f"{'æ¨¡å‹':<15} {'è®­ç»ƒå‡†ç¡®ç‡':<10} {'éªŒè¯å‡†ç¡®ç‡':<10} {'æµ‹è¯•å‡†ç¡®ç‡':<10} {'æµ‹è¯•F1':<10}")
        print("-" * 60)
        
        # æŒ‰æµ‹è¯•F1åˆ†æ•°æ’åº
        sorted_results = sorted(self.results.items(), 
                              key=lambda x: x[1]['test_f1'], 
                              reverse=True)
        
        for model_name, result in sorted_results:
            print(f"{model_name:<15} "
                  f"{result['train_accuracy']:<10.4f} "
                  f"{result['val_accuracy']:<10.4f} "
                  f"{result['test_accuracy']:<10.4f} "
                  f"{result['test_f1']:<10.4f}")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = sorted_results[0]
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]}")
        print(f"   æµ‹è¯•F1åˆ†æ•°: {best_model[1]['test_f1']:.4f}")
        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_model[1]['test_accuracy']:.4f}")
    
    def load_trained_model(self, model_name: str, vectorizer_name: str = 'tfidf'):
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            vectorizer_name: ç‰¹å¾æå–å™¨åç§°
            
        Returns:
            (model, vectorizer) å…ƒç»„
        """
        model_file = self.output_dir / f'{model_name}_model.pkl'
        vec_file = self.output_dir / f'{vectorizer_name}_vectorizer.pkl'
        
        if not model_file.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")
        if not vec_file.exists():
            raise FileNotFoundError(f"ç‰¹å¾æå–å™¨æ–‡ä»¶ä¸å­˜åœ¨: {vec_file}")
        
        with open(model_file, 'rb') as f:
            model = pickle.load(f)
        
        with open(vec_file, 'rb') as f:
            vectorizer = pickle.load(f)
        
        return model, vectorizer
    
    def predict_single_text(self, text: str, model_name: str = 'best') -> Dict[str, Any]:
        """
        å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œé¢„æµ‹
        
        Args:
            text: å¾…é¢„æµ‹æ–‡æœ¬
            model_name: æ¨¡å‹åç§°ï¼Œ'best'è¡¨ç¤ºä½¿ç”¨æœ€ä½³æ¨¡å‹
            
        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        # å¦‚æœæŒ‡å®šä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼Œæ‰¾å‡ºæœ€ä½³æ¨¡å‹
        if model_name == 'best':
            if not self.results:
                raise ValueError("æ²¡æœ‰è®­ç»ƒç»“æœï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            
            best_model_name = max(self.results.keys(), 
                                key=lambda x: self.results[x]['test_f1'])
            model_name = best_model_name
        
        # åŠ è½½æ¨¡å‹å’Œç‰¹å¾æå–å™¨
        model, vectorizer = self.load_trained_model(model_name)
        
        # é¢„å¤„ç†æ–‡æœ¬
        processed_text = self.preprocess_texts([text])[0]
        
        # ç‰¹å¾æå–
        features = vectorizer.transform([processed_text])
        
        # é¢„æµ‹
        prediction = model.predict(features)[0]
        if hasattr(model, 'predict_proba'):
            probabilities = model.predict_proba(features)[0]
        else:
            probabilities = None
        
        result = {
            'original_text': text,
            'processed_text': processed_text,
            'prediction': int(prediction),
            'prediction_label': self.label_mapping.get(prediction, 'Unknown'),
            'model_used': model_name
        }
        
        if probabilities is not None:
            result['probabilities'] = {
                self.label_mapping.get(i, f'Class_{i}'): float(prob)
                for i, prob in enumerate(probabilities)
            }
        
        return result


def main():
    """ä¸»å‡½æ•°ï¼Œæ¼”ç¤ºè®­ç»ƒæµç¨‹"""
    print("ğŸš€ ä¼ ç»Ÿæœºå™¨å­¦ä¹ åˆ†ç±»å™¨è®­ç»ƒæ¼”ç¤º")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MLClassifierTrainer(data_dir="data")
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    trainer.train_all_models(use_hyperparameter_tuning=False)  # è®¾ç½®ä¸ºTrueå¯ç”¨è¶…å‚æ•°è°ƒä¼˜
    
    # æ¼”ç¤ºé¢„æµ‹
    print("\nğŸ”® æ¼”ç¤ºé¢„æµ‹åŠŸèƒ½:")
    test_texts = [
        "è¿™æ˜¯ä¸€ä¸ªå…³äºæ–°æŠ€æœ¯çªç ´çš„çœŸå®æ–°é—»",
        "ç½‘ä¼ æŸåœ°å‘ç”Ÿé‡å¤§äº‹æ•…ï¼Œå®˜æ–¹å°šæœªç¡®è®¤",
        "This might be fake news about celebrities"
    ]
    
    for text in test_texts:
        try:
            result = trainer.predict_single_text(text)
            print(f"\næ–‡æœ¬: {text}")
            print(f"é¢„æµ‹: {result['prediction_label']} (ç½®ä¿¡åº¦: {max(result.get('probabilities', {0: 0}).values()):.3f})")
        except Exception as e:
            print(f"é¢„æµ‹å¤±è´¥: {e}")
    
    print("\nâœ… è®­ç»ƒæ¼”ç¤ºå®Œæˆ!")
    print(f"ğŸ“ æ¨¡å‹å’Œç»“æœå·²ä¿å­˜åˆ°: {trainer.output_dir}")


if __name__ == "__main__":
    main()