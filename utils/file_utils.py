#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Author: ipanzhzh
# utils/file_utils.py

"""
æ–‡ä»¶æ“ä½œå·¥å…·æ¨¡å—
æä¾›ç»Ÿä¸€çš„æ–‡ä»¶è¯»å†™ã€æ ¼å¼è½¬æ¢ã€è·¯å¾„å¤„ç†ç­‰åŠŸèƒ½
"""

import json
import csv
import pickle
import os
import shutil
import yaml
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
import pandas as pd
from PIL import Image
import logging

logger = logging.getLogger(__name__)


class FileUtils:
    """æ–‡ä»¶æ“ä½œå·¥å…·ç±»"""
    
    @staticmethod
    def read_json(file_path: Union[str, Path], encoding: str = 'utf-8') -> Dict[str, Any]:
        """
        è¯»å–JSONæ–‡ä»¶
        
        Args:
            file_path: JSONæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            
        Returns:
            JSONæ•°æ®å­—å…¸
        """
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {file_path}, é”™è¯¯: {e}")
            raise
        except Exception as e:
            logger.error(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def write_json(data: Dict[str, Any], file_path: Union[str, Path], 
                   encoding: str = 'utf-8', indent: int = 2, ensure_ascii: bool = False) -> None:
        """
        å†™å…¥JSONæ–‡ä»¶
        
        Args:
            data: è¦å†™å…¥çš„æ•°æ®
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            indent: ç¼©è¿›ç©ºæ ¼æ•°
            ensure_ascii: æ˜¯å¦ç¡®ä¿ASCIIç¼–ç 
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'w', encoding=encoding) as f:
                json.dump(data, f, indent=indent, ensure_ascii=ensure_ascii)
            
            logger.info(f"æˆåŠŸå†™å…¥JSONæ–‡ä»¶: {file_path}")
            
        except Exception as e:
            logger.error(f"å†™å…¥JSONæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def read_yaml(file_path: Union[str, Path], encoding: str = 'utf-8') -> Dict[str, Any]:
        """
        è¯»å–YAMLæ–‡ä»¶
        
        Args:
            file_path: YAMLæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            
        Returns:
            YAMLæ•°æ®å­—å…¸
        """
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            logger.error(f"YAMLæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise
        except yaml.YAMLError as e:
            logger.error(f"YAMLæ–‡ä»¶æ ¼å¼é”™è¯¯: {file_path}, é”™è¯¯: {e}")
            raise
        except Exception as e:
            logger.error(f"è¯»å–YAMLæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def write_yaml(data: Dict[str, Any], file_path: Union[str, Path], 
                   encoding: str = 'utf-8') -> None:
        """
        å†™å…¥YAMLæ–‡ä»¶
        
        Args:
            data: è¦å†™å…¥çš„æ•°æ®
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'w', encoding=encoding) as f:
                yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
            
            logger.info(f"æˆåŠŸå†™å…¥YAMLæ–‡ä»¶: {file_path}")
            
        except Exception as e:
            logger.error(f"å†™å…¥YAMLæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def read_csv(file_path: Union[str, Path], encoding: str = 'utf-8', **kwargs) -> pd.DataFrame:
        """
        è¯»å–CSVæ–‡ä»¶
        
        Args:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            **kwargs: pandas.read_csvçš„å…¶ä»–å‚æ•°
            
        Returns:
            DataFrameå¯¹è±¡
        """
        try:
            return pd.read_csv(file_path, encoding=encoding, **kwargs)
        except FileNotFoundError:
            logger.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise
        except Exception as e:
            logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def write_csv(df: pd.DataFrame, file_path: Union[str, Path], 
                  encoding: str = 'utf-8', index: bool = False, **kwargs) -> None:
        """
        å†™å…¥CSVæ–‡ä»¶
        
        Args:
            df: DataFrameå¯¹è±¡
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            index: æ˜¯å¦åŒ…å«ç´¢å¼•
            **kwargs: pandas.to_csvçš„å…¶ä»–å‚æ•°
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            df.to_csv(file_path, encoding=encoding, index=index, **kwargs)
            logger.info(f"æˆåŠŸå†™å…¥CSVæ–‡ä»¶: {file_path}")
            
        except Exception as e:
            logger.error(f"å†™å…¥CSVæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def read_pickle(file_path: Union[str, Path]) -> Any:
        """
        è¯»å–Pickleæ–‡ä»¶
        
        Args:
            file_path: Pickleæ–‡ä»¶è·¯å¾„
            
        Returns:
            ååºåˆ—åŒ–çš„å¯¹è±¡
        """
        try:
            with open(file_path, 'rb') as f:
                return pickle.load(f)
        except FileNotFoundError:
            logger.error(f"Pickleæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise
        except Exception as e:
            logger.error(f"è¯»å–Pickleæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def write_pickle(obj: Any, file_path: Union[str, Path]) -> None:
        """
        å†™å…¥Pickleæ–‡ä»¶
        
        Args:
            obj: è¦åºåˆ—åŒ–çš„å¯¹è±¡
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'wb') as f:
                pickle.dump(obj, f)
            
            logger.info(f"æˆåŠŸå†™å…¥Pickleæ–‡ä»¶: {file_path}")
            
        except Exception as e:
            logger.error(f"å†™å…¥Pickleæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def read_text(file_path: Union[str, Path], encoding: str = 'utf-8') -> str:
        """
        è¯»å–æ–‡æœ¬æ–‡ä»¶
        
        Args:
            file_path: æ–‡æœ¬æ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            
        Returns:
            æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²
        """
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                return f.read()
        except FileNotFoundError:
            logger.error(f"æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise
        except Exception as e:
            logger.error(f"è¯»å–æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def write_text(text: str, file_path: Union[str, Path], 
                   encoding: str = 'utf-8', mode: str = 'w') -> None:
        """
        å†™å…¥æ–‡æœ¬æ–‡ä»¶
        
        Args:
            text: è¦å†™å…¥çš„æ–‡æœ¬
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            mode: å†™å…¥æ¨¡å¼ ('w' è¦†ç›–, 'a' è¿½åŠ )
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, mode, encoding=encoding) as f:
                f.write(text)
            
            logger.info(f"æˆåŠŸå†™å…¥æ–‡æœ¬æ–‡ä»¶: {file_path}")
            
        except Exception as e:
            logger.error(f"å†™å…¥æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def read_lines(file_path: Union[str, Path], encoding: str = 'utf-8', 
                   strip: bool = True) -> List[str]:
        """
        æŒ‰è¡Œè¯»å–æ–‡æœ¬æ–‡ä»¶
        
        Args:
            file_path: æ–‡æœ¬æ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            strip: æ˜¯å¦å»é™¤æ¯è¡Œçš„é¦–å°¾ç©ºç™½
            
        Returns:
            è¡Œåˆ—è¡¨
        """
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                lines = f.readlines()
                return [line.strip() for line in lines] if strip else lines
        except FileNotFoundError:
            logger.error(f"æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise
        except Exception as e:
            logger.error(f"æŒ‰è¡Œè¯»å–æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def write_lines(lines: List[str], file_path: Union[str, Path], 
                    encoding: str = 'utf-8', add_newline: bool = True) -> None:
        """
        æŒ‰è¡Œå†™å…¥æ–‡æœ¬æ–‡ä»¶
        
        Args:
            lines: è¡Œåˆ—è¡¨
            file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            encoding: æ–‡ä»¶ç¼–ç 
            add_newline: æ˜¯å¦åœ¨æ¯è¡Œæœ«å°¾æ·»åŠ æ¢è¡Œç¬¦
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'w', encoding=encoding) as f:
                for line in lines:
                    if add_newline and not line.endswith('\n'):
                        line += '\n'
                    f.write(line)
            
            logger.info(f"æˆåŠŸæŒ‰è¡Œå†™å…¥æ–‡æœ¬æ–‡ä»¶: {file_path}")
            
        except Exception as e:
            logger.error(f"æŒ‰è¡Œå†™å…¥æ–‡æœ¬æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            raise


class PathUtils:
    """è·¯å¾„æ“ä½œå·¥å…·ç±»"""
    
    @staticmethod
    def ensure_dir(dir_path: Union[str, Path]) -> Path:
        """
        ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            
        Returns:
            Pathå¯¹è±¡
        """
        path = Path(dir_path)
        path.mkdir(parents=True, exist_ok=True)
        return path
    
    @staticmethod
    def get_file_size(file_path: Union[str, Path]) -> int:
        """
        è·å–æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶å¤§å°
        """
        try:
            return os.path.getsize(file_path)
        except FileNotFoundError:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise
    
    @staticmethod
    def get_file_extension(file_path: Union[str, Path]) -> str:
        """
        è·å–æ–‡ä»¶æ‰©å±•å
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶æ‰©å±•åï¼ˆåŒ…å«ç‚¹ï¼‰
        """
        return Path(file_path).suffix
    
    @staticmethod
    def change_file_extension(file_path: Union[str, Path], new_ext: str) -> Path:
        """
        æ›´æ”¹æ–‡ä»¶æ‰©å±•å
        
        Args:
            file_path: åŸæ–‡ä»¶è·¯å¾„
            new_ext: æ–°æ‰©å±•åï¼ˆå¯åŒ…å«æˆ–ä¸åŒ…å«ç‚¹ï¼‰
            
        Returns:
            æ–°çš„Pathå¯¹è±¡
        """
        path = Path(file_path)
        if not new_ext.startswith('.'):
            new_ext = '.' + new_ext
        return path.with_suffix(new_ext)
    
    @staticmethod
    def list_files(dir_path: Union[str, Path], pattern: str = "*", 
                   recursive: bool = False) -> List[Path]:
        """
        åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
        
        Args:
            dir_path: ç›®å½•è·¯å¾„
            pattern: æ–‡ä»¶åæ¨¡å¼ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
            recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        path = Path(dir_path)
        if not path.exists():
            logger.warning(f"ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            return []
        
        if recursive:
            return list(path.rglob(pattern))
        else:
            return list(path.glob(pattern))
    
    @staticmethod
    def copy_file(src: Union[str, Path], dst: Union[str, Path], 
                  create_dirs: bool = True) -> None:
        """
        å¤åˆ¶æ–‡ä»¶
        
        Args:
            src: æºæ–‡ä»¶è·¯å¾„
            dst: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            create_dirs: æ˜¯å¦è‡ªåŠ¨åˆ›å»ºç›®æ ‡ç›®å½•
        """
        try:
            if create_dirs:
                Path(dst).parent.mkdir(parents=True, exist_ok=True)
            
            shutil.copy2(src, dst)
            logger.info(f"æˆåŠŸå¤åˆ¶æ–‡ä»¶: {src} -> {dst}")
            
        except Exception as e:
            logger.error(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {src} -> {dst}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def move_file(src: Union[str, Path], dst: Union[str, Path], 
                  create_dirs: bool = True) -> None:
        """
        ç§»åŠ¨æ–‡ä»¶
        
        Args:
            src: æºæ–‡ä»¶è·¯å¾„
            dst: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            create_dirs: æ˜¯å¦è‡ªåŠ¨åˆ›å»ºç›®æ ‡ç›®å½•
        """
        try:
            if create_dirs:
                Path(dst).parent.mkdir(parents=True, exist_ok=True)
            
            shutil.move(str(src), str(dst))
            logger.info(f"æˆåŠŸç§»åŠ¨æ–‡ä»¶: {src} -> {dst}")
            
        except Exception as e:
            logger.error(f"ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {src} -> {dst}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def delete_file(file_path: Union[str, Path], ignore_errors: bool = False) -> None:
        """
        åˆ é™¤æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            ignore_errors: æ˜¯å¦å¿½ç•¥é”™è¯¯
        """
        try:
            Path(file_path).unlink()
            logger.info(f"æˆåŠŸåˆ é™¤æ–‡ä»¶: {file_path}")
            
        except FileNotFoundError:
            if not ignore_errors:
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                raise
        except Exception as e:
            if not ignore_errors:
                logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
                raise


class ImageUtils:
    """å›¾åƒæ–‡ä»¶æ“ä½œå·¥å…·ç±»"""
    
    @staticmethod
    def load_image(image_path: Union[str, Path], mode: str = 'RGB') -> Image.Image:
        """
        åŠ è½½å›¾åƒæ–‡ä»¶
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            mode: å›¾åƒæ¨¡å¼ ('RGB', 'RGBA', 'L' ç­‰)
            
        Returns:
            PIL Imageå¯¹è±¡
        """
        try:
            image = Image.open(image_path)
            if mode and image.mode != mode:
                image = image.convert(mode)
            return image
        except FileNotFoundError:
            logger.error(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            raise
        except Exception as e:
            logger.error(f"åŠ è½½å›¾åƒå¤±è´¥: {image_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def save_image(image: Image.Image, save_path: Union[str, Path], 
                   quality: int = 95, **kwargs) -> None:
        """
        ä¿å­˜å›¾åƒæ–‡ä»¶
        
        Args:
            image: PIL Imageå¯¹è±¡
            save_path: ä¿å­˜è·¯å¾„
            quality: å›¾åƒè´¨é‡ (1-100)
            **kwargs: å…¶ä»–ä¿å­˜å‚æ•°
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            Path(save_path).parent.mkdir(parents=True, exist_ok=True)
            
            image.save(save_path, quality=quality, **kwargs)
            logger.info(f"æˆåŠŸä¿å­˜å›¾åƒ: {save_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å›¾åƒå¤±è´¥: {save_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def get_image_info(image_path: Union[str, Path]) -> Dict[str, Any]:
        """
        è·å–å›¾åƒåŸºæœ¬ä¿¡æ¯
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾åƒä¿¡æ¯å­—å…¸
        """
        try:
            with Image.open(image_path) as image:
                file_size = PathUtils.get_file_size(image_path)
                
                return {
                    'path': str(image_path),
                    'format': image.format,
                    'mode': image.mode,
                    'size': image.size,
                    'width': image.width,
                    'height': image.height,
                    'file_size': file_size,
                    'file_size_mb': round(file_size / (1024 * 1024), 2)
                }
        except Exception as e:
            logger.error(f"è·å–å›¾åƒä¿¡æ¯å¤±è´¥: {image_path}, é”™è¯¯: {e}")
            raise
    
    @staticmethod
    def resize_image(image: Image.Image, size: tuple, 
                     resample: int = Image.Resampling.LANCZOS) -> Image.Image:
        """
        è°ƒæ•´å›¾åƒå¤§å°
        
        Args:
            image: PIL Imageå¯¹è±¡
            size: ç›®æ ‡å°ºå¯¸ (width, height)
            resample: é‡é‡‡æ ·æ–¹æ³•
            
        Returns:
            è°ƒæ•´åçš„å›¾åƒ
        """
        try:
            return image.resize(size, resample)
        except Exception as e:
            logger.error(f"è°ƒæ•´å›¾åƒå¤§å°å¤±è´¥: {e}")
            raise
    
    @staticmethod
    def is_valid_image(file_path: Union[str, Path]) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆå›¾åƒ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¸ºæœ‰æ•ˆå›¾åƒ
        """
        try:
            with Image.open(file_path) as image:
                image.verify()
            return True
        except Exception:
            return False


class DatasetUtils:
    """æ•°æ®é›†æ–‡ä»¶æ“ä½œå·¥å…·ç±»"""
    
    @staticmethod
    def load_mr2_dataset(data_dir: Union[str, Path], split: str) -> Dict[str, Any]:
        """
        åŠ è½½MR2æ•°æ®é›†
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            split: æ•°æ®åˆ’åˆ† ('train', 'val', 'test')
            
        Returns:
            æ•°æ®é›†å­—å…¸
        """
        dataset_file = Path(data_dir) / f'dataset_items_{split}.json'
        return FileUtils.read_json(dataset_file)
    
    @staticmethod
    def save_processed_features(features: Any, data_dir: Union[str, Path], 
                               split: str, feature_type: str = 'features') -> None:
        """
        ä¿å­˜å¤„ç†åçš„ç‰¹å¾
        
        Args:
            features: ç‰¹å¾æ•°æ®
            data_dir: æ•°æ®ç›®å½•
            split: æ•°æ®åˆ’åˆ†
            feature_type: ç‰¹å¾ç±»å‹å
        """
        processed_dir = Path(data_dir) / 'processed'
        processed_dir.mkdir(parents=True, exist_ok=True)
        
        feature_file = processed_dir / f'{split}_{feature_type}.pkl'
        FileUtils.write_pickle(features, feature_file)
    
    @staticmethod
    def load_processed_features(data_dir: Union[str, Path], split: str, 
                               feature_type: str = 'features') -> Any:
        """
        åŠ è½½å¤„ç†åçš„ç‰¹å¾
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            split: æ•°æ®åˆ’åˆ†
            feature_type: ç‰¹å¾ç±»å‹å
            
        Returns:
            ç‰¹å¾æ•°æ®
        """
        processed_dir = Path(data_dir) / 'processed'
        feature_file = processed_dir / f'{split}_{feature_type}.pkl'
        
        if not feature_file.exists():
            raise FileNotFoundError(f"å¤„ç†åçš„ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {feature_file}")
        
        return FileUtils.read_pickle(feature_file)
    
    @staticmethod
    def get_annotation_file(data_dir: Union[str, Path], split: str, 
                           item_id: str, annotation_type: str) -> Path:
        """
        è·å–æ ‡æ³¨æ–‡ä»¶è·¯å¾„
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            split: æ•°æ®åˆ’åˆ†
            item_id: æ•°æ®é¡¹ID
            annotation_type: æ ‡æ³¨ç±»å‹ ('direct', 'inverse')
            
        Returns:
            æ ‡æ³¨æ–‡ä»¶è·¯å¾„
        """
        if annotation_type == 'direct':
            return Path(data_dir) / split / 'img_html_news' / item_id / 'direct_annotation.json'
        elif annotation_type == 'inverse':
            return Path(data_dir) / split / 'inverse_search' / item_id / 'inverse_annotation.json'
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ‡æ³¨ç±»å‹: {annotation_type}")
    
    @staticmethod
    def batch_process_files(file_list: List[Union[str, Path]], 
                           process_func: callable, 
                           output_dir: Optional[Union[str, Path]] = None,
                           **kwargs) -> List[Any]:
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶
        
        Args:
            file_list: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            process_func: å¤„ç†å‡½æ•°
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
            **kwargs: å¤„ç†å‡½æ•°çš„é¢å¤–å‚æ•°
            
        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨
        """
        results = []
        
        for file_path in file_list:
            try:
                result = process_func(file_path, **kwargs)
                
                # å¦‚æœæŒ‡å®šäº†è¾“å‡ºç›®å½•ï¼Œä¿å­˜ç»“æœ
                if output_dir and result is not None:
                    output_path = Path(output_dir) / f"{Path(file_path).stem}_processed.pkl"
                    FileUtils.write_pickle(result, output_path)
                
                results.append(result)
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
                results.append(None)
        
        return results


# ä¾¿æ·å‡½æ•°
def load_config(config_path: Union[str, Path]) -> Dict[str, Any]:
    """
    æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨é€‰æ‹©åŠ è½½æ–¹æ³•
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        é…ç½®æ•°æ®å­—å…¸
    """
    ext = PathUtils.get_file_extension(config_path).lower()
    
    if ext in ['.json']:
        return FileUtils.read_json(config_path)
    elif ext in ['.yaml', '.yml']:
        return FileUtils.read_yaml(config_path)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼: {ext}")


def save_results(results: Dict[str, Any], output_path: Union[str, Path], 
                format: str = 'auto') -> None:
    """
    ä¿å­˜å®éªŒç»“æœ
    
    Args:
        results: ç»“æœæ•°æ®
        output_path: è¾“å‡ºè·¯å¾„
        format: ä¿å­˜æ ¼å¼ ('json', 'yaml', 'pickle', 'auto')
    """
    if format == 'auto':
        ext = PathUtils.get_file_extension(output_path).lower()
        if ext in ['.json']:
            format = 'json'
        elif ext in ['.yaml', '.yml']:
            format = 'yaml'
        elif ext in ['.pkl', '.pickle']:
            format = 'pickle'
        else:
            format = 'json'  # é»˜è®¤
    
    if format == 'json':
        FileUtils.write_json(results, output_path)
    elif format == 'yaml':
        FileUtils.write_yaml(results, output_path)
    elif format == 'pickle':
        FileUtils.write_pickle(results, output_path)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ä¿å­˜æ ¼å¼: {format}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•æ–‡ä»¶æ“ä½œåŠŸèƒ½
    print("ğŸ§ª æµ‹è¯•æ–‡ä»¶æ“ä½œå·¥å…·")
    
    # æµ‹è¯•JSONè¯»å†™
    test_data = {"name": "æµ‹è¯•", "value": 123, "list": [1, 2, 3]}
    FileUtils.write_json(test_data, "test_output.json")
    loaded_data = FileUtils.read_json("test_output.json")
    print(f"JSONæµ‹è¯•: {loaded_data}")
    
    # æµ‹è¯•è·¯å¾„æ“ä½œ
    test_dir = PathUtils.ensure_dir("test_dir/subdir")
    print(f"åˆ›å»ºç›®å½•: {test_dir}")
    
    # æµ‹è¯•å›¾åƒä¿¡æ¯è·å–ï¼ˆå¦‚æœæœ‰å›¾åƒæ–‡ä»¶ï¼‰
    try:
        # è¿™é‡Œéœ€è¦å®é™…çš„å›¾åƒæ–‡ä»¶è·¯å¾„
        # image_info = ImageUtils.get_image_info("path/to/image.jpg")
        # print(f"å›¾åƒä¿¡æ¯: {image_info}")
        pass
    except:
        print("è·³è¿‡å›¾åƒæµ‹è¯•ï¼ˆæ— å›¾åƒæ–‡ä»¶ï¼‰")
    
    print("âœ… æ–‡ä»¶æ“ä½œå·¥å…·æµ‹è¯•å®Œæˆ")